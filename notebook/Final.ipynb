{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GWqANkvn7z_9",
        "outputId": "f71d969d-eec7-4752-e1ee-e31ccef56cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.21.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.37.37-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Collecting mlflow-skinny==2.21.3 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.21.3-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.8)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading databricks_sdk-0.50.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (1.32.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (2.11.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (4.13.2)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting botocore<1.38.0,>=1.37.37 (from boto3)\n",
            "  Downloading botocore-1.37.37-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
            "  Downloading s3transfer-0.11.5-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.37->boto3) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (2.38.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.3->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (0.53b1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (2025.1.31)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.21.3->mlflow) (0.14.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.21.3-py3-none-any.whl (28.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.21.3-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.37-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.37-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.50.0-py3-none-any.whl (692 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m692.3/692.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, jmespath, gunicorn, graphql-core, starlette, graphql-relay, docker, botocore, alembic, s3transfer, graphene, fastapi, databricks-sdk, boto3, mlflow-skinny, mlflow\n",
            "Successfully installed alembic-1.15.2 boto3-1.37.37 botocore-1.37.37 databricks-sdk-0.50.0 docker-7.1.0 fastapi-0.115.12 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 mlflow-2.21.3 mlflow-skinny-2.21.3 s3transfer-0.11.5 starlette-0.46.2 uvicorn-0.34.2\n",
            "Required packages installed\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost statsmodels matplotlib seaborn plotly mlflow boto3\n",
        "print(\"Required packages installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import warnings\n",
        "import logging\n",
        "import boto3\n",
        "from io import StringIO\n",
        "\n",
        "# Configure prettier plots\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"muted\")\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress warnings for cleaner notebook output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(\"Environment setup complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRdpDtc18GNs",
        "outputId": "55488334-b85d-4c93-bbd2-84c4d44e4795"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n",
            "Environment setup complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class S3Connector:\n",
        "    \"\"\"Utility class for connecting to S3 and retrieving files.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 aws_access_key_id=None,\n",
        "                 aws_secret_access_key=None,\n",
        "                 region_name='us-east-1'):\n",
        "        \"\"\"\n",
        "        Initialize S3 client.\n",
        "\n",
        "        Args:\n",
        "            aws_access_key_id (str, optional): AWS access key ID\n",
        "            aws_secret_access_key (str, optional): AWS secret access key\n",
        "            region_name (str, optional): AWS region name\n",
        "        \"\"\"\n",
        "        self.s3_client = boto3.client(\n",
        "            's3',\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key,\n",
        "            region_name=region_name\n",
        "        )\n",
        "        self.region_name = region_name\n",
        "        print(f\"✅ S3 client initialized for region: {region_name}\")\n",
        "\n",
        "    def read_csv_from_s3(self, bucket_name, key):\n",
        "        \"\"\"\n",
        "        Read CSV file from S3 bucket.\n",
        "\n",
        "        Args:\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: DataFrame containing CSV data\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Reading file from S3: s3://{bucket_name}/{key}\")\n",
        "            response = self.s3_client.get_object(Bucket=bucket_name, Key=key)\n",
        "            csv_content = response['Body'].read().decode('utf-8')\n",
        "            df = pd.read_csv(StringIO(csv_content))\n",
        "            print(f\"✅ Successfully read CSV from S3 with {len(df):,} rows\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading file from S3: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def save_file_to_s3(self, local_file_path, bucket_name, key):\n",
        "        \"\"\"\n",
        "        Save a local file to S3 bucket.\n",
        "\n",
        "        Args:\n",
        "            local_file_path (str): Local file path\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Uploading file to S3: s3://{bucket_name}/{key}\")\n",
        "            self.s3_client.upload_file(local_file_path, bucket_name, key)\n",
        "            print(f\"✅ Successfully uploaded file to S3\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error uploading file to S3: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_data_to_s3(self, data, bucket_name, key, content_type=None):\n",
        "        \"\"\"\n",
        "        Save data directly to S3 without creating a local file first.\n",
        "\n",
        "        Args:\n",
        "            data: Data to save (bytes, string, or serializable object)\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "            content_type (str, optional): Content type of the data\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Saving data to S3: s3://{bucket_name}/{key}\")\n",
        "\n",
        "            # Handle different data types\n",
        "            if isinstance(data, bytes):\n",
        "                body = data\n",
        "            elif isinstance(data, str):\n",
        "                body = data.encode('utf-8')\n",
        "            else:\n",
        "                # For other objects like dictionaries, try to JSON serialize\n",
        "                try:\n",
        "                    body = json.dumps(data).encode('utf-8')\n",
        "                    if not content_type:\n",
        "                        content_type = 'application/json'\n",
        "                except:\n",
        "                    print(f\"❌ Error: Data type not supported for direct S3 upload\")\n",
        "                    return False\n",
        "\n",
        "            # Set up the upload parameters\n",
        "            params = {\n",
        "                'Bucket': bucket_name,\n",
        "                'Key': key,\n",
        "                'Body': body\n",
        "            }\n",
        "\n",
        "            if content_type:\n",
        "                params['ContentType'] = content_type\n",
        "\n",
        "            # Upload the data\n",
        "            self.s3_client.put_object(**params)\n",
        "            print(f\"✅ Successfully saved data to S3\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error saving data to S3: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_pickle_to_s3(self, obj, bucket_name, key):\n",
        "        \"\"\"\n",
        "        Pickle an object and save it directly to S3.\n",
        "\n",
        "        Args:\n",
        "            obj: Python object to pickle\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Saving pickled object to S3: s3://{bucket_name}/{key}\")\n",
        "\n",
        "            # Pickle the object to a bytes buffer\n",
        "            import pickle\n",
        "            from io import BytesIO\n",
        "\n",
        "            buffer = BytesIO()\n",
        "            pickle.dump(obj, buffer)\n",
        "            buffer.seek(0)\n",
        "\n",
        "            # Upload the pickled object\n",
        "            self.s3_client.upload_fileobj(buffer, bucket_name, key)\n",
        "            print(f\"✅ Successfully saved pickled object to S3\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error pickling object to S3: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_figure_to_s3(self, figure, bucket_name, key, dpi=300, format='png'):\n",
        "        \"\"\"\n",
        "        Save a matplotlib figure directly to S3.\n",
        "\n",
        "        Args:\n",
        "            figure: Matplotlib figure object\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "            dpi (int): DPI for the figure\n",
        "            format (str): Format to save the figure ('png', 'jpg', etc.)\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Saving figure to S3: s3://{bucket_name}/{key}\")\n",
        "\n",
        "            # Save figure to a bytes buffer\n",
        "            from io import BytesIO\n",
        "            buffer = BytesIO()\n",
        "            figure.savefig(buffer, format=format, dpi=dpi)\n",
        "            buffer.seek(0)\n",
        "\n",
        "            # Set appropriate content type based on format\n",
        "            content_type = f\"image/{format}\"\n",
        "\n",
        "            # Upload the figure\n",
        "            self.s3_client.upload_fileobj(\n",
        "                buffer,\n",
        "                bucket_name,\n",
        "                key,\n",
        "                ExtraArgs={'ContentType': content_type}\n",
        "            )\n",
        "            print(f\"✅ Successfully saved figure to S3\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error saving figure to S3: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def check_s3_path_exists(self, bucket_name, prefix):\n",
        "        \"\"\"\n",
        "        Check if an S3 path (prefix) exists.\n",
        "\n",
        "        Args:\n",
        "            bucket_name (str): S3 bucket name\n",
        "            prefix (str): Path prefix to check\n",
        "\n",
        "        Returns:\n",
        "            bool: True if path exists, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Ensure the prefix ends with a slash if it's meant to be a directory\n",
        "            if prefix and not prefix.endswith('/'):\n",
        "                prefix += '/'\n",
        "\n",
        "            response = self.s3_client.list_objects_v2(\n",
        "                Bucket=bucket_name,\n",
        "                Prefix=prefix,\n",
        "                MaxKeys=1\n",
        "            )\n",
        "\n",
        "            return 'Contents' in response\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error checking S3 path: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def create_s3_directory(self, bucket_name, directory):\n",
        "        \"\"\"\n",
        "        Create a directory structure in S3 (by adding an empty object with trailing slash).\n",
        "\n",
        "        Args:\n",
        "            bucket_name (str): S3 bucket name\n",
        "            directory (str): Directory path to create\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Ensure the directory path ends with a slash\n",
        "            if not directory.endswith('/'):\n",
        "                directory += '/'\n",
        "\n",
        "            # Create an empty object with the directory name (S3 convention for directories)\n",
        "            self.s3_client.put_object(\n",
        "                Bucket=bucket_name,\n",
        "                Key=directory,\n",
        "                Body=''\n",
        "            )\n",
        "\n",
        "            print(f\"✅ Created S3 directory: s3://{bucket_name}/{directory}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error creating S3 directory: {str(e)}\")\n",
        "            return False"
      ],
      "metadata": {
        "id": "4dHSpcfu8LbV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataUtils:\n",
        "    \"\"\"Utility class for data loading and preprocessing operations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_data(s3_connector, bucket_name, key):\n",
        "        \"\"\"\n",
        "        Load data from S3 bucket.\n",
        "\n",
        "        Args:\n",
        "            s3_connector (S3Connector): S3 connector instance\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: Loaded data\n",
        "        \"\"\"\n",
        "        print(f\"Loading data from S3: s3://{bucket_name}/{key}\")\n",
        "        data = s3_connector.read_csv_from_s3(bucket_name, key)\n",
        "\n",
        "        if data is None:\n",
        "            print(f\"❌ Error loading data from S3\")\n",
        "            return None\n",
        "\n",
        "        print(f\"✅ Successfully loaded {len(data):,} records with {len(data.columns)} columns\")\n",
        "\n",
        "        # Display sample data\n",
        "        print(\"\\n📊 Data Preview:\")\n",
        "        print(data.head())\n",
        "\n",
        "        # Display data info\n",
        "        print(\"\\n📋 Data Information:\")\n",
        "        print(f\"Shape: {data.shape}\")\n",
        "        print(f\"Columns: {', '.join(data.columns)}\")\n",
        "        print(f\"Date range: {pd.to_datetime(data['date']).min()} to {pd.to_datetime(data['date']).max()}\")\n",
        "\n",
        "        # Check for missing values\n",
        "        missing_values = data.isnull().sum().sum()\n",
        "        print(f\"Missing values: {missing_values:,} ({missing_values/data.size:.2%} of all data)\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def create_output_dirs(output_dir):\n",
        "        \"\"\"\n",
        "        Create output directories for models and plots.\n",
        "\n",
        "        Args:\n",
        "            output_dir (str): Base output directory\n",
        "\n",
        "        Returns:\n",
        "            tuple: Paths to model registry and plots directories\n",
        "        \"\"\"\n",
        "        print(f\"Creating output directories in: {output_dir}\")\n",
        "\n",
        "        # Create main output directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Create subdirectories\n",
        "        model_registry_dir = os.path.join(output_dir, \"model_registry\")\n",
        "        plots_dir = os.path.join(output_dir, \"plots\")\n",
        "\n",
        "        os.makedirs(model_registry_dir, exist_ok=True)\n",
        "        os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"✅ Created directory structure:\")\n",
        "        print(f\"  - 📁 {output_dir} (main)\")\n",
        "        print(f\"  - 📁 {model_registry_dir} (models)\")\n",
        "        print(f\"  - 📁 {plots_dir} (visualizations)\")\n",
        "\n",
        "        return model_registry_dir, plots_dir\n"
      ],
      "metadata": {
        "id": "uCeTTdse8OGt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "    \"\"\"Class for preprocessing wheat price data.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the preprocessor.\"\"\"\n",
        "        self.date_col = None\n",
        "\n",
        "    def preprocess_retail_prices(self, raw_data):\n",
        "        \"\"\"\n",
        "        Preprocess retail price data.\n",
        "\n",
        "        Args:\n",
        "            raw_data (pandas.DataFrame): Raw input data\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: Preprocessed retail data\n",
        "        \"\"\"\n",
        "        print(\"Starting data preprocessing...\")\n",
        "\n",
        "        # Convert MSP from quintal to KG\n",
        "        if 'MSP_Wheat' in raw_data.columns:\n",
        "            raw_data['MSP_Wheat_KG'] = raw_data['MSP_Wheat'] / 100\n",
        "            print(\"Converted MSP from quintal to KG\")\n",
        "        else:\n",
        "            raw_data['MSP_Wheat_KG'] = 0\n",
        "            print(\"MSP_Wheat column not found, using 0 as default\")\n",
        "\n",
        "        # Keep only retail prices if price type available\n",
        "        if 'pricetype' in raw_data.columns:\n",
        "            df_retail = raw_data[raw_data['pricetype'].str.lower() == 'retail'].copy()\n",
        "            print(f\"Filtered {len(df_retail):,} retail price records\")\n",
        "        else:\n",
        "            df_retail = raw_data.copy()\n",
        "            print(f\"No price type column found. Using all {len(df_retail):,} records\")\n",
        "\n",
        "        # Initialize price_per_KG column\n",
        "        if 'price' in df_retail.columns:\n",
        "            df_retail['price_per_KG'] = df_retail['price']\n",
        "            print(\"Using 'price' column as price_per_KG\")\n",
        "        else:\n",
        "            df_retail['price_per_KG'] = 0\n",
        "            print(\"No price column found, using 0 as default\")\n",
        "\n",
        "        # Drop rows with missing state values\n",
        "        if 'state' in df_retail.columns:\n",
        "            pre_count = len(df_retail)\n",
        "            df_retail = df_retail[df_retail['state'].notna() & (df_retail['state'].str.strip() != '')]\n",
        "            dropped = pre_count - len(df_retail)\n",
        "            print(f\"Dropped {dropped:,} rows with missing states ({dropped/pre_count:.2%})\")\n",
        "            print(f\"Remaining records: {len(df_retail):,}\")\n",
        "\n",
        "        # Convert date to datetime\n",
        "        self.date_col = self._find_date_column(df_retail)\n",
        "\n",
        "        if self.date_col:\n",
        "            print(f\"Converting '{self.date_col}' to datetime\")\n",
        "            df_retail['date'] = pd.to_datetime(df_retail[self.date_col])\n",
        "        else:\n",
        "            print(\"❌ No date column found. Cannot proceed with time-based modeling\")\n",
        "            return None\n",
        "\n",
        "        # Extract time features\n",
        "        print(\"Extracting time features...\")\n",
        "        df_retail = self._add_time_features(df_retail)\n",
        "\n",
        "        # Sort for logical imputation order\n",
        "        df_retail = df_retail.sort_values(['state', 'date'])\n",
        "        print(\"Sorted data by state and date\")\n",
        "\n",
        "        # Handle missing values\n",
        "        print(\"Handling missing values...\")\n",
        "        df_retail = self._handle_missing_values(df_retail)\n",
        "\n",
        "        # Filter for wheat only if commodity column exists\n",
        "        if 'commodity' in df_retail.columns:\n",
        "            pre_count = len(df_retail)\n",
        "            wheat_data = df_retail[df_retail['commodity'].str.lower() == 'wheat'].copy()\n",
        "            print(f\"Filtered for wheat commodity: {len(wheat_data):,} records from {pre_count:,}\")\n",
        "        else:\n",
        "            wheat_data = df_retail.copy()\n",
        "            print(f\"No commodity column found. Using all {len(wheat_data):,} records\")\n",
        "\n",
        "        print(\"✅ Preprocessing complete\")\n",
        "\n",
        "        # Display summary statistics\n",
        "        print(\"\\n📊 Summary Statistics for Preprocessed Data:\")\n",
        "        print(wheat_data.describe())\n",
        "\n",
        "        return wheat_data\n",
        "\n",
        "    def _find_date_column(self, df):\n",
        "        \"\"\"Find the date column in the dataframe.\"\"\"\n",
        "        date_candidates = ['date', 'date_x', 'Date']\n",
        "        for col in date_candidates:\n",
        "            if col in df.columns:\n",
        "                return col\n",
        "        return None\n",
        "\n",
        "    def _add_time_features(self, df):\n",
        "        \"\"\"Add time-based features to the dataframe.\"\"\"\n",
        "        # Basic time components\n",
        "        df['year'] = df['date'].dt.year\n",
        "        df['month_num'] = df['date'].dt.month\n",
        "        df['day'] = df['date'].dt.day\n",
        "        df['quarter'] = df['date'].dt.quarter\n",
        "\n",
        "        # Cyclical time features - these capture seasonality better\n",
        "        df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
        "        df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
        "        df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)\n",
        "        df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)\n",
        "\n",
        "        print(\"Added time features: year, month, day, quarter\")\n",
        "        print(\"Added cyclical features: month_sin, month_cos, quarter_sin, quarter_cos\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _handle_missing_values(self, df):\n",
        "        \"\"\"Handle missing values in the dataframe.\"\"\"\n",
        "        # Fill Rainfall using state and month group mean\n",
        "        if 'Rainfall' in df.columns:\n",
        "            missing_before = df['Rainfall'].isna().sum()\n",
        "            df['Rainfall'] = df.groupby(['state', 'month_num'])['Rainfall'].transform(\n",
        "                lambda x: x.fillna(x.mean())\n",
        "            )\n",
        "            missing_after = df['Rainfall'].isna().sum()\n",
        "            print(f\"Filled {missing_before - missing_after:,} missing Rainfall values\")\n",
        "\n",
        "        # Fill diesel price forward within each state\n",
        "        if 'Diesel Price' in df.columns:\n",
        "            missing_before = df['Diesel Price'].isna().sum()\n",
        "            df['diesel_price'] = df.groupby('state')['Diesel Price'].ffill()\n",
        "            missing_after = df['diesel_price'].isna().sum()\n",
        "            print(f\"Filled {missing_before - missing_after:,} missing Diesel Price values\")\n",
        "\n",
        "        # Convert ROC columns to numeric and handle missing values\n",
        "        if 'Diesel ROC' in df.columns:\n",
        "            df['Diesel ROC'] = pd.to_numeric(df['Diesel ROC'], errors='coerce')\n",
        "            missing_before = df['Diesel ROC'].isna().sum()\n",
        "            df['Diesel ROC'].fillna(method='ffill', inplace=True)\n",
        "            missing_after = df['Diesel ROC'].isna().sum()\n",
        "            print(f\"Filled {missing_before - missing_after:,} missing Diesel ROC values\")\n",
        "\n",
        "        if 'Wheat ROC' in df.columns:\n",
        "            df['Wheat ROC'] = pd.to_numeric(df['Wheat ROC'], errors='coerce')\n",
        "            missing_before = df['Wheat ROC'].isna().sum()\n",
        "            df['Wheat ROC'].fillna(method='ffill', inplace=True)\n",
        "            missing_after = df['Wheat ROC'].isna().sum()\n",
        "            print(f\"Filled {missing_before - missing_after:,} missing Wheat ROC values\")\n",
        "\n",
        "        # Calculate price ratios if not already present\n",
        "        if 'diesel_price' in df.columns and 'price_per_KG' in df.columns:\n",
        "            df['Diesel / Wheat Price Ratio'] = df['diesel_price'] / df['price_per_KG'].replace(0, np.nan)\n",
        "            print(\"Calculated 'Diesel / Wheat Price Ratio'\")\n",
        "\n",
        "        # Report remaining missing values\n",
        "        missing_counts = df.isnull().sum()\n",
        "        if missing_counts.sum() > 0:\n",
        "            print(\"\\nRemaining missing values:\")\n",
        "            for col in missing_counts[missing_counts > 0].index:\n",
        "                print(f\"- {col}: {missing_counts[col]:,} missing values\")\n",
        "        else:\n",
        "            print(\"No missing values remain in the dataset\")\n",
        "\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "0s5DuQV48Q0V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer:\n",
        "    \"\"\"Class for feature engineering on time series data.\"\"\"\n",
        "\n",
        "    def engineer_features(self, df_state):\n",
        "        \"\"\"\n",
        "        Add time series features to the data.\n",
        "\n",
        "        Args:\n",
        "            df_state (pandas.DataFrame): State data with date index\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: Data with added features\n",
        "        \"\"\"\n",
        "        print(\"Adding time series features...\")\n",
        "\n",
        "        # Set date as index if not already\n",
        "        if not isinstance(df_state.index, pd.DatetimeIndex):\n",
        "            if 'date' in df_state.columns:\n",
        "                df_state = df_state.set_index('date', drop=False)\n",
        "                df_state = df_state.sort_index()\n",
        "                print(\"Set date as index and sorted data\")\n",
        "\n",
        "        # Add time lags for price\n",
        "        for lag in [1, 3, 6, 12]:  # 1, 3, 6, 12 month lags\n",
        "            lag_col = f'lag_{lag}m'\n",
        "            df_state[lag_col] = df_state['price_per_KG'].shift(lag)\n",
        "            print(f\"Added {lag_col} feature\")\n",
        "\n",
        "        # Add rolling statistics\n",
        "        for window in [3, 6]:\n",
        "            # Rolling mean\n",
        "            mean_col = f'rolling_mean_{window}m'\n",
        "            df_state[mean_col] = df_state['price_per_KG'].rolling(window=window).mean()\n",
        "            print(f\"Added {mean_col} feature\")\n",
        "\n",
        "            # Rolling std\n",
        "            std_col = f'rolling_std_{window}m'\n",
        "            df_state[std_col] = df_state['price_per_KG'].rolling(window=window).std()\n",
        "            print(f\"Added {std_col} feature\")\n",
        "\n",
        "        # Calculate rate of change\n",
        "        for period in [1, 3]:\n",
        "            roc_col = f'roc_{period}m'\n",
        "            df_state[roc_col] = df_state['price_per_KG'].pct_change(periods=period)\n",
        "            print(f\"Added {roc_col} feature\")\n",
        "\n",
        "        # Add MSP to retail price ratio\n",
        "        if 'MSP_Wheat_KG' in df_state.columns:\n",
        "            df_state['MSP_to_retail_ratio'] = df_state['MSP_Wheat_KG'] / df_state['price_per_KG']\n",
        "            print(\"Added MSP_to_retail_ratio feature\")\n",
        "\n",
        "        # Report on engineered features\n",
        "        feature_count = len(df_state.columns) - len(df_state.select_dtypes(include=['object']).columns)\n",
        "        print(f\"✅ Feature engineering complete. Dataset now has {feature_count} numeric features\")\n",
        "\n",
        "        # Display correlations with target\n",
        "        print(\"\\n📊 Correlation with price_per_KG:\")\n",
        "        # Select only numeric columns before calculating correlation\n",
        "        numeric_df_state = df_state.select_dtypes(include=['number'])\n",
        "        correlations = numeric_df_state.corr()['price_per_KG'].sort_values(ascending=False)\n",
        "        print(correlations.head(10))\n",
        "\n",
        "        return df_state\n"
      ],
      "metadata": {
        "id": "xSlCSASM8T-M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    \"\"\"Class for training and evaluating forecasting models.\"\"\"\n",
        "\n",
        "    def __init__(self, s3_connector, s3_bucket, output_prefix):\n",
        "        \"\"\"\n",
        "        Initialize the model trainer with S3 storage.\n",
        "\n",
        "        Args:\n",
        "            s3_connector (S3Connector): S3 connector instance\n",
        "            s3_bucket (str): S3 bucket for saving models and plots\n",
        "            output_prefix (str): Prefix path in the S3 bucket\n",
        "        \"\"\"\n",
        "        self.s3_connector = s3_connector\n",
        "        self.s3_bucket = s3_bucket\n",
        "        self.output_prefix = output_prefix\n",
        "        self.feature_cols = None\n",
        "\n",
        "        # Create S3 directory structure\n",
        "        self.model_registry_prefix = f\"{output_prefix}/model_registry\"\n",
        "        self.plots_prefix = f\"{output_prefix}/plots\"\n",
        "\n",
        "        # Ensure directories exist in S3\n",
        "        self.s3_connector.create_s3_directory(s3_bucket, self.model_registry_prefix)\n",
        "        self.s3_connector.create_s3_directory(s3_bucket, self.plots_prefix)\n",
        "\n",
        "        print(f\"✅ Set up S3 directory structure:\")\n",
        "        print(f\"  - 📁 s3://{s3_bucket}/{self.model_registry_prefix} (models)\")\n",
        "        print(f\"  - 📁 s3://{s3_bucket}/{self.plots_prefix} (visualizations)\")\n",
        "\n",
        "    def train_models_for_state(self, state, df_state, split_date):\n",
        "        \"\"\"\n",
        "        Train models for a specific state.\n",
        "\n",
        "        Args:\n",
        "            state (str): State name\n",
        "            df_state (pandas.DataFrame): Preprocessed data for the state\n",
        "            split_date (str): Date to split train/test data\n",
        "\n",
        "        Returns:\n",
        "            dict: State model results\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"📌 Processing state: {state.title()}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        try:\n",
        "            # Check if we have enough data\n",
        "            if len(df_state) < 24:  # Skip states with insufficient data\n",
        "                print(f\"⚠️ Skipping {state.title()} - insufficient data (only {len(df_state)} records)\")\n",
        "                return None\n",
        "\n",
        "            print(f\"Found {len(df_state):,} records for {state.title()}\")\n",
        "\n",
        "            # Define feature columns based on available columns\n",
        "            self.feature_cols = self._get_feature_columns(df_state)\n",
        "\n",
        "            # Prepare data for modeling\n",
        "            print(f\"Preparing train/test split using date {split_date}\")\n",
        "\n",
        "            # Split based on date\n",
        "            train_data = df_state[df_state.index < split_date].copy()\n",
        "            test_data = df_state[df_state.index >= split_date].copy()\n",
        "\n",
        "            print(f\"Train data: {len(train_data):,} records ({len(train_data)/len(df_state):.1%})\")\n",
        "            print(f\"Test data: {len(test_data):,} records ({len(test_data)/len(df_state):.1%})\")\n",
        "\n",
        "            # Drop rows with NaN values in key columns\n",
        "            train_data = train_data.dropna(subset=['price_per_KG'] +\n",
        "                                         [col for col in self.feature_cols if col in train_data.columns])\n",
        "            test_data = test_data.dropna(subset=['price_per_KG'] +\n",
        "                                        [col for col in self.feature_cols if col in test_data.columns])\n",
        "\n",
        "            print(f\"After dropping NaN values - Train: {len(train_data):,}, Test: {len(test_data):,}\")\n",
        "\n",
        "            if len(train_data) < 12 or len(test_data) < 4:\n",
        "                print(f\"⚠️ Skipping {state.title()} - insufficient data after cleaning\")\n",
        "                return None\n",
        "\n",
        "            # Feature scaling\n",
        "            scaler_features = StandardScaler()\n",
        "\n",
        "            # Extract features and target\n",
        "            X_train = pd.DataFrame(\n",
        "                scaler_features.fit_transform(train_data[self.feature_cols]),\n",
        "                columns=self.feature_cols,\n",
        "                index=train_data.index\n",
        "            )\n",
        "            y_train = train_data['price_per_KG'].values\n",
        "\n",
        "            X_test = pd.DataFrame(\n",
        "                scaler_features.transform(test_data[self.feature_cols]),\n",
        "                columns=self.feature_cols,\n",
        "                index=test_data.index\n",
        "            )\n",
        "            y_test = test_data['price_per_KG'].values\n",
        "\n",
        "            print(f\"Final feature matrix shapes - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "\n",
        "            # Train models\n",
        "            models = {}\n",
        "            model_metrics = {}\n",
        "\n",
        "            # 1. Random Forest\n",
        "            print(\"\\n🔹 Training Random Forest model...\")\n",
        "            rf_model, rf_metrics, rf_importance = self._train_random_forest(X_train, y_train, X_test, y_test)\n",
        "            models['random_forest'] = rf_model\n",
        "            model_metrics['random_forest'] = rf_metrics\n",
        "\n",
        "            # 2. XGBoost\n",
        "            print(\"\\n🔹 Training XGBoost model...\")\n",
        "            xgb_model, xgb_metrics, xgb_importance = self._train_xgboost(X_train, y_train, X_test, y_test)\n",
        "            models['xgboost'] = xgb_model\n",
        "            model_metrics['xgboost'] = xgb_metrics\n",
        "\n",
        "            # 3. Holt-Winters\n",
        "            print(\"\\n🔹 Training Holt-Winters model...\")\n",
        "            hw_fit, hw_metrics = self._train_holt_winters(train_data, test_data)\n",
        "\n",
        "            if hw_fit is not None:\n",
        "                models['holt_winters'] = hw_fit\n",
        "                model_metrics['holt_winters'] = hw_metrics\n",
        "\n",
        "            # Determine best model\n",
        "            print(\"\\n🔹 Determining best model...\")\n",
        "            best_model_name = min(model_metrics, key=lambda x: model_metrics[x]['test_rmse'])\n",
        "            best_model = models[best_model_name]\n",
        "            best_metrics = model_metrics[best_model_name]\n",
        "\n",
        "            print(f\"Best model for {state.title()}: {best_model_name}\")\n",
        "            print(f\"Best model metrics:\")\n",
        "            for metric, value in best_metrics.items():\n",
        "                print(f\"   - {metric}: {value:.4f}\")\n",
        "\n",
        "            # Create visualizations and save directly to S3\n",
        "            self._create_forecast_visualization(\n",
        "                state,\n",
        "                train_data,\n",
        "                test_data,\n",
        "                models,\n",
        "                best_model_name,\n",
        "                split_date\n",
        "            )\n",
        "\n",
        "            # Save all models directly to S3\n",
        "            state_model_prefix = f\"{self.model_registry_prefix}/{state}\"\n",
        "            self.s3_connector.create_s3_directory(self.s3_bucket, state_model_prefix)\n",
        "\n",
        "            for model_name, model in models.items():\n",
        "                s3_model_key = f\"{state_model_prefix}/{model_name}.pkl\"\n",
        "                self.s3_connector.save_pickle_to_s3(model, self.s3_bucket, s3_model_key)\n",
        "                print(f\"Saved {model_name} model to s3://{self.s3_bucket}/{s3_model_key}\")\n",
        "\n",
        "            # Save best model separately\n",
        "            best_model_key = f\"{self.model_registry_prefix}/{state}_best_model.pkl\"\n",
        "            self.s3_connector.save_pickle_to_s3(best_model, self.s3_bucket, best_model_key)\n",
        "            print(f\"Saved best model ({best_model_name}) to s3://{self.s3_bucket}/{best_model_key}\")\n",
        "\n",
        "            # Store feature importance data\n",
        "            if best_model_name == 'random_forest':\n",
        "                importance_data = rf_importance\n",
        "            elif best_model_name == 'xgboost':\n",
        "                importance_data = xgb_importance\n",
        "            else:\n",
        "                importance_data = None\n",
        "\n",
        "            # Create result structure with S3 paths instead of local paths\n",
        "            result = {\n",
        "                'best_model': best_model_name,\n",
        "                'model': best_model,\n",
        "                'metrics': best_metrics,\n",
        "                'feature_importance': importance_data.to_dict() if importance_data is not None else None,\n",
        "                'model_s3_path': f\"s3://{self.s3_bucket}/{best_model_key}\"\n",
        "            }\n",
        "\n",
        "            print(f\"✅ Successfully processed {state.title()}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing state {state}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def _get_feature_columns(self, df):\n",
        "        \"\"\"Get feature columns that exist in the dataframe.\"\"\"\n",
        "        all_feature_cols = [\n",
        "            # Economic indicators\n",
        "            'MSP_Wheat_KG', 'CPI', 'diesel_price',\n",
        "            'Diesel ROC', 'Wheat ROC', 'Diesel / Wheat Price Ratio',\n",
        "\n",
        "            # External factors\n",
        "            'Rainfall',\n",
        "\n",
        "            # Time components\n",
        "            'year', 'month_num', 'quarter',\n",
        "            'month_sin', 'month_cos', 'quarter_sin', 'quarter_cos',\n",
        "\n",
        "            # Lagged features\n",
        "            'lag_1m', 'lag_3m', 'lag_6m', 'lag_12m',\n",
        "\n",
        "            # Rolling statistics\n",
        "            'rolling_mean_3m', 'rolling_mean_6m',\n",
        "            'rolling_std_3m', 'rolling_std_6m',\n",
        "\n",
        "            # Rate of change\n",
        "            'roc_1m', 'roc_3m',\n",
        "\n",
        "            # Price ratios\n",
        "            'MSP_to_retail_ratio'\n",
        "        ]\n",
        "\n",
        "        # Filter to columns that exist in the dataframe\n",
        "        feature_cols = [col for col in all_feature_cols if col in df.columns]\n",
        "        print(f\"Using {len(feature_cols)} features: {', '.join(feature_cols)}\")\n",
        "\n",
        "        return feature_cols\n",
        "\n",
        "    def _train_random_forest(self, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"Train and evaluate Random Forest model.\"\"\"\n",
        "        rf_params = {\n",
        "            'n_estimators': 200,\n",
        "            'max_depth': 15,\n",
        "            'min_samples_split': 5,\n",
        "            'random_state': 42,\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "\n",
        "        print(f\"RF Parameters: {rf_params}\")\n",
        "\n",
        "        # Train model\n",
        "        rf_model = RandomForestRegressor(**rf_params)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        train_pred_rf = rf_model.predict(X_train)\n",
        "        test_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "        rf_metrics = self._calculate_metrics(y_train, train_pred_rf, y_test, test_pred_rf)\n",
        "\n",
        "        # Get feature importance\n",
        "        feature_importance_rf = pd.DataFrame({\n",
        "            'Feature': X_train.columns,\n",
        "            'Importance': rf_model.feature_importances_\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "\n",
        "        print(f\"Random Forest metrics - Test RMSE: {rf_metrics['test_rmse']:.4f}, R²: {rf_metrics['test_r2']:.4f}\")\n",
        "        print(f\"Top 5 important features:\")\n",
        "        for i, row in feature_importance_rf.head(5).iterrows():\n",
        "            print(f\"   - {row['Feature']}: {row['Importance']:.4f}\")\n",
        "\n",
        "        return rf_model, rf_metrics, feature_importance_rf\n",
        "\n",
        "    def _train_xgboost(self, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"Train and evaluate XGBoost model.\"\"\"\n",
        "        xgb_params = {\n",
        "            'n_estimators': 1000,\n",
        "            'learning_rate': 0.03,\n",
        "            'max_depth': 6,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'subsample': 0.9,\n",
        "            'gamma': 0.1,\n",
        "            'reg_alpha': 0.1,\n",
        "            'reg_lambda': 0.5,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"XGBoost Parameters: {xgb_params}\")\n",
        "\n",
        "        # Train model\n",
        "        xgb_model = xgb.XGBRegressor(**xgb_params)\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        train_pred_xgb = xgb_model.predict(X_train)\n",
        "        test_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "        xgb_metrics = self._calculate_metrics(y_train, train_pred_xgb, y_test, test_pred_xgb)\n",
        "\n",
        "        # Get feature importance\n",
        "        feature_importance_xgb = pd.DataFrame({\n",
        "            'Feature': X_train.columns,\n",
        "            'Importance': xgb_model.feature_importances_\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "\n",
        "        print(f\"XGBoost metrics - Test RMSE: {xgb_metrics['test_rmse']:.4f}, R²: {xgb_metrics['test_r2']:.4f}\")\n",
        "        print(f\"Top 5 important features:\")\n",
        "        for i, row in feature_importance_xgb.head(5).iterrows():\n",
        "            print(f\"   - {row['Feature']}: {row['Importance']:.4f}\")\n",
        "\n",
        "        return xgb_model, xgb_metrics, feature_importance_xgb\n",
        "\n",
        "    def _train_holt_winters(self, train_data, test_data):\n",
        "        \"\"\"Train and evaluate Holt-Winters model.\"\"\"\n",
        "        # Convert to pandas Series with datetime index\n",
        "        train_series = pd.Series(train_data['price_per_KG'].values, index=train_data.index)\n",
        "        test_series = pd.Series(test_data['price_per_KG'].values, index=test_data.index)\n",
        "\n",
        "        hw_params = {\n",
        "            'trend': 'add',\n",
        "            'seasonal': 'mul',\n",
        "            'seasonal_periods': 12  # Monthly data with yearly seasonality\n",
        "        }\n",
        "\n",
        "        print(f\"Holt-Winters Parameters: {hw_params}\")\n",
        "\n",
        "        try:\n",
        "            # Create and fit model\n",
        "            hw_model = ExponentialSmoothing(train_series, **hw_params)\n",
        "            hw_fit = hw_model.fit()\n",
        "\n",
        "            # Make predictions\n",
        "            hw_train_pred = hw_fit.fittedvalues\n",
        "            hw_test_pred = hw_fit.forecast(steps=len(test_series))\n",
        "\n",
        "            # Align indices\n",
        "            hw_test_pred.index = test_series.index\n",
        "\n",
        "            # Calculate metrics\n",
        "            hw_train_rmse = np.sqrt(mean_squared_error(train_series, hw_train_pred))\n",
        "            hw_test_rmse = np.sqrt(mean_squared_error(test_series, hw_test_pred))\n",
        "            hw_train_mae = mean_absolute_error(train_series, hw_train_pred)\n",
        "            hw_test_mae = mean_absolute_error(test_series, hw_test_pred)\n",
        "\n",
        "            # Avoid division by zero in MAPE\n",
        "            hw_train_mape = np.mean(np.abs((train_series - hw_train_pred) /\n",
        "                                          np.maximum(0.01, np.abs(train_series)))) * 100\n",
        "            hw_test_mape = np.mean(np.abs((test_series - hw_test_pred) /\n",
        "                                         np.maximum(0.01, np.abs(test_series)))) * 100\n",
        "\n",
        "            # Calculate R² if possible\n",
        "            try:\n",
        "                hw_train_r2 = r2_score(train_series, hw_train_pred)\n",
        "                hw_test_r2 = r2_score(test_series, hw_test_pred)\n",
        "            except:\n",
        "                hw_train_r2 = np.nan\n",
        "                hw_test_r2 = np.nan\n",
        "\n",
        "            hw_metrics = {\n",
        "                'train_rmse': hw_train_rmse,\n",
        "                'test_rmse': hw_test_rmse,\n",
        "                'train_mae': hw_train_mae,\n",
        "                'test_mae': hw_test_mae,\n",
        "                'train_mape': hw_train_mape,\n",
        "                'test_mape': hw_test_mape,\n",
        "                'train_r2': hw_train_r2,\n",
        "                'test_r2': hw_test_r2\n",
        "            }\n",
        "\n",
        "            print(f\"Holt-Winters metrics - Test RMSE: {hw_test_rmse:.4f}\")\n",
        "\n",
        "            return hw_fit, hw_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error training Holt-Winters model: {str(e)}\")\n",
        "            return None, None\n",
        "\n",
        "    def _calculate_metrics(self, y_train, train_pred, y_test, test_pred):\n",
        "        \"\"\"Calculate common evaluation metrics.\"\"\"\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "        train_mae = mean_absolute_error(y_train, train_pred)\n",
        "        test_mae = mean_absolute_error(y_test, test_pred)\n",
        "        train_r2 = r2_score(y_train, train_pred)\n",
        "        test_r2 = r2_score(y_test, test_pred)\n",
        "\n",
        "        # Avoid division by zero in MAPE\n",
        "        train_mape = np.mean(np.abs((y_train - train_pred) / np.maximum(0.01, np.abs(y_train)))) * 100\n",
        "        test_mape = np.mean(np.abs((y_test - test_pred) / np.maximum(0.01, np.abs(y_test)))) * 100\n",
        "\n",
        "        metrics = {\n",
        "            'train_rmse': train_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'train_mae': train_mae,\n",
        "            'test_mae': test_mae,\n",
        "            'train_mape': train_mape,\n",
        "            'test_mape': test_mape,\n",
        "            'train_r2': train_r2,\n",
        "            'test_r2': test_r2\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _create_forecast_visualization(self, state, train_data, test_data, models, best_model_name, split_date):\n",
        "        \"\"\"Create visualization of model forecasts and save directly to S3.\"\"\"\n",
        "        print(\"\\n🔹 Creating visualization...\")\n",
        "\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Plot actual prices\n",
        "        plt.plot(train_data.index, train_data['price_per_KG'], 'b-',\n",
        "                 label='Actual (Train)', alpha=0.7, linewidth=2)\n",
        "        plt.plot(test_data.index, test_data['price_per_KG'], 'k-',\n",
        "                 label='Actual (Test)', alpha=0.7, linewidth=2)\n",
        "\n",
        "        # Plot best model predictions\n",
        "        if best_model_name == 'holt_winters':\n",
        "            hw_fit = models['holt_winters']\n",
        "            hw_train_pred = hw_fit.fittedvalues\n",
        "            hw_test_pred = hw_fit.forecast(steps=len(test_data))\n",
        "            hw_test_pred.index = test_data.index\n",
        "\n",
        "            plt.plot(hw_train_pred.index, hw_train_pred, 'g--',\n",
        "                     label=f'Predicted (Train - {best_model_name})', alpha=0.7, linewidth=2)\n",
        "            plt.plot(hw_test_pred.index, hw_test_pred, 'r--',\n",
        "                     label=f'Predicted (Test - {best_model_name})', alpha=0.7, linewidth=2)\n",
        "        else:\n",
        "            # For RF and XGB, calculate predictions\n",
        "            X_train = train_data[self.feature_cols]\n",
        "            X_test = test_data[self.feature_cols]\n",
        "\n",
        "            best_model = models[best_model_name]\n",
        "            train_pred = best_model.predict(X_train)\n",
        "            test_pred = best_model.predict(X_test)\n",
        "\n",
        "            plt.plot(train_data.index, train_pred, 'g--',\n",
        "                     label=f'Predicted (Train - {best_model_name})', alpha=0.7, linewidth=2)\n",
        "            plt.plot(test_data.index, test_pred, 'r--',\n",
        "                     label=f'Predicted (Test - {best_model_name})', alpha=0.7, linewidth=2)\n",
        "\n",
        "        # Add chart elements\n",
        "        plt.title(f'Wheat Price Forecast for {state.title()} - {best_model_name.title()}', fontsize=16)\n",
        "        plt.xlabel('Date', fontsize=14)\n",
        "        plt.ylabel('Price per KG (₹)', fontsize=14)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend(loc='best', fontsize=12)\n",
        "\n",
        "        # Add vertical line for train/test split\n",
        "        plt.axvline(pd.to_datetime(split_date), color='gray', linestyle='--', alpha=0.7)\n",
        "        plt.text(pd.to_datetime(split_date), plt.ylim()[0], 'Train-Test Split',\n",
        "                 rotation=90, verticalalignment='bottom', fontsize=12)\n",
        "\n",
        "        # Format plot\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save the plot directly to S3\n",
        "        s3_plot_key = f\"{self.plots_prefix}/{state}_forecast.png\"\n",
        "        self.s3_connector.save_figure_to_s3(plt.gcf(), self.s3_bucket, s3_plot_key)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"✅ Saved visualization to s3://{self.s3_bucket}/{s3_plot_key}\")\n",
        "\n",
        "        # Create feature importance plot if applicable\n",
        "        if best_model_name in ['random_forest', 'xgboost']:\n",
        "            self._create_feature_importance_plot(state, best_model_name, models[best_model_name], self.feature_cols)\n",
        "\n",
        "\n",
        "    def _create_feature_importance_plot(self, state, model_name, model, feature_cols):\n",
        "          \"\"\"Create feature importance visualization and save directly to S3.\"\"\"\n",
        "          # Get feature importances\n",
        "          importances = model.feature_importances_\n",
        "\n",
        "          # Create DataFrame of feature importances\n",
        "          feature_importance = pd.DataFrame({\n",
        "              'Feature': feature_cols,\n",
        "              'Importance': importances\n",
        "          }).sort_values('Importance', ascending=False)\n",
        "\n",
        "          # Create plot\n",
        "          plt.figure(figsize=(12, 8))\n",
        "\n",
        "          # Plot horizontal bar chart\n",
        "          sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15), palette='viridis')\n",
        "\n",
        "          # Add chart elements\n",
        "          plt.title(f'Top 15 Feature Importances for {state.title()} - {model_name.title()}', fontsize=16)\n",
        "          plt.xlabel('Importance', fontsize=14)\n",
        "          plt.ylabel('Feature', fontsize=14)\n",
        "          plt.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "          # Format plot\n",
        "          plt.tight_layout()\n",
        "\n",
        "          # Save the plot directly to S3\n",
        "          s3_plot_key = f\"{self.plots_prefix}/{state}_{model_name}_importance.png\"\n",
        "          self.s3_connector.save_figure_to_s3(plt.gcf(), self.s3_bucket, s3_plot_key)\n",
        "          plt.close()\n",
        "\n",
        "          print(f\"✅ Saved feature importance plot to s3://{self.s3_bucket}/{s3_plot_key}\")\n",
        "\n",
        "          # Also save the feature importance data as JSON\n",
        "          importance_data = feature_importance.to_dict('records')\n",
        "          s3_importance_key = f\"{self.plots_prefix}/{state}_{model_name}_importance.json\"\n",
        "          self.s3_connector.save_data_to_s3(\n",
        "              importance_data,\n",
        "              self.s3_bucket,\n",
        "              s3_importance_key,\n",
        "              content_type='application/json'\n",
        "          )\n",
        "          print(f\"✅ Saved feature importance data to s3://{self.s3_bucket}/{s3_importance_key}\")\n"
      ],
      "metadata": {
        "id": "U3malv2C8WbM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelAggregator:\n",
        "    \"\"\"Class for aggregating models across all states.\"\"\"\n",
        "\n",
        "    def __init__(self, s3_connector, s3_bucket, output_prefix):\n",
        "        \"\"\"\n",
        "        Initialize the model aggregator with S3 storage.\n",
        "\n",
        "        Args:\n",
        "            s3_connector (S3Connector): S3 connector instance\n",
        "            s3_bucket (str): S3 bucket for saving models\n",
        "            output_prefix (str): Prefix path in the S3 bucket\n",
        "        \"\"\"\n",
        "        self.s3_connector = s3_connector\n",
        "        self.s3_bucket = s3_bucket\n",
        "        self.output_prefix = output_prefix\n",
        "\n",
        "    def aggregate_models(self, all_states_models, feature_cols):\n",
        "        \"\"\"\n",
        "        Combine all state models into a single file with metadata and save to S3.\n",
        "\n",
        "        Args:\n",
        "            all_states_models (dict): Dictionary of state-model mappings\n",
        "            feature_cols (list): Feature columns used in modeling\n",
        "\n",
        "        Returns:\n",
        "            str: S3 path to the combined model file\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"📦 Aggregating models across all states to S3\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Filter out None values\n",
        "        valid_models = {state: data for state, data in all_states_models.items() if data is not None}\n",
        "\n",
        "        print(f\"Aggregating models for {len(valid_models)}/{len(all_states_models)} states\")\n",
        "\n",
        "        # Create metadata\n",
        "        metadata = {\n",
        "            'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'states_included': list(valid_models.keys()),\n",
        "            'total_states': len(valid_models),\n",
        "            'model_details': {\n",
        "                state: {\n",
        "                    'best_model': data['best_model'],\n",
        "                    'metrics': data['metrics'],\n",
        "                    'feature_importance': data['feature_importance'],\n",
        "                    's3_model_path': data.get('model_s3_path', f\"s3://{self.s3_bucket}/{self.output_prefix}/model_registry/{state}_best_model.pkl\")\n",
        "                } for state, data in valid_models.items()\n",
        "            },\n",
        "            'feature_cols': feature_cols\n",
        "        }\n",
        "\n",
        "        # Create combined data structure\n",
        "        combined_data = {\n",
        "            'models': {state: data['model'] for state, data in valid_models.items()},\n",
        "            'metadata': metadata\n",
        "        }\n",
        "\n",
        "        # Generate S3 paths with timestamp\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "        # Save the combined model directly to S3\n",
        "        s3_combined_key = f\"{self.output_prefix}/models/all_states_best_model_{timestamp}.pkl\"\n",
        "        s3_latest_key = f\"{self.output_prefix}/models/all_states_best_model_latest.pkl\"\n",
        "        s3_metadata_key = f\"{self.output_prefix}/models/all_states_metadata_{timestamp}.json\"\n",
        "\n",
        "        # Save combined model to S3\n",
        "        model_saved = self.s3_connector.save_pickle_to_s3(\n",
        "            combined_data,\n",
        "            self.s3_bucket,\n",
        "            s3_combined_key\n",
        "        )\n",
        "\n",
        "        if model_saved:\n",
        "            print(f\"✅ Saved combined model to S3: s3://{self.s3_bucket}/{s3_combined_key}\")\n",
        "\n",
        "            # Save a copy as \"latest\" version\n",
        "            self.s3_connector.save_pickle_to_s3(\n",
        "                combined_data,\n",
        "                self.s3_bucket,\n",
        "                s3_latest_key\n",
        "            )\n",
        "            print(f\"✅ Saved latest version to S3: s3://{self.s3_bucket}/{s3_latest_key}\")\n",
        "\n",
        "            # Save metadata as JSON\n",
        "            self.s3_connector.save_data_to_s3(\n",
        "                metadata,\n",
        "                self.s3_bucket,\n",
        "                s3_metadata_key,\n",
        "                content_type='application/json'\n",
        "            )\n",
        "            print(f\"✅ Saved metadata to S3: s3://{self.s3_bucket}/{s3_metadata_key}\")\n",
        "        else:\n",
        "            print(f\"❌ Failed to save combined model to S3\")\n",
        "\n",
        "        # Return the S3 path\n",
        "        combined_s3_path = f\"s3://{self.s3_bucket}/{s3_combined_key}\"\n",
        "        return combined_s3_path\n",
        "\n",
        "    def print_summary_table(self, all_states_models):\n",
        "        \"\"\"\n",
        "        Print a summary table of model results.\n",
        "\n",
        "        Args:\n",
        "            all_states_models (dict): Dictionary of state-model mappings\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"📊 Summary of Results\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Filter out None values\n",
        "        valid_models = {state: data for state, data in all_states_models.items() if data is not None}\n",
        "\n",
        "        # Print header\n",
        "        print(f\"{'State':<20} {'Best Model':<15} {'Test RMSE':<12} {'Test MAPE':<12} {'R²':<8}\")\n",
        "        print(f\"{'-'*80}\")\n",
        "\n",
        "        # Print each state's results\n",
        "        for state, details in sorted(valid_models.items()):\n",
        "            rmse = details['metrics'].get('test_rmse', 'N/A')\n",
        "            mape = details['metrics'].get('test_mape', 'N/A')\n",
        "            r2 = details['metrics'].get('test_r2', 'N/A')\n",
        "\n",
        "            rmse_str = f\"{rmse:.4f}\" if isinstance(rmse, (int, float)) else rmse\n",
        "            mape_str = f\"{mape:.2f}%\" if isinstance(mape, (int, float)) else mape\n",
        "            r2_str = f\"{r2:.4f}\" if isinstance(r2, (int, float)) else r2\n",
        "\n",
        "            print(f\"{state.title():<20} {details['best_model']:<15} {rmse_str:<12} {mape_str:<12} {r2_str:<8}\")\n",
        "\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"✅ Successfully processed {len(valid_models)}/{len(all_states_models)} states\")"
      ],
      "metadata": {
        "id": "2iPpEQxW9GKd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelAggregator:\n",
        "    \"\"\"Class for aggregating models across all states.\"\"\"\n",
        "\n",
        "    def __init__(self, s3_connector, s3_bucket, output_prefix):\n",
        "        \"\"\"\n",
        "        Initialize the model aggregator with S3 storage.\n",
        "\n",
        "        Args:\n",
        "            s3_connector (S3Connector): S3 connector instance\n",
        "            s3_bucket (str): S3 bucket for saving models\n",
        "            output_prefix (str): Prefix path in the S3 bucket\n",
        "        \"\"\"\n",
        "        self.s3_connector = s3_connector\n",
        "        self.s3_bucket = s3_bucket\n",
        "        self.output_prefix = output_prefix\n",
        "\n",
        "    def aggregate_models(self, all_states_models, feature_cols):\n",
        "        \"\"\"\n",
        "        Combine all state models into a single file with metadata and save to S3.\n",
        "\n",
        "        Args:\n",
        "            all_states_models (dict): Dictionary of state-model mappings\n",
        "            feature_cols (list): Feature columns used in modeling\n",
        "\n",
        "        Returns:\n",
        "            str: S3 path to the combined model file\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"📦 Aggregating models across all states to S3\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Filter out None values\n",
        "        valid_models = {state: data for state, data in all_states_models.items() if data is not None}\n",
        "\n",
        "        print(f\"Aggregating models for {len(valid_models)}/{len(all_states_models)} states\")\n",
        "\n",
        "        # Create metadata\n",
        "        metadata = {\n",
        "            'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'states_included': list(valid_models.keys()),\n",
        "            'total_states': len(valid_models),\n",
        "            'model_details': {\n",
        "                state: {\n",
        "                    'best_model': data['best_model'],\n",
        "                    'metrics': data['metrics'],\n",
        "                    'feature_importance': data['feature_importance'],\n",
        "                    's3_model_path': data.get('model_s3_path', f\"s3://{self.s3_bucket}/{self.output_prefix}/model_registry/{state}_best_model.pkl\")\n",
        "                } for state, data in valid_models.items()\n",
        "            },\n",
        "            'feature_cols': feature_cols\n",
        "        }\n",
        "\n",
        "        # Create combined data structure\n",
        "        combined_data = {\n",
        "            'models': {state: data['model'] for state, data in valid_models.items()},\n",
        "            'metadata': metadata\n",
        "        }\n",
        "\n",
        "        # Generate S3 paths with timestamp\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "        # Save the combined model directly to S3\n",
        "        s3_combined_key = f\"{self.output_prefix}/models/all_states_best_model_{timestamp}.pkl\"\n",
        "        s3_latest_key = f\"{self.output_prefix}/models/all_states_best_model_latest.pkl\"\n",
        "        s3_metadata_key = f\"{self.output_prefix}/models/all_states_metadata_{timestamp}.json\"\n",
        "\n",
        "        # Save combined model to S3\n",
        "        model_saved = self.s3_connector.save_pickle_to_s3(\n",
        "            combined_data,\n",
        "            self.s3_bucket,\n",
        "            s3_combined_key\n",
        "        )\n",
        "\n",
        "        if model_saved:\n",
        "            print(f\"✅ Saved combined model to S3: s3://{self.s3_bucket}/{s3_combined_key}\")\n",
        "\n",
        "            # Save a copy as \"latest\" version\n",
        "            self.s3_connector.save_pickle_to_s3(\n",
        "                combined_data,\n",
        "                self.s3_bucket,\n",
        "                s3_latest_key\n",
        "            )\n",
        "            print(f\"✅ Saved latest version to S3: s3://{self.s3_bucket}/{s3_latest_key}\")\n",
        "\n",
        "            # Save metadata as JSON\n",
        "            self.s3_connector.save_data_to_s3(\n",
        "                metadata,\n",
        "                self.s3_bucket,\n",
        "                s3_metadata_key,\n",
        "                content_type='application/json'\n",
        "            )\n",
        "            print(f\"✅ Saved metadata to S3: s3://{self.s3_bucket}/{s3_metadata_key}\")\n",
        "        else:\n",
        "            print(f\"❌ Failed to save combined model to S3\")\n",
        "\n",
        "        # Return the S3 path\n",
        "        combined_s3_path = f\"s3://{self.s3_bucket}/{s3_combined_key}\"\n",
        "        return combined_s3_path\n",
        "\n",
        "    def print_summary_table(self, all_states_models):\n",
        "        \"\"\"\n",
        "        Print a summary table of model results.\n",
        "\n",
        "        Args:\n",
        "            all_states_models (dict): Dictionary of state-model mappings\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"📊 Summary of Results\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Filter out None values\n",
        "        valid_models = {state: data for state, data in all_states_models.items() if data is not None}\n",
        "\n",
        "        # Print header\n",
        "        print(f\"{'State':<20} {'Best Model':<15} {'Test RMSE':<12} {'Test MAPE':<12} {'R²':<8}\")\n",
        "        print(f\"{'-'*80}\")\n",
        "\n",
        "        # Print each state's results\n",
        "        for state, details in sorted(valid_models.items()):\n",
        "            rmse = details['metrics'].get('test_rmse', 'N/A')\n",
        "            mape = details['metrics'].get('test_mape', 'N/A')\n",
        "            r2 = details['metrics'].get('test_r2', 'N/A')\n",
        "\n",
        "            rmse_str = f\"{rmse:.4f}\" if isinstance(rmse, (int, float)) else rmse\n",
        "            mape_str = f\"{mape:.2f}%\" if isinstance(mape, (int, float)) else mape\n",
        "            r2_str = f\"{r2:.4f}\" if isinstance(r2, (int, float)) else r2\n",
        "\n",
        "            print(f\"{state.title():<20} {details['best_model']:<15} {rmse_str:<12} {mape_str:<12} {r2_str:<8}\")\n",
        "\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"✅ Successfully processed {len(valid_models)}/{len(all_states_models)} states\")\n",
        "\n",
        "\n",
        "class WheatPriceForecaster:\n",
        "    \"\"\"Main class for wheat price forecasting process with S3 storage.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 s3_bucket,\n",
        "                 s3_key,\n",
        "                 output_prefix=\"wheat_forecaster\",\n",
        "                 split_date=\"2020-01-01\",\n",
        "                 mlflow_uri=None,\n",
        "                 aws_access_key_id=None,\n",
        "                 aws_secret_access_key=None,\n",
        "                 aws_region='us-east-1'):\n",
        "        \"\"\"\n",
        "        Initialize the wheat price forecasting process with S3 data source and storage.\n",
        "\n",
        "        Args:\n",
        "            s3_bucket (str): S3 bucket containing the CSV data file and for storing outputs\n",
        "            s3_key (str): S3 key (path) to the CSV data file\n",
        "            output_prefix (str): Prefix path in the S3 bucket for all outputs\n",
        "            split_date (str): Date to split train/test data\n",
        "            mlflow_uri (str, optional): MLflow tracking URI\n",
        "            aws_access_key_id (str, optional): AWS access key ID\n",
        "            aws_secret_access_key (str, optional): AWS secret access key\n",
        "            aws_region (str, optional): AWS region name\n",
        "        \"\"\"\n",
        "        self.s3_bucket = s3_bucket\n",
        "        self.s3_key = s3_key\n",
        "        self.output_prefix = output_prefix\n",
        "        self.split_date = split_date\n",
        "        self.mlflow_uri = mlflow_uri\n",
        "\n",
        "        # Initialize S3 connector\n",
        "        self.s3_connector = S3Connector(\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key,\n",
        "            region_name=aws_region\n",
        "        )\n",
        "\n",
        "        # Initialize other attributes\n",
        "        self.raw_data = None\n",
        "        self.wheat_data = None\n",
        "        self.all_states = None\n",
        "        self.all_state_models = {}\n",
        "        self.feature_cols = None\n",
        "\n",
        "        # Print initialization information\n",
        "        print(f\"🚀 Initializing Wheat Price Forecaster with S3 storage\")\n",
        "        print(f\"📄 Input file: s3://{self.s3_bucket}/{self.s3_key}\")\n",
        "        print(f\"📁 Output location: s3://{self.s3_bucket}/{self.output_prefix}/\")\n",
        "        print(f\"📅 Train/Test split date: {self.split_date}\")\n",
        "        if self.mlflow_uri:\n",
        "            print(f\"📊 MLflow tracking URI: {self.mlflow_uri}\")\n",
        "\n",
        "            # Set up MLflow if provided\n",
        "            import mlflow\n",
        "            mlflow.set_tracking_uri(self.mlflow_uri)\n",
        "\n",
        "    def run_full_process(self):\n",
        "        \"\"\"Run the complete wheat price forecasting process with S3 storage.\"\"\"\n",
        "        # Step 1: Create S3 directory structure\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Step 1: Setting up S3 directory structure\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Create S3 directory structure\n",
        "        self.s3_connector.create_s3_directory(self.s3_bucket, f\"{self.output_prefix}/\")\n",
        "        self.s3_connector.create_s3_directory(self.s3_bucket, f\"{self.output_prefix}/model_registry/\")\n",
        "        self.s3_connector.create_s3_directory(self.s3_bucket, f\"{self.output_prefix}/plots/\")\n",
        "        self.s3_connector.create_s3_directory(self.s3_bucket, f\"{self.output_prefix}/models/\")\n",
        "\n",
        "        print(f\"✅ Created S3 directory structure in s3://{self.s3_bucket}/{self.output_prefix}/\")\n",
        "\n",
        "        # Step 2: Load data from S3\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Step 2: Loading data from S3\")\n",
        "        print(\"=\"*80)\n",
        "        self.raw_data = self.s3_connector.read_csv_from_s3(self.s3_bucket, self.s3_key)\n",
        "        if self.raw_data is None:\n",
        "            print(\"❌ Failed to load data from S3. Exiting process.\")\n",
        "            return None\n",
        "\n",
        "        # Step 3: Preprocess data\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Step 3: Preprocessing data\")\n",
        "        print(\"=\"*80)\n",
        "        preprocessor = DataPreprocessor()\n",
        "        self.wheat_data = preprocessor.preprocess_retail_prices(self.raw_data)\n",
        "        if self.wheat_data is None:\n",
        "            print(\"❌ Preprocessing failed. Exiting process.\")\n",
        "            return None\n",
        "\n",
        "        # Get all states\n",
        "        self.all_states = self.wheat_data['state'].str.lower().unique().tolist()\n",
        "        print(f\"\\nFound {len(self.all_states)} states with wheat price data:\")\n",
        "        for i, state in enumerate(self.all_states):\n",
        "            print(f\"   {i+1}. {state.title()}\")\n",
        "\n",
        "        # Step 4: Process each state\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Step 4: Processing individual states\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        feature_engineer = FeatureEngineer()\n",
        "        model_trainer = ModelTrainer(\n",
        "            s3_connector=self.s3_connector,\n",
        "            s3_bucket=self.s3_bucket,\n",
        "            output_prefix=self.output_prefix\n",
        "        )\n",
        "\n",
        "        for state_idx, state in enumerate(self.all_states):\n",
        "            print(f\"\\nProcessing state {state_idx+1}/{len(self.all_states)}: {state.title()}\")\n",
        "\n",
        "            # Filter data for this state\n",
        "            df_state = self.wheat_data[self.wheat_data['state'].str.lower() == state.lower()].copy()\n",
        "\n",
        "            # Engineer features\n",
        "            df_state = feature_engineer.engineer_features(df_state)\n",
        "\n",
        "            # Train models for this state\n",
        "            state_result = model_trainer.train_models_for_state(state, df_state, self.split_date)\n",
        "\n",
        "            if state_result is not None:\n",
        "                # Store feature columns from first successful state if not already set\n",
        "                if self.feature_cols is None:\n",
        "                    self.feature_cols = model_trainer.feature_cols\n",
        "\n",
        "                # Store state result\n",
        "                self.all_state_models[state] = state_result\n",
        "\n",
        "        # Step 5: Aggregate models to S3\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Step 5: Aggregating models to S3\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Initialize aggregator with S3 capability\n",
        "        aggregator = ModelAggregator(\n",
        "            s3_connector=self.s3_connector,\n",
        "            s3_bucket=self.s3_bucket,\n",
        "            output_prefix=self.output_prefix\n",
        "        )\n",
        "        combined_s3_path = aggregator.aggregate_models(self.all_state_models, self.feature_cols)\n",
        "\n",
        "        # Step 6: Print summary\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Step 6: Results summary\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        aggregator.print_summary_table(self.all_state_models)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"✅ Wheat price forecasting process completed successfully\")\n",
        "        print(f\"✅ All outputs saved to S3: s3://{self.s3_bucket}/{self.output_prefix}/\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        return {\n",
        "            'combined_model_s3_path': combined_s3_path,\n",
        "            'all_state_models': self.all_state_models,\n",
        "            'feature_cols': self.feature_cols,\n",
        "            's3_location': f\"s3://{self.s3_bucket}/{self.output_prefix}/\"\n",
        "        }"
      ],
      "metadata": {
        "id": "0PWQa1sa9GPd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(s3_bucket,\n",
        "         s3_key,\n",
        "         output_prefix=\"wheat_forecaster\",\n",
        "         split_date=\"2020-01-01\",\n",
        "         mlflow_uri=None,\n",
        "         aws_access_key_id=None,\n",
        "         aws_secret_access_key=None,\n",
        "         aws_region='us-east-1'):\n",
        "    \"\"\"\n",
        "    Run the wheat price forecasting pipeline using data from S3 and storing all outputs to S3.\n",
        "\n",
        "    Args:\n",
        "        s3_bucket (str): S3 bucket containing the CSV data file and for storing outputs\n",
        "        s3_key (str): S3 key (path) to the CSV data file\n",
        "        output_prefix (str): Prefix path in the S3 bucket for all outputs\n",
        "        split_date (str): Date to split train/test data\n",
        "        mlflow_uri (str, optional): MLflow tracking URI\n",
        "        aws_access_key_id (str, optional): AWS access key ID\n",
        "        aws_secret_access_key (str, optional): AWS secret access key\n",
        "        aws_region (str, optional): AWS region name\n",
        "\n",
        "    Returns:\n",
        "        dict: Results from the forecasting process with S3 paths\n",
        "    \"\"\"\n",
        "    forecaster = WheatPriceForecaster(\n",
        "        s3_bucket=s3_bucket,\n",
        "        s3_key=s3_key,\n",
        "        output_prefix=output_prefix,\n",
        "        split_date=split_date,\n",
        "        mlflow_uri=mlflow_uri,\n",
        "        aws_access_key_id=aws_access_key_id,\n",
        "        aws_secret_access_key=aws_secret_access_key,\n",
        "        aws_region=aws_region\n",
        "    )\n",
        "    results = forecaster.run_full_process()\n",
        "    return results"
      ],
      "metadata": {
        "id": "MJI0bMFi9GSc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = main(\n",
        "    s3_bucket=\"foundation-project-data\",\n",
        "    s3_key=\"data/wheat_prices_merged.csv\",\n",
        "    output_prefix=\"wheat_forecaster\",\n",
        "    split_date=\"2020-01-01\",\n",
        "    mlflow_uri=\"http://ec2-51-21-244-174.eu-north-1.compute.amazonaws.com:5000/\",\n",
        "    aws_access_key_id=\"AKIAWZDATPAE545UJHYU\",\n",
        "    aws_secret_access_key=\"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\",\n",
        "    aws_region=\"eu-north-1\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru3xWqI29fZ8",
        "outputId": "91ad9178-b6cb-4b2b-b970-4d97dc6573dd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ S3 client initialized for region: eu-north-1\n",
            "🚀 Initializing Wheat Price Forecaster with S3 storage\n",
            "📄 Input file: s3://foundation-project-data/data/wheat_prices_merged.csv\n",
            "📁 Output location: s3://foundation-project-data/wheat_forecaster/\n",
            "📅 Train/Test split date: 2020-01-01\n",
            "📊 MLflow tracking URI: http://ec2-51-21-244-174.eu-north-1.compute.amazonaws.com:5000/\n",
            "\n",
            "================================================================================\n",
            "Step 1: Setting up S3 directory structure\n",
            "================================================================================\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/plots/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/models/\n",
            "✅ Created S3 directory structure in s3://foundation-project-data/wheat_forecaster/\n",
            "\n",
            "================================================================================\n",
            "Step 2: Loading data from S3\n",
            "================================================================================\n",
            "Reading file from S3: s3://foundation-project-data/data/wheat_prices_merged.csv\n",
            "✅ Successfully read CSV from S3 with 5,658 rows\n",
            "\n",
            "================================================================================\n",
            "Step 3: Preprocessing data\n",
            "================================================================================\n",
            "Starting data preprocessing...\n",
            "Converted MSP from quintal to KG\n",
            "Filtered 4,867 retail price records\n",
            "Using 'price' column as price_per_KG\n",
            "Dropped 0 rows with missing states (0.00%)\n",
            "Remaining records: 4,867\n",
            "Converting 'date' to datetime\n",
            "Extracting time features...\n",
            "Added time features: year, month, day, quarter\n",
            "Added cyclical features: month_sin, month_cos, quarter_sin, quarter_cos\n",
            "Sorted data by state and date\n",
            "Handling missing values...\n",
            "Filled 1,026 missing Rainfall values\n",
            "Filled 0 missing Diesel Price values\n",
            "Filled 1,308 missing Diesel ROC values\n",
            "Filled 1,308 missing Wheat ROC values\n",
            "Calculated 'Diesel / Wheat Price Ratio'\n",
            "\n",
            "Remaining missing values:\n",
            "- Date: 1,298 missing values\n",
            "- Diesel Price: 1,298 missing values\n",
            "- Wheat Price (Indian Rupee per Metric Ton): 1,298 missing values\n",
            "- Diesel / Wheat Price Ratio: 1,298 missing values\n",
            "- Rainfall: 1,322 missing values\n",
            "- ANNUAL: 2,348 missing values\n",
            "- JF: 2,348 missing values\n",
            "- MAM: 2,348 missing values\n",
            "- JJAS: 2,348 missing values\n",
            "- OND: 2,348 missing values\n",
            "- index: 4,867 missing values\n",
            "- 0: 4,867 missing values\n",
            "- diesel_price: 1,298 missing values\n",
            "Filtered for wheat commodity: 4,867 records from 4,867\n",
            "✅ Preprocessing complete\n",
            "\n",
            "📊 Summary Statistics for Preprocessed Data:\n",
            "                             date         year        price          CPI  \\\n",
            "count                        4867  4867.000000  4867.000000  4867.000000   \n",
            "mean   2011-11-22 09:57:21.709472  2011.386686    19.207975     6.571177   \n",
            "min           1994-01-15 00:00:00  1994.000000     3.800000     3.330000   \n",
            "25%           2005-08-30 12:00:00  2005.000000    11.000000     4.300000   \n",
            "50%           2013-09-15 00:00:00  2013.000000    18.500000     6.370000   \n",
            "75%           2018-06-30 00:00:00  2018.000000    25.931591     8.910000   \n",
            "max           2022-12-15 00:00:00  2022.000000    60.000000    13.230000   \n",
            "std                           NaN     8.109863     9.331686     2.598563   \n",
            "\n",
            "          msp_year    MSP_Wheat  Diesel Price  \\\n",
            "count  4867.000000  4867.000000   3569.000000   \n",
            "mean   2011.227039  1324.245942    143.608571   \n",
            "min    1993.000000   350.000000     64.280000   \n",
            "25%    2005.000000   650.000000    100.130000   \n",
            "50%    2013.000000  1400.000000    134.890000   \n",
            "75%    2018.000000  1840.000000    167.670000   \n",
            "max    2022.000000  2125.000000    359.180000   \n",
            "std       8.115257   551.159864     60.091085   \n",
            "\n",
            "       Wheat Price (Indian Rupee per Metric Ton)   Diesel ROC    Wheat ROC  \\\n",
            "count                                3569.000000  4867.000000  4867.000000   \n",
            "mean                                16800.637691    -0.045546    -0.015570   \n",
            "min                                  7341.830000    -0.258800    -0.182900   \n",
            "25%                                 12370.720000    -0.227800    -0.080000   \n",
            "50%                                 14844.200000    -0.015900    -0.024400   \n",
            "75%                                 19282.070000     0.050800     0.034200   \n",
            "max                                 40377.800000     0.337400     0.265400   \n",
            "std                                  6815.883204     0.131715     0.071884   \n",
            "\n",
            "       ...  MSP_Wheat_KG  price_per_KG    month_num     day      quarter  \\\n",
            "count  ...   4867.000000   4867.000000  4867.000000  4867.0  4867.000000   \n",
            "mean   ...     13.242459     19.207975     6.609616    15.0     2.534415   \n",
            "min    ...      3.500000      3.800000     1.000000    15.0     1.000000   \n",
            "25%    ...      6.500000     11.000000     4.000000    15.0     2.000000   \n",
            "50%    ...     14.000000     18.500000     7.000000    15.0     3.000000   \n",
            "75%    ...     18.400000     25.931591    10.000000    15.0     4.000000   \n",
            "max    ...     21.250000     60.000000    12.000000    15.0     4.000000   \n",
            "std    ...      5.511599      9.331686     3.443880     0.0     1.116239   \n",
            "\n",
            "          month_sin     month_cos   quarter_sin   quarter_cos  diesel_price  \n",
            "count  4.867000e+03  4.867000e+03  4.867000e+03  4.867000e+03   3569.000000  \n",
            "mean  -2.196411e-02  1.911619e-03 -1.787549e-02  1.479351e-02    143.608571  \n",
            "min   -1.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00     64.280000  \n",
            "25%   -8.660254e-01 -8.660254e-01 -1.000000e+00 -1.836970e-16    100.130000  \n",
            "50%   -2.449294e-16 -1.836970e-16 -2.449294e-16 -1.836970e-16    134.890000  \n",
            "75%    5.000000e-01  8.660254e-01  1.224647e-16  1.000000e+00    167.670000  \n",
            "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00    359.180000  \n",
            "std    7.048365e-01  7.091719e-01  7.057169e-01  7.082589e-01     60.091085  \n",
            "\n",
            "[8 rows x 29 columns]\n",
            "\n",
            "Found 31 states with wheat price data:\n",
            "   1. Andaman And Nicobar\n",
            "   2. Andhra Pradesh\n",
            "   3. Assam\n",
            "   4. Bihar\n",
            "   5. Chandigarh\n",
            "   6. Chhattisgarh\n",
            "   7. Delhi\n",
            "   8. Goa\n",
            "   9. Gujarat\n",
            "   10. Haryana\n",
            "   11. Himachal Pradesh\n",
            "   12. Jharkhand\n",
            "   13. Karnataka\n",
            "   14. Kerala\n",
            "   15. Madhya Pradesh\n",
            "   16. Maharashtra\n",
            "   17. Manipur\n",
            "   18. Meghalaya\n",
            "   19. Mizoram\n",
            "   20. Nagaland\n",
            "   21. Orissa\n",
            "   22. Puducherry\n",
            "   23. Punjab\n",
            "   24. Rajasthan\n",
            "   25. Sikkim\n",
            "   26. Tamil Nadu\n",
            "   27. Telangana\n",
            "   28. Tripura\n",
            "   29. Uttar Pradesh\n",
            "   30. Uttarakhand\n",
            "   31. West Bengal\n",
            "\n",
            "================================================================================\n",
            "Step 4: Processing individual states\n",
            "================================================================================\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/plots/\n",
            "✅ Set up S3 directory structure:\n",
            "  - 📁 s3://foundation-project-data/wheat_forecaster/model_registry (models)\n",
            "  - 📁 s3://foundation-project-data/wheat_forecaster/plots (visualizations)\n",
            "\n",
            "Processing state 1/31: Andaman And Nicobar\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.993208\n",
            "lag_1m             0.988189\n",
            "rolling_mean_6m    0.983719\n",
            "lag_3m             0.968071\n",
            "MSP_Wheat_KG       0.957335\n",
            "MSP_Wheat          0.957335\n",
            "year               0.949912\n",
            "msp_year           0.947900\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Andaman And Nicobar\n",
            "================================================================================\n",
            "Found 97 records for Andaman And Nicobar\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 66 records (68.0%)\n",
            "Test data: 31 records (32.0%)\n",
            "After dropping NaN values - Train: 54, Test: 31\n",
            "Final feature matrix shapes - X_train: (54, 25), X_test: (31, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 2.4941, R²: -2.4182\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3669\n",
            "   - rolling_mean_6m: 0.2897\n",
            "   - lag_1m: 0.1009\n",
            "   - MSP_Wheat_KG: 0.0836\n",
            "   - year: 0.0717\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 3.3279, R²: -5.0854\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.4372\n",
            "   - rolling_mean_3m: 0.1423\n",
            "   - MSP_Wheat_KG: 0.1131\n",
            "   - year: 0.1039\n",
            "   - diesel_price: 0.0922\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 3.7136\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Andaman And Nicobar: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.2836\n",
            "   - test_rmse: 2.4941\n",
            "   - train_mae: 0.1476\n",
            "   - test_mae: 2.0949\n",
            "   - train_mape: 0.4328\n",
            "   - test_mape: 4.9890\n",
            "   - train_r2: 0.9956\n",
            "   - test_r2: -2.4182\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar_best_model.pkl\n",
            "✅ Successfully processed Andaman And Nicobar\n",
            "\n",
            "Processing state 2/31: Andhra Pradesh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.980992\n",
            "rolling_mean_6m    0.965950\n",
            "lag_1m             0.953954\n",
            "lag_3m             0.929783\n",
            "year               0.917954\n",
            "MSP_Wheat_KG       0.917729\n",
            "MSP_Wheat          0.917729\n",
            "msp_year           0.914837\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Andhra Pradesh\n",
            "================================================================================\n",
            "Found 99 records for Andhra Pradesh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 66 records (66.7%)\n",
            "Test data: 33 records (33.3%)\n",
            "After dropping NaN values - Train: 54, Test: 33\n",
            "Final feature matrix shapes - X_train: (54, 25), X_test: (33, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 4.2536, R²: -1.6305\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3039\n",
            "   - rolling_mean_6m: 0.2994\n",
            "   - roc_1m: 0.0837\n",
            "   - rolling_std_3m: 0.0634\n",
            "   - lag_1m: 0.0455\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 3.3055, R²: -0.5885\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.1549\n",
            "   - rolling_std_6m: 0.1523\n",
            "   - CPI: 0.1019\n",
            "   - rolling_mean_3m: 0.1008\n",
            "   - MSP_Wheat_KG: 0.0755\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 9.7640\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Andhra Pradesh: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.1068\n",
            "   - test_rmse: 3.3055\n",
            "   - train_mae: 0.0645\n",
            "   - test_mae: 2.5981\n",
            "   - train_mape: 0.2313\n",
            "   - test_mape: 6.9778\n",
            "   - train_r2: 0.9982\n",
            "   - test_r2: -0.5885\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh_best_model.pkl\n",
            "✅ Successfully processed Andhra Pradesh\n",
            "\n",
            "Processing state 3/31: Assam\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.993224\n",
            "lag_1m             0.985648\n",
            "rolling_mean_6m    0.982591\n",
            "lag_3m             0.963256\n",
            "lag_6m             0.940372\n",
            "year               0.929634\n",
            "msp_year           0.929441\n",
            "MSP_Wheat          0.922022\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Assam\n",
            "================================================================================\n",
            "Found 159 records for Assam\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 125 records (78.6%)\n",
            "Test data: 34 records (21.4%)\n",
            "After dropping NaN values - Train: 113, Test: 34\n",
            "Final feature matrix shapes - X_train: (113, 25), X_test: (34, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 1.1689, R²: 0.6758\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3257\n",
            "   - rolling_mean_6m: 0.2369\n",
            "   - lag_1m: 0.2029\n",
            "   - lag_3m: 0.1358\n",
            "   - year: 0.0386\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 1.3997, R²: 0.5351\n",
            "Top 5 important features:\n",
            "   - lag_3m: 0.5243\n",
            "   - lag_1m: 0.1862\n",
            "   - year: 0.1359\n",
            "   - rolling_mean_6m: 0.0599\n",
            "   - rolling_mean_3m: 0.0544\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 3.0048\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Assam: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.2224\n",
            "   - test_rmse: 1.1689\n",
            "   - train_mae: 0.1340\n",
            "   - test_mae: 0.8873\n",
            "   - train_mape: 0.7181\n",
            "   - test_mape: 3.2550\n",
            "   - train_r2: 0.9979\n",
            "   - test_r2: 0.6758\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/assam_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/assam_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/assam_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/assam_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/assam_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/assam_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/assam/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/assam/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/assam/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/assam/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/assam/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/assam/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/assam/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/assam_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/assam_best_model.pkl\n",
            "✅ Successfully processed Assam\n",
            "\n",
            "Processing state 4/31: Bihar\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.991982\n",
            "lag_1m             0.983748\n",
            "rolling_mean_6m    0.981128\n",
            "lag_3m             0.961915\n",
            "MSP_Wheat          0.954708\n",
            "MSP_Wheat_KG       0.954708\n",
            "msp_year           0.937907\n",
            "year               0.937503\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Bihar\n",
            "================================================================================\n",
            "Found 259 records for Bihar\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 223 records (86.1%)\n",
            "Test data: 36 records (13.9%)\n",
            "After dropping NaN values - Train: 146, Test: 36\n",
            "Final feature matrix shapes - X_train: (146, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 1.4489, R²: 0.6543\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.8469\n",
            "   - rolling_mean_6m: 0.0464\n",
            "   - lag_1m: 0.0437\n",
            "   - MSP_to_retail_ratio: 0.0160\n",
            "   - roc_1m: 0.0102\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 1.4960, R²: 0.6315\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.2850\n",
            "   - rolling_mean_3m: 0.2362\n",
            "   - lag_1m: 0.2182\n",
            "   - MSP_Wheat_KG: 0.0868\n",
            "   - rolling_std_6m: 0.0407\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 4.1494\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Bihar: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.3460\n",
            "   - test_rmse: 1.4489\n",
            "   - train_mae: 0.2223\n",
            "   - test_mae: 0.9745\n",
            "   - train_mape: 1.3140\n",
            "   - test_mape: 4.1453\n",
            "   - train_r2: 0.9921\n",
            "   - test_r2: 0.6543\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/bihar_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/bihar_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/bihar_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/bihar_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/bihar_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/bihar_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/bihar/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/bihar/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/bihar/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/bihar/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/bihar/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/bihar/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/bihar/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/bihar_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/bihar_best_model.pkl\n",
            "✅ Successfully processed Bihar\n",
            "\n",
            "Processing state 5/31: Chandigarh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.962519\n",
            "rolling_mean_6m    0.896990\n",
            "lag_1m             0.896789\n",
            "lag_3m             0.766036\n",
            "MSP_Wheat_KG       0.751957\n",
            "MSP_Wheat          0.751957\n",
            "msp_year           0.735284\n",
            "year               0.721384\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Chandigarh\n",
            "================================================================================\n",
            "Found 87 records for Chandigarh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 64 records (73.6%)\n",
            "Test data: 23 records (26.4%)\n",
            "After dropping NaN values - Train: 52, Test: 23\n",
            "Final feature matrix shapes - X_train: (52, 25), X_test: (23, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 1.5562, R²: 0.5651\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.5622\n",
            "   - lag_1m: 0.3384\n",
            "   - rolling_mean_6m: 0.0219\n",
            "   - roc_1m: 0.0160\n",
            "   - MSP_to_retail_ratio: 0.0117\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 1.9523, R²: 0.3154\n",
            "Top 5 important features:\n",
            "   - CPI: 0.5967\n",
            "   - lag_1m: 0.1553\n",
            "   - rolling_mean_3m: 0.1012\n",
            "   - roc_3m: 0.0211\n",
            "   - lag_6m: 0.0172\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 5.2383\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Chandigarh: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.2893\n",
            "   - test_rmse: 1.5562\n",
            "   - train_mae: 0.1610\n",
            "   - test_mae: 1.1810\n",
            "   - train_mape: 0.8006\n",
            "   - test_mape: 5.1207\n",
            "   - train_r2: 0.9851\n",
            "   - test_r2: 0.5651\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/chandigarh_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/chandigarh_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/chandigarh_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/chandigarh_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/chandigarh_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/chandigarh_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh_best_model.pkl\n",
            "✅ Successfully processed Chandigarh\n",
            "\n",
            "Processing state 6/31: Chhattisgarh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price                                        1.000000\n",
            "price_per_KG                                 1.000000\n",
            "rolling_mean_3m                              0.650236\n",
            "roc_1m                                       0.638076\n",
            "roc_3m                                       0.614765\n",
            "rolling_mean_6m                              0.608490\n",
            "Wheat Price (Indian Rupee per Metric Ton)    0.554384\n",
            "Diesel Price                                 0.536052\n",
            "diesel_price                                 0.536052\n",
            "MSP_Wheat                                    0.534047\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Chhattisgarh\n",
            "================================================================================\n",
            "Found 27 records for Chhattisgarh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 0 records (0.0%)\n",
            "Test data: 27 records (100.0%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Chhattisgarh - insufficient data after cleaning\n",
            "\n",
            "Processing state 7/31: Delhi\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.994947\n",
            "rolling_mean_6m    0.988619\n",
            "lag_1m             0.988350\n",
            "MSP_Wheat_KG       0.978569\n",
            "MSP_Wheat          0.978569\n",
            "lag_3m             0.976122\n",
            "year               0.965751\n",
            "msp_year           0.964683\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Delhi\n",
            "================================================================================\n",
            "Found 310 records for Delhi\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 283 records (91.3%)\n",
            "Test data: 27 records (8.7%)\n",
            "After dropping NaN values - Train: 156, Test: 27\n",
            "Final feature matrix shapes - X_train: (156, 25), X_test: (27, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 1.0122, R²: 0.8041\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.7129\n",
            "   - rolling_mean_6m: 0.1156\n",
            "   - lag_1m: 0.0668\n",
            "   - MSP_Wheat_KG: 0.0327\n",
            "   - year: 0.0150\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 1.1473, R²: 0.7482\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.4590\n",
            "   - rolling_mean_3m: 0.2160\n",
            "   - MSP_Wheat_KG: 0.0648\n",
            "   - lag_1m: 0.0512\n",
            "   - lag_12m: 0.0401\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 4.0344\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Delhi: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.3551\n",
            "   - test_rmse: 1.0122\n",
            "   - train_mae: 0.1713\n",
            "   - test_mae: 0.7603\n",
            "   - train_mape: 1.0038\n",
            "   - test_mape: 3.1877\n",
            "   - train_r2: 0.9916\n",
            "   - test_r2: 0.8041\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/delhi_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/delhi_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/delhi_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/delhi_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/delhi_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/delhi_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/delhi/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/delhi/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/delhi/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/delhi/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/delhi/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/delhi/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/delhi/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/delhi_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/delhi_best_model.pkl\n",
            "✅ Successfully processed Delhi\n",
            "\n",
            "Processing state 8/31: Goa\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.988238\n",
            "lag_1m             0.979324\n",
            "rolling_mean_6m    0.973388\n",
            "lag_3m             0.934758\n",
            "lag_6m             0.911878\n",
            "year               0.897717\n",
            "msp_year           0.892188\n",
            "lag_12m            0.865166\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Goa\n",
            "================================================================================\n",
            "Found 80 records for Goa\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 56 records (70.0%)\n",
            "Test data: 24 records (30.0%)\n",
            "After dropping NaN values - Train: 43, Test: 22\n",
            "Final feature matrix shapes - X_train: (43, 25), X_test: (22, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 4.1054, R²: -2.2594\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.4283\n",
            "   - roc_3m: 0.2931\n",
            "   - lag_1m: 0.1222\n",
            "   - rolling_mean_6m: 0.0485\n",
            "   - year: 0.0328\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 4.0217, R²: -2.1278\n",
            "Top 5 important features:\n",
            "   - MSP_Wheat_KG: 0.2311\n",
            "   - rolling_mean_3m: 0.1959\n",
            "   - year: 0.1120\n",
            "   - roc_3m: 0.1108\n",
            "   - lag_6m: 0.0866\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 2.1603\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Goa: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.4663\n",
            "   - test_rmse: 2.1603\n",
            "   - train_mae: 0.3414\n",
            "   - test_mae: 1.8619\n",
            "   - train_mape: 1.1056\n",
            "   - test_mape: 5.0445\n",
            "   - train_r2: 0.8337\n",
            "   - test_r2: 0.0975\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/goa_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/goa_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/goa/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/goa/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/goa/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/goa/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/goa/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/goa/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/goa/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/goa_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/goa_best_model.pkl\n",
            "✅ Successfully processed Goa\n",
            "\n",
            "Processing state 9/31: Gujarat\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.996899\n",
            "rolling_mean_6m    0.993703\n",
            "lag_1m             0.993117\n",
            "lag_3m             0.986002\n",
            "lag_6m             0.980850\n",
            "MSP_Wheat_KG       0.969012\n",
            "MSP_Wheat          0.969012\n",
            "lag_12m            0.967627\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Gujarat\n",
            "================================================================================\n",
            "Found 258 records for Gujarat\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 222 records (86.0%)\n",
            "Test data: 36 records (14.0%)\n",
            "After dropping NaN values - Train: 134, Test: 36\n",
            "Final feature matrix shapes - X_train: (134, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 4.9122, R²: -1.7847\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.6912\n",
            "   - rolling_mean_6m: 0.1492\n",
            "   - lag_1m: 0.0940\n",
            "   - year: 0.0137\n",
            "   - MSP_Wheat_KG: 0.0130\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 5.2374, R²: -2.1656\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.4055\n",
            "   - rolling_mean_3m: 0.2278\n",
            "   - MSP_Wheat_KG: 0.1679\n",
            "   - lag_1m: 0.0550\n",
            "   - year: 0.0541\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 3.9267\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Gujarat: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.9089\n",
            "   - test_rmse: 3.9267\n",
            "   - train_mae: 0.6170\n",
            "   - test_mae: 3.2930\n",
            "   - train_mape: 3.8642\n",
            "   - test_mape: 11.6397\n",
            "   - train_r2: 0.9421\n",
            "   - test_r2: -0.7795\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/gujarat_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/gujarat_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/gujarat_best_model.pkl\n",
            "✅ Successfully processed Gujarat\n",
            "\n",
            "Processing state 10/31: Haryana\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.980551\n",
            "rolling_mean_6m    0.971206\n",
            "lag_1m             0.957536\n",
            "lag_3m             0.930766\n",
            "year               0.920828\n",
            "msp_year           0.918282\n",
            "MSP_Wheat_KG       0.904261\n",
            "MSP_Wheat          0.904261\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Haryana\n",
            "================================================================================\n",
            "Found 136 records for Haryana\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 100 records (73.5%)\n",
            "Test data: 36 records (26.5%)\n",
            "After dropping NaN values - Train: 88, Test: 36\n",
            "Final feature matrix shapes - X_train: (88, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 2.5765, R²: -3.4008\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.5195\n",
            "   - rolling_mean_6m: 0.1507\n",
            "   - lag_1m: 0.1257\n",
            "   - MSP_to_retail_ratio: 0.0701\n",
            "   - Diesel / Wheat Price Ratio: 0.0344\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 2.6412, R²: -3.6246\n",
            "Top 5 important features:\n",
            "   - lag_1m: 0.1905\n",
            "   - rolling_mean_3m: 0.1881\n",
            "   - year: 0.1660\n",
            "   - rolling_mean_6m: 0.1587\n",
            "   - lag_3m: 0.1155\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 0.9177\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Haryana: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.6442\n",
            "   - test_rmse: 0.9177\n",
            "   - train_mae: 0.4595\n",
            "   - test_mae: 0.7647\n",
            "   - train_mape: 2.5957\n",
            "   - test_mape: 3.3519\n",
            "   - train_r2: 0.9276\n",
            "   - test_r2: 0.4417\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/haryana_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/haryana_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/haryana/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/haryana/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/haryana/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/haryana/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/haryana/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/haryana/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/haryana/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/haryana_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/haryana_best_model.pkl\n",
            "✅ Successfully processed Haryana\n",
            "\n",
            "Processing state 11/31: Himachal Pradesh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "MAM                0.959778\n",
            "rolling_mean_3m    0.917462\n",
            "JF                 0.868506\n",
            "lag_1m             0.853700\n",
            "msp_year           0.837622\n",
            "year               0.835793\n",
            "MSP_Wheat_KG       0.811949\n",
            "MSP_Wheat          0.811949\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Himachal Pradesh\n",
            "================================================================================\n",
            "Found 37 records for Himachal Pradesh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 25 records (67.6%)\n",
            "Test data: 12 records (32.4%)\n",
            "After dropping NaN values - Train: 13, Test: 12\n",
            "Final feature matrix shapes - X_train: (13, 25), X_test: (12, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 5.9799, R²: -4.1441\n",
            "Top 5 important features:\n",
            "   - year: 0.1514\n",
            "   - rolling_mean_3m: 0.1348\n",
            "   - rolling_std_6m: 0.1093\n",
            "   - rolling_mean_6m: 0.0948\n",
            "   - MSP_Wheat_KG: 0.0893\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 4.7876, R²: -2.2973\n",
            "Top 5 important features:\n",
            "   - CPI: 0.5031\n",
            "   - MSP_Wheat_KG: 0.4560\n",
            "   - Diesel / Wheat Price Ratio: 0.0230\n",
            "   - year: 0.0113\n",
            "   - diesel_price: 0.0065\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "❌ Error training Holt-Winters model: Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Himachal Pradesh: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.1544\n",
            "   - test_rmse: 4.7876\n",
            "   - train_mae: 0.0953\n",
            "   - test_mae: 4.4757\n",
            "   - train_mape: 0.5663\n",
            "   - test_mape: 17.4322\n",
            "   - train_r2: 0.9991\n",
            "   - test_r2: -2.2973\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh_best_model.pkl\n",
            "✅ Successfully processed Himachal Pradesh\n",
            "\n",
            "Processing state 12/31: Jharkhand\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.976709\n",
            "lag_1m             0.960154\n",
            "rolling_mean_6m    0.952307\n",
            "lag_3m             0.902141\n",
            "MSP_Wheat          0.864170\n",
            "MSP_Wheat_KG       0.864170\n",
            "year               0.855873\n",
            "msp_year           0.853486\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Jharkhand\n",
            "================================================================================\n",
            "Found 128 records for Jharkhand\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 92 records (71.9%)\n",
            "Test data: 36 records (28.1%)\n",
            "After dropping NaN values - Train: 80, Test: 36\n",
            "Final feature matrix shapes - X_train: (80, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 1.2729, R²: 0.7251\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3945\n",
            "   - rolling_mean_6m: 0.3006\n",
            "   - lag_1m: 0.1376\n",
            "   - MSP_to_retail_ratio: 0.0585\n",
            "   - Diesel / Wheat Price Ratio: 0.0413\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 1.2306, R²: 0.7431\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.2609\n",
            "   - rolling_mean_3m: 0.2101\n",
            "   - lag_3m: 0.2089\n",
            "   - lag_1m: 0.0935\n",
            "   - rolling_std_6m: 0.0469\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 6.3747\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Jharkhand: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.0894\n",
            "   - test_rmse: 1.2306\n",
            "   - train_mae: 0.0522\n",
            "   - test_mae: 0.9504\n",
            "   - train_mape: 0.2375\n",
            "   - test_mape: 3.5593\n",
            "   - train_r2: 0.9991\n",
            "   - test_r2: 0.7431\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/jharkhand_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/jharkhand_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/jharkhand_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/jharkhand_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/jharkhand_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/jharkhand_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand_best_model.pkl\n",
            "✅ Successfully processed Jharkhand\n",
            "\n",
            "Processing state 13/31: Karnataka\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.995779\n",
            "rolling_mean_6m    0.993618\n",
            "lag_1m             0.988378\n",
            "lag_3m             0.986917\n",
            "lag_6m             0.979794\n",
            "MSP_Wheat          0.979409\n",
            "MSP_Wheat_KG       0.979409\n",
            "lag_12m            0.971125\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Karnataka\n",
            "================================================================================\n",
            "Found 301 records for Karnataka\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 266 records (88.4%)\n",
            "Test data: 35 records (11.6%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Karnataka - insufficient data after cleaning\n",
            "\n",
            "Processing state 14/31: Kerala\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.989927\n",
            "rolling_mean_6m    0.982877\n",
            "lag_1m             0.979262\n",
            "MSP_Wheat          0.968962\n",
            "MSP_Wheat_KG       0.968962\n",
            "lag_3m             0.957190\n",
            "lag_6m             0.954730\n",
            "year               0.951830\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Kerala\n",
            "================================================================================\n",
            "Found 224 records for Kerala\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 188 records (83.9%)\n",
            "Test data: 36 records (16.1%)\n",
            "After dropping NaN values - Train: 135, Test: 36\n",
            "Final feature matrix shapes - X_train: (135, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 3.2028, R²: -0.4771\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.8392\n",
            "   - rolling_mean_6m: 0.0589\n",
            "   - lag_1m: 0.0340\n",
            "   - MSP_to_retail_ratio: 0.0251\n",
            "   - Diesel / Wheat Price Ratio: 0.0070\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 3.8821, R²: -1.1701\n",
            "Top 5 important features:\n",
            "   - year: 0.4481\n",
            "   - rolling_mean_3m: 0.2148\n",
            "   - rolling_mean_6m: 0.1761\n",
            "   - lag_1m: 0.0638\n",
            "   - MSP_to_retail_ratio: 0.0159\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 2.6003\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Kerala: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 2.0331\n",
            "   - test_rmse: 2.6003\n",
            "   - train_mae: 1.2874\n",
            "   - test_mae: 2.2261\n",
            "   - train_mape: 4.8367\n",
            "   - test_mape: 6.1703\n",
            "   - train_r2: 0.8793\n",
            "   - test_r2: 0.0264\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/kerala_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/kerala_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/kerala/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/kerala/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/kerala/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/kerala/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/kerala/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/kerala/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/kerala/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/kerala_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/kerala_best_model.pkl\n",
            "✅ Successfully processed Kerala\n",
            "\n",
            "Processing state 15/31: Madhya Pradesh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.996886\n",
            "rolling_mean_6m    0.993000\n",
            "lag_1m             0.992638\n",
            "MSP_Wheat          0.985689\n",
            "MSP_Wheat_KG       0.985689\n",
            "lag_3m             0.985005\n",
            "lag_6m             0.977425\n",
            "lag_12m            0.967828\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Madhya Pradesh\n",
            "================================================================================\n",
            "Found 283 records for Madhya Pradesh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 247 records (87.3%)\n",
            "Test data: 36 records (12.7%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Madhya Pradesh - insufficient data after cleaning\n",
            "\n",
            "Processing state 16/31: Maharashtra\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.993091\n",
            "rolling_mean_6m    0.987926\n",
            "lag_1m             0.983160\n",
            "MSP_Wheat          0.978237\n",
            "MSP_Wheat_KG       0.978237\n",
            "lag_3m             0.972835\n",
            "lag_6m             0.966410\n",
            "lag_12m            0.963693\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Maharashtra\n",
            "================================================================================\n",
            "Found 288 records for Maharashtra\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 252 records (87.5%)\n",
            "Test data: 36 records (12.5%)\n",
            "After dropping NaN values - Train: 141, Test: 36\n",
            "Final feature matrix shapes - X_train: (141, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 3.6550, R²: -1.6399\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.5738\n",
            "   - rolling_mean_6m: 0.2148\n",
            "   - year: 0.0826\n",
            "   - lag_3m: 0.0278\n",
            "   - lag_1m: 0.0263\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 3.7066, R²: -1.7151\n",
            "Top 5 important features:\n",
            "   - year: 0.4472\n",
            "   - rolling_mean_6m: 0.2261\n",
            "   - rolling_mean_3m: 0.1909\n",
            "   - lag_3m: 0.0600\n",
            "   - roc_3m: 0.0130\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 2.2955\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Maharashtra: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 1.6292\n",
            "   - test_rmse: 2.2955\n",
            "   - train_mae: 1.1973\n",
            "   - test_mae: 1.7778\n",
            "   - train_mape: 5.2881\n",
            "   - test_mape: 5.1949\n",
            "   - train_r2: 0.8940\n",
            "   - test_r2: -0.0413\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/maharashtra_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/maharashtra_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra_best_model.pkl\n",
            "✅ Successfully processed Maharashtra\n",
            "\n",
            "Processing state 17/31: Manipur\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "roc_3m             1.000000\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.918559\n",
            "lag_1m             0.632456\n",
            "roc_1m             0.632456\n",
            "Diesel ROC         0.473540\n",
            "Wheat ROC          0.223475\n",
            "diesel_price       0.211446\n",
            "Diesel Price       0.211446\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Manipur\n",
            "================================================================================\n",
            "⚠️ Skipping Manipur - insufficient data (only 7 records)\n",
            "\n",
            "Processing state 18/31: Meghalaya\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.994184\n",
            "lag_1m             0.989276\n",
            "MSP_Wheat_KG       0.988283\n",
            "MSP_Wheat          0.988283\n",
            "rolling_mean_6m    0.985185\n",
            "lag_3m             0.969710\n",
            "year               0.968191\n",
            "msp_year           0.967927\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Meghalaya\n",
            "================================================================================\n",
            "Found 179 records for Meghalaya\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 146 records (81.6%)\n",
            "Test data: 33 records (18.4%)\n",
            "After dropping NaN values - Train: 60, Test: 33\n",
            "Final feature matrix shapes - X_train: (60, 25), X_test: (33, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 2.3687, R²: 0.2994\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.5929\n",
            "   - lag_1m: 0.1485\n",
            "   - rolling_mean_6m: 0.1078\n",
            "   - year: 0.0219\n",
            "   - lag_3m: 0.0162\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 2.5694, R²: 0.1757\n",
            "Top 5 important features:\n",
            "   - lag_3m: 0.3311\n",
            "   - rolling_mean_6m: 0.1909\n",
            "   - rolling_mean_3m: 0.1518\n",
            "   - lag_1m: 0.1012\n",
            "   - rolling_std_6m: 0.0849\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 3.0715\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Meghalaya: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.3659\n",
            "   - test_rmse: 2.3687\n",
            "   - train_mae: 0.2157\n",
            "   - test_mae: 1.7304\n",
            "   - train_mape: 0.7181\n",
            "   - test_mape: 4.9913\n",
            "   - train_r2: 0.9817\n",
            "   - test_r2: 0.2994\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/meghalaya_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/meghalaya_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/meghalaya_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/meghalaya_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/meghalaya_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/meghalaya_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya_best_model.pkl\n",
            "✅ Successfully processed Meghalaya\n",
            "\n",
            "Processing state 19/31: Mizoram\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.987783\n",
            "year               0.981586\n",
            "msp_year           0.981100\n",
            "MSP_Wheat_KG       0.980937\n",
            "MSP_Wheat          0.980937\n",
            "lag_1m             0.979405\n",
            "rolling_mean_6m    0.948631\n",
            "lag_3m             0.914167\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Mizoram\n",
            "================================================================================\n",
            "Found 41 records for Mizoram\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 21 records (51.2%)\n",
            "Test data: 20 records (48.8%)\n",
            "After dropping NaN values - Train: 1, Test: 20\n",
            "⚠️ Skipping Mizoram - insufficient data after cleaning\n",
            "\n",
            "Processing state 20/31: Nagaland\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.970164\n",
            "lag_1m             0.955073\n",
            "rolling_mean_6m    0.901761\n",
            "ANNUAL             0.833618\n",
            "OND                0.831077\n",
            "lag_3m             0.825295\n",
            "MSP_Wheat          0.764570\n",
            "MSP_Wheat_KG       0.764570\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Nagaland\n",
            "================================================================================\n",
            "Found 123 records for Nagaland\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 88 records (71.5%)\n",
            "Test data: 35 records (28.5%)\n",
            "After dropping NaN values - Train: 76, Test: 35\n",
            "Final feature matrix shapes - X_train: (76, 25), X_test: (35, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 5.4358, R²: 0.6488\n",
            "Top 5 important features:\n",
            "   - MSP_to_retail_ratio: 0.6514\n",
            "   - rolling_mean_3m: 0.1415\n",
            "   - lag_1m: 0.0788\n",
            "   - rolling_std_6m: 0.0359\n",
            "   - rolling_mean_6m: 0.0342\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 4.9772, R²: 0.7055\n",
            "Top 5 important features:\n",
            "   - lag_3m: 0.3488\n",
            "   - MSP_to_retail_ratio: 0.2516\n",
            "   - rolling_mean_6m: 0.0882\n",
            "   - rolling_mean_3m: 0.0805\n",
            "   - year: 0.0679\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 24.4913\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Nagaland: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.0673\n",
            "   - test_rmse: 4.9772\n",
            "   - train_mae: 0.0506\n",
            "   - test_mae: 3.6232\n",
            "   - train_mape: 0.2093\n",
            "   - test_mape: 9.7128\n",
            "   - train_r2: 1.0000\n",
            "   - test_r2: 0.7055\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/nagaland_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/nagaland_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/nagaland_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/nagaland_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/nagaland_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/nagaland_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/nagaland_best_model.pkl\n",
            "✅ Successfully processed Nagaland\n",
            "\n",
            "Processing state 21/31: Orissa\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.997116\n",
            "lag_1m             0.995029\n",
            "rolling_mean_6m    0.992670\n",
            "lag_3m             0.984767\n",
            "lag_6m             0.974535\n",
            "MSP_Wheat_KG       0.969719\n",
            "MSP_Wheat          0.969719\n",
            "lag_12m            0.950152\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Orissa\n",
            "================================================================================\n",
            "Found 174 records for Orissa\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 138 records (79.3%)\n",
            "Test data: 36 records (20.7%)\n",
            "After dropping NaN values - Train: 87, Test: 36\n",
            "Final feature matrix shapes - X_train: (87, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 4.9234, R²: -67.5213\n",
            "Top 5 important features:\n",
            "   - CPI: 0.2112\n",
            "   - rolling_mean_3m: 0.1612\n",
            "   - year: 0.1516\n",
            "   - rolling_mean_6m: 0.1335\n",
            "   - MSP_Wheat_KG: 0.1081\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 3.5199, R²: -34.0241\n",
            "Top 5 important features:\n",
            "   - MSP_Wheat_KG: 0.4644\n",
            "   - CPI: 0.4622\n",
            "   - year: 0.0171\n",
            "   - lag_1m: 0.0127\n",
            "   - rolling_mean_3m: 0.0097\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 3.9760\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Orissa: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.1001\n",
            "   - test_rmse: 3.5199\n",
            "   - train_mae: 0.0663\n",
            "   - test_mae: 3.3982\n",
            "   - train_mape: 0.3959\n",
            "   - test_mape: 10.1048\n",
            "   - train_r2: 0.9997\n",
            "   - test_r2: -34.0241\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/orissa_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/orissa_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/orissa_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/orissa_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/orissa_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/orissa_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/orissa/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/orissa/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/orissa/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/orissa/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/orissa/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/orissa/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/orissa/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/orissa_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/orissa_best_model.pkl\n",
            "✅ Successfully processed Orissa\n",
            "\n",
            "Processing state 22/31: Puducherry\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.947999\n",
            "lag_1m             0.919493\n",
            "MSP_Wheat_KG       0.843505\n",
            "MSP_Wheat          0.843505\n",
            "msp_year           0.842547\n",
            "year               0.836874\n",
            "rolling_mean_6m    0.828812\n",
            "lag_3m             0.707011\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Puducherry\n",
            "================================================================================\n",
            "Found 78 records for Puducherry\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 52 records (66.7%)\n",
            "Test data: 26 records (33.3%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Puducherry - insufficient data after cleaning\n",
            "\n",
            "Processing state 23/31: Punjab\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.990961\n",
            "rolling_mean_6m    0.981796\n",
            "lag_1m             0.964806\n",
            "lag_3m             0.952290\n",
            "year               0.940151\n",
            "msp_year           0.935377\n",
            "MSP_Wheat          0.926581\n",
            "MSP_Wheat_KG       0.926581\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Punjab\n",
            "================================================================================\n",
            "Found 134 records for Punjab\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 98 records (73.1%)\n",
            "Test data: 36 records (26.9%)\n",
            "After dropping NaN values - Train: 86, Test: 36\n",
            "Final feature matrix shapes - X_train: (86, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 0.9112, R²: -0.2891\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3151\n",
            "   - lag_1m: 0.1821\n",
            "   - rolling_mean_6m: 0.1762\n",
            "   - MSP_Wheat_KG: 0.1203\n",
            "   - MSP_to_retail_ratio: 0.0556\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 0.8455, R²: -0.1099\n",
            "Top 5 important features:\n",
            "   - MSP_Wheat_KG: 0.5766\n",
            "   - CPI: 0.1318\n",
            "   - year: 0.0666\n",
            "   - rolling_mean_3m: 0.0437\n",
            "   - rolling_mean_6m: 0.0413\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 2.3688\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Punjab: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.0841\n",
            "   - test_rmse: 0.8455\n",
            "   - train_mae: 0.0543\n",
            "   - test_mae: 0.7041\n",
            "   - train_mape: 0.3056\n",
            "   - test_mape: 3.1548\n",
            "   - train_r2: 0.9978\n",
            "   - test_r2: -0.1099\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/punjab_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/punjab_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/punjab_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/punjab_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/punjab_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/punjab_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/punjab/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/punjab/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/punjab/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/punjab/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/punjab/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/punjab/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/punjab/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/punjab_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/punjab_best_model.pkl\n",
            "✅ Successfully processed Punjab\n",
            "\n",
            "Processing state 24/31: Rajasthan\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.996646\n",
            "rolling_mean_6m    0.993361\n",
            "lag_1m             0.992727\n",
            "lag_3m             0.984086\n",
            "lag_6m             0.979230\n",
            "MSP_Wheat_KG       0.977201\n",
            "MSP_Wheat          0.977201\n",
            "lag_12m            0.967716\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Rajasthan\n",
            "================================================================================\n",
            "Found 292 records for Rajasthan\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 256 records (87.7%)\n",
            "Test data: 36 records (12.3%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Rajasthan - insufficient data after cleaning\n",
            "\n",
            "Processing state 25/31: Sikkim\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.968801\n",
            "lag_1m             0.948113\n",
            "rolling_mean_6m    0.934039\n",
            "rolling_std_6m     0.918382\n",
            "roc_3m             0.817870\n",
            "lag_3m             0.783756\n",
            "rolling_std_3m     0.614148\n",
            "MSP_Wheat_KG       0.603755\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Sikkim\n",
            "================================================================================\n",
            "Found 25 records for Sikkim\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 0 records (0.0%)\n",
            "Test data: 25 records (100.0%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Sikkim - insufficient data after cleaning\n",
            "\n",
            "Processing state 26/31: Tamil Nadu\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.998875\n",
            "lag_1m             0.997563\n",
            "rolling_mean_6m    0.997434\n",
            "lag_3m             0.994488\n",
            "lag_6m             0.990685\n",
            "MSP_Wheat          0.984919\n",
            "MSP_Wheat_KG       0.984919\n",
            "lag_12m            0.983355\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Tamil Nadu\n",
            "================================================================================\n",
            "Found 314 records for Tamil Nadu\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 278 records (88.5%)\n",
            "Test data: 36 records (11.5%)\n",
            "After dropping NaN values - Train: 153, Test: 36\n",
            "Final feature matrix shapes - X_train: (153, 25), X_test: (36, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 2.4542, R²: -2.0429\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.4116\n",
            "   - rolling_mean_6m: 0.3580\n",
            "   - lag_1m: 0.1351\n",
            "   - lag_3m: 0.0574\n",
            "   - year: 0.0101\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 2.6648, R²: -2.5875\n",
            "Top 5 important features:\n",
            "   - year: 0.5378\n",
            "   - rolling_mean_6m: 0.2130\n",
            "   - rolling_mean_3m: 0.1002\n",
            "   - lag_1m: 0.0667\n",
            "   - lag_6m: 0.0269\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 1.1682\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Tamil Nadu: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.7900\n",
            "   - test_rmse: 1.1682\n",
            "   - train_mae: 0.5157\n",
            "   - test_mae: 0.9688\n",
            "   - train_mape: 2.1239\n",
            "   - test_mape: 2.6433\n",
            "   - train_r2: 0.9845\n",
            "   - test_r2: 0.3106\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/tamil nadu_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/tamil nadu_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu_best_model.pkl\n",
            "✅ Successfully processed Tamil Nadu\n",
            "\n",
            "Processing state 27/31: Telangana\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.995722\n",
            "rolling_mean_6m    0.991543\n",
            "lag_1m             0.991303\n",
            "lag_3m             0.982249\n",
            "lag_6m             0.973351\n",
            "MSP_Wheat_KG       0.968573\n",
            "MSP_Wheat          0.968573\n",
            "msp_year           0.957326\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Telangana\n",
            "================================================================================\n",
            "Found 153 records for Telangana\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 125 records (81.7%)\n",
            "Test data: 28 records (18.3%)\n",
            "After dropping NaN values - Train: 63, Test: 28\n",
            "Final feature matrix shapes - X_train: (63, 25), X_test: (28, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 3.1366, R²: -1.7398\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.4570\n",
            "   - rolling_mean_3m: 0.2019\n",
            "   - year: 0.1254\n",
            "   - MSP_Wheat_KG: 0.0635\n",
            "   - lag_1m: 0.0433\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 2.5392, R²: -0.7955\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.6853\n",
            "   - MSP_Wheat_KG: 0.0857\n",
            "   - rolling_mean_3m: 0.0609\n",
            "   - MSP_to_retail_ratio: 0.0336\n",
            "   - lag_12m: 0.0314\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 3.0535\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Telangana: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.1071\n",
            "   - test_rmse: 2.5392\n",
            "   - train_mae: 0.0642\n",
            "   - test_mae: 2.0579\n",
            "   - train_mape: 0.3247\n",
            "   - test_mape: 6.1197\n",
            "   - train_r2: 0.9997\n",
            "   - test_r2: -0.7955\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/telangana_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/telangana_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/telangana_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/telangana_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/telangana_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/telangana_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/telangana/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/telangana/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/telangana/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/telangana/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/telangana/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/telangana/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/telangana/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/telangana_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/telangana_best_model.pkl\n",
            "✅ Successfully processed Telangana\n",
            "\n",
            "Processing state 28/31: Tripura\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "year                                        NaN\n",
            "price                                       NaN\n",
            "CPI                                         NaN\n",
            "msp_year                                    NaN\n",
            "MSP_Wheat                                   NaN\n",
            "Diesel Price                                NaN\n",
            "Wheat Price (Indian Rupee per Metric Ton)   NaN\n",
            "Diesel ROC                                  NaN\n",
            "Wheat ROC                                   NaN\n",
            "Diesel / Wheat Price Ratio                  NaN\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Tripura\n",
            "================================================================================\n",
            "⚠️ Skipping Tripura - insufficient data (only 1 records)\n",
            "\n",
            "Processing state 29/31: Uttar Pradesh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.996179\n",
            "lag_1m             0.992883\n",
            "rolling_mean_6m    0.990952\n",
            "lag_3m             0.979976\n",
            "MSP_Wheat          0.979790\n",
            "MSP_Wheat_KG       0.979790\n",
            "lag_6m             0.970929\n",
            "year               0.968669\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Uttar Pradesh\n",
            "================================================================================\n",
            "Found 306 records for Uttar Pradesh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 270 records (88.2%)\n",
            "Test data: 36 records (11.8%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Uttar Pradesh - insufficient data after cleaning\n",
            "\n",
            "Processing state 30/31: Uttarakhand\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.982989\n",
            "lag_1m             0.969170\n",
            "rolling_mean_6m    0.951346\n",
            "lag_3m             0.907491\n",
            "MSP_Wheat_KG       0.881051\n",
            "MSP_Wheat          0.881051\n",
            "year               0.869378\n",
            "msp_year           0.867749\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Uttarakhand\n",
            "================================================================================\n",
            "Found 102 records for Uttarakhand\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 71 records (69.6%)\n",
            "Test data: 31 records (30.4%)\n",
            "After dropping NaN values - Train: 59, Test: 31\n",
            "Final feature matrix shapes - X_train: (59, 25), X_test: (31, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 2.2336, R²: 0.1460\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3392\n",
            "   - rolling_mean_6m: 0.2596\n",
            "   - lag_1m: 0.1132\n",
            "   - MSP_Wheat_KG: 0.1056\n",
            "   - year: 0.0539\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 1.6941, R²: 0.5088\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.3066\n",
            "   - MSP_Wheat_KG: 0.1675\n",
            "   - year: 0.1238\n",
            "   - rolling_mean_3m: 0.1234\n",
            "   - lag_6m: 0.1014\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 6.7719\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Uttarakhand: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.0997\n",
            "   - test_rmse: 1.6941\n",
            "   - train_mae: 0.0588\n",
            "   - test_mae: 1.4444\n",
            "   - train_mape: 0.3085\n",
            "   - test_mape: 6.3961\n",
            "   - train_r2: 0.9989\n",
            "   - test_r2: 0.5088\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand_best_model.pkl\n",
            "✅ Successfully processed Uttarakhand\n",
            "\n",
            "Processing state 31/31: West Bengal\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.991265\n",
            "lag_1m             0.983536\n",
            "rolling_mean_6m    0.980504\n",
            "MSP_Wheat_KG       0.977476\n",
            "MSP_Wheat          0.977476\n",
            "year               0.971739\n",
            "msp_year           0.970974\n",
            "lag_3m             0.955344\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: West Bengal\n",
            "================================================================================\n",
            "Found 165 records for West Bengal\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 130 records (78.8%)\n",
            "Test data: 35 records (21.2%)\n",
            "After dropping NaN values - Train: 82, Test: 35\n",
            "Final feature matrix shapes - X_train: (82, 25), X_test: (35, 25)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Random Forest metrics - Test RMSE: 1.7884, R²: 0.3017\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.7072\n",
            "   - lag_1m: 0.1187\n",
            "   - rolling_mean_6m: 0.0743\n",
            "   - MSP_to_retail_ratio: 0.0167\n",
            "   - diesel_price: 0.0140\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "XGBoost metrics - Test RMSE: 1.9416, R²: 0.1770\n",
            "Top 5 important features:\n",
            "   - year: 0.3140\n",
            "   - rolling_mean_3m: 0.2239\n",
            "   - lag_1m: 0.1496\n",
            "   - CPI: 0.1188\n",
            "   - rolling_mean_6m: 0.1044\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Holt-Winters metrics - Test RMSE: 3.9181\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for West Bengal: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.3606\n",
            "   - test_rmse: 1.7884\n",
            "   - train_mae: 0.2440\n",
            "   - test_mae: 1.4809\n",
            "   - train_mape: 1.3313\n",
            "   - test_mape: 5.9852\n",
            "   - train_r2: 0.9887\n",
            "   - test_r2: 0.3017\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/west bengal_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/west bengal_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/west bengal_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/west bengal_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/west bengal_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/west bengal_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/west bengal_best_model.pkl\n",
            "✅ Successfully processed West Bengal\n",
            "\n",
            "================================================================================\n",
            "Step 5: Aggregating models to S3\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "📦 Aggregating models across all states to S3\n",
            "================================================================================\n",
            "Aggregating models for 21/21 states\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_best_model_20250419_124048.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "✅ Saved combined model to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_best_model_20250419_124048.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_best_model_latest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "✅ Saved latest version to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_best_model_latest.pkl\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_metadata_20250419_124048.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved metadata to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_metadata_20250419_124048.json\n",
            "\n",
            "================================================================================\n",
            "Step 6: Results summary\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "📊 Summary of Results\n",
            "================================================================================\n",
            "State                Best Model      Test RMSE    Test MAPE    R²      \n",
            "--------------------------------------------------------------------------------\n",
            "Andaman And Nicobar  random_forest   2.4941       4.99%        -2.4182 \n",
            "Andhra Pradesh       xgboost         3.3055       6.98%        -0.5885 \n",
            "Assam                random_forest   1.1689       3.26%        0.6758  \n",
            "Bihar                random_forest   1.4489       4.15%        0.6543  \n",
            "Chandigarh           random_forest   1.5562       5.12%        0.5651  \n",
            "Delhi                random_forest   1.0122       3.19%        0.8041  \n",
            "Goa                  holt_winters    2.1603       5.04%        0.0975  \n",
            "Gujarat              holt_winters    3.9267       11.64%       -0.7795 \n",
            "Haryana              holt_winters    0.9177       3.35%        0.4417  \n",
            "Himachal Pradesh     xgboost         4.7876       17.43%       -2.2973 \n",
            "Jharkhand            xgboost         1.2306       3.56%        0.7431  \n",
            "Kerala               holt_winters    2.6003       6.17%        0.0264  \n",
            "Maharashtra          holt_winters    2.2955       5.19%        -0.0413 \n",
            "Meghalaya            random_forest   2.3687       4.99%        0.2994  \n",
            "Nagaland             xgboost         4.9772       9.71%        0.7055  \n",
            "Orissa               xgboost         3.5199       10.10%       -34.0241\n",
            "Punjab               xgboost         0.8455       3.15%        -0.1099 \n",
            "Tamil Nadu           holt_winters    1.1682       2.64%        0.3106  \n",
            "Telangana            xgboost         2.5392       6.12%        -0.7955 \n",
            "Uttarakhand          xgboost         1.6941       6.40%        0.5088  \n",
            "West Bengal          random_forest   1.7884       5.99%        0.3017  \n",
            "================================================================================\n",
            "✅ Successfully processed 21/21 states\n",
            "\n",
            "================================================================================\n",
            "✅ Wheat price forecasting process completed successfully\n",
            "✅ All outputs saved to S3: s3://foundation-project-data/wheat_forecaster/\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
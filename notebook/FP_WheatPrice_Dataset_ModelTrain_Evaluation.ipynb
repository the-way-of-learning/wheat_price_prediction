{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GWqANkvn7z_9",
        "outputId": "04e4c828-a2a4-43f9-f3c8-b8d20dccbd40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.21.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.37.37-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Collecting mlflow-skinny==2.21.3 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.21.3-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.8)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading databricks_sdk-0.50.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (1.32.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (2.11.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (4.13.2)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting botocore<1.38.0,>=1.37.37 (from boto3)\n",
            "  Downloading botocore-1.37.37-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
            "  Downloading s3transfer-0.11.5-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.37->boto3) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (2.38.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.3->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (0.53b1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (2025.1.31)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.21.3->mlflow) (0.14.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.21.3-py3-none-any.whl (28.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.21.3-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.37-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.37-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.50.0-py3-none-any.whl (692 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m692.3/692.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, jmespath, gunicorn, graphql-core, starlette, graphql-relay, docker, botocore, alembic, s3transfer, graphene, fastapi, databricks-sdk, boto3, mlflow-skinny, mlflow\n",
            "Successfully installed alembic-1.15.2 boto3-1.37.37 botocore-1.37.37 databricks-sdk-0.50.0 docker-7.1.0 fastapi-0.115.12 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 mlflow-2.21.3 mlflow-skinny-2.21.3 s3transfer-0.11.5 starlette-0.46.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost statsmodels matplotlib seaborn plotly mlflow boto3\n",
        "# print(\"Required packages installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import warnings\n",
        "import logging\n",
        "import boto3\n",
        "from io import StringIO\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "# Configure prettier plots\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"muted\")\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress warnings for cleaner notebook output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(\"Environment setup complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRdpDtc18GNs",
        "outputId": "91d3a2da-444b-4698-dfa8-4967b12b512b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n",
            "Environment setup complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class S3Connector:\n",
        "    \"\"\"Utility class for connecting to S3 and retrieving files.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 aws_access_key_id=None,\n",
        "                 aws_secret_access_key=None,\n",
        "                 region_name='us-east-1'):\n",
        "        \"\"\"\n",
        "        Initialize S3 client.\n",
        "\n",
        "        Args:\n",
        "            aws_access_key_id (str, optional): AWS access key ID\n",
        "            aws_secret_access_key (str, optional): AWS secret access key\n",
        "            region_name (str, optional): AWS region name\n",
        "        \"\"\"\n",
        "        self.s3_client = boto3.client(\n",
        "            's3',\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key,\n",
        "            region_name=region_name\n",
        "        )\n",
        "        self.region_name = region_name\n",
        "        print(f\"✅ S3 client initialized for region: {region_name}\")\n",
        "\n",
        "    def read_csv_from_s3(self, bucket_name, key):\n",
        "        \"\"\"\n",
        "        Read CSV file from S3 bucket.\n",
        "\n",
        "        Args:\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: DataFrame containing CSV data\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Reading file from S3: s3://{bucket_name}/{key}\")\n",
        "            response = self.s3_client.get_object(Bucket=bucket_name, Key=key)\n",
        "            csv_content = response['Body'].read().decode('utf-8')\n",
        "            df = pd.read_csv(StringIO(csv_content))\n",
        "            print(f\"✅ Successfully read CSV from S3 with {len(df):,} rows\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading file from S3: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def save_file_to_s3(self, local_file_path, bucket_name, key):\n",
        "        \"\"\"\n",
        "        Save a local file to S3 bucket.\n",
        "\n",
        "        Args:\n",
        "            local_file_path (str): Local file path\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Uploading file to S3: s3://{bucket_name}/{key}\")\n",
        "            self.s3_client.upload_file(local_file_path, bucket_name, key)\n",
        "            print(f\"✅ Successfully uploaded file to S3\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error uploading file to S3: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_data_to_s3(self, data, bucket_name, key, content_type=None):\n",
        "        \"\"\"\n",
        "        Save data directly to S3 without creating a local file first.\n",
        "\n",
        "        Args:\n",
        "            data: Data to save (bytes, string, or serializable object)\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "            content_type (str, optional): Content type of the data\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Saving data to S3: s3://{bucket_name}/{key}\")\n",
        "\n",
        "            # Handle different data types\n",
        "            if isinstance(data, bytes):\n",
        "                body = data\n",
        "            elif isinstance(data, str):\n",
        "                body = data.encode('utf-8')\n",
        "            else:\n",
        "                # For other objects like dictionaries, try to JSON serialize\n",
        "                try:\n",
        "                    body = json.dumps(data).encode('utf-8')\n",
        "                    if not content_type:\n",
        "                        content_type = 'application/json'\n",
        "                except:\n",
        "                    print(f\"❌ Error: Data type not supported for direct S3 upload\")\n",
        "                    return False\n",
        "\n",
        "            # Set up the upload parameters\n",
        "            params = {\n",
        "                'Bucket': bucket_name,\n",
        "                'Key': key,\n",
        "                'Body': body\n",
        "            }\n",
        "\n",
        "            if content_type:\n",
        "                params['ContentType'] = content_type\n",
        "\n",
        "            # Upload the data\n",
        "            self.s3_client.put_object(**params)\n",
        "            print(f\"✅ Successfully saved data to S3\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error saving data to S3: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_pickle_to_s3(self, obj, bucket_name, key):\n",
        "        \"\"\"\n",
        "        Pickle an object and save it directly to S3.\n",
        "\n",
        "        Args:\n",
        "            obj: Python object to pickle\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Saving pickled object to S3: s3://{bucket_name}/{key}\")\n",
        "\n",
        "            # Pickle the object to a bytes buffer\n",
        "            import pickle\n",
        "            from io import BytesIO\n",
        "\n",
        "            buffer = BytesIO()\n",
        "            pickle.dump(obj, buffer)\n",
        "            buffer.seek(0)\n",
        "\n",
        "            # Upload the pickled object\n",
        "            self.s3_client.upload_fileobj(buffer, bucket_name, key)\n",
        "            print(f\"✅ Successfully saved pickled object to S3\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error pickling object to S3: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_figure_to_s3(self, figure, bucket_name, key, dpi=300, format='png'):\n",
        "        \"\"\"\n",
        "        Save a matplotlib figure directly to S3.\n",
        "\n",
        "        Args:\n",
        "            figure: Matplotlib figure object\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "            dpi (int): DPI for the figure\n",
        "            format (str): Format to save the figure ('png', 'jpg', etc.)\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"Saving figure to S3: s3://{bucket_name}/{key}\")\n",
        "\n",
        "            # Save figure to a bytes buffer\n",
        "            from io import BytesIO\n",
        "            buffer = BytesIO()\n",
        "            figure.savefig(buffer, format=format, dpi=dpi)\n",
        "            buffer.seek(0)\n",
        "\n",
        "            # Set appropriate content type based on format\n",
        "            content_type = f\"image/{format}\"\n",
        "\n",
        "            # Upload the figure\n",
        "            self.s3_client.upload_fileobj(\n",
        "                buffer,\n",
        "                bucket_name,\n",
        "                key,\n",
        "                ExtraArgs={'ContentType': content_type}\n",
        "            )\n",
        "            print(f\"✅ Successfully saved figure to S3\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error saving figure to S3: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def check_s3_path_exists(self, bucket_name, prefix):\n",
        "        \"\"\"\n",
        "        Check if an S3 path (prefix) exists.\n",
        "\n",
        "        Args:\n",
        "            bucket_name (str): S3 bucket name\n",
        "            prefix (str): Path prefix to check\n",
        "\n",
        "        Returns:\n",
        "            bool: True if path exists, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Ensure the prefix ends with a slash if it's meant to be a directory\n",
        "            if prefix and not prefix.endswith('/'):\n",
        "                prefix += '/'\n",
        "\n",
        "            response = self.s3_client.list_objects_v2(\n",
        "                Bucket=bucket_name,\n",
        "                Prefix=prefix,\n",
        "                MaxKeys=1\n",
        "            )\n",
        "\n",
        "            return 'Contents' in response\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error checking S3 path: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def create_s3_directory(self, bucket_name, directory):\n",
        "        \"\"\"\n",
        "        Create a directory structure in S3 (by adding an empty object with trailing slash).\n",
        "\n",
        "        Args:\n",
        "            bucket_name (str): S3 bucket name\n",
        "            directory (str): Directory path to create\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Ensure the directory path ends with a slash\n",
        "            if not directory.endswith('/'):\n",
        "                directory += '/'\n",
        "\n",
        "            # Create an empty object with the directory name (S3 convention for directories)\n",
        "            self.s3_client.put_object(\n",
        "                Bucket=bucket_name,\n",
        "                Key=directory,\n",
        "                Body=''\n",
        "            )\n",
        "\n",
        "            print(f\"✅ Created S3 directory: s3://{bucket_name}/{directory}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error creating S3 directory: {str(e)}\")\n",
        "            return False"
      ],
      "metadata": {
        "id": "4dHSpcfu8LbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataUtils:\n",
        "    \"\"\"Utility class for data loading and preprocessing operations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_data(s3_connector, bucket_name, key):\n",
        "        \"\"\"\n",
        "        Load data from S3 bucket.\n",
        "\n",
        "        Args:\n",
        "            s3_connector (S3Connector): S3 connector instance\n",
        "            bucket_name (str): S3 bucket name\n",
        "            key (str): Object key (file path in bucket)\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: Loaded data\n",
        "        \"\"\"\n",
        "        print(f\"Loading data from S3: s3://{bucket_name}/{key}\")\n",
        "        data = s3_connector.read_csv_from_s3(bucket_name, key)\n",
        "\n",
        "        if data is None:\n",
        "            print(f\"❌ Error loading data from S3\")\n",
        "            return None\n",
        "\n",
        "        print(f\"✅ Successfully loaded {len(data):,} records with {len(data.columns)} columns\")\n",
        "\n",
        "        # Display sample data\n",
        "        print(\"\\n📊 Data Preview:\")\n",
        "        print(data.head())\n",
        "\n",
        "        # Display data info\n",
        "        print(\"\\n📋 Data Information:\")\n",
        "        print(f\"Shape: {data.shape}\")\n",
        "        print(f\"Columns: {', '.join(data.columns)}\")\n",
        "        print(f\"Date range: {pd.to_datetime(data['date']).min()} to {pd.to_datetime(data['date']).max()}\")\n",
        "\n",
        "        # Check for missing values\n",
        "        missing_values = data.isnull().sum().sum()\n",
        "        print(f\"Missing values: {missing_values:,} ({missing_values/data.size:.2%} of all data)\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def create_output_dirs(output_dir):\n",
        "        \"\"\"\n",
        "        Create output directories for models and plots.\n",
        "\n",
        "        Args:\n",
        "            output_dir (str): Base output directory\n",
        "\n",
        "        Returns:\n",
        "            tuple: Paths to model registry and plots directories\n",
        "        \"\"\"\n",
        "        print(f\"Creating output directories in: {output_dir}\")\n",
        "\n",
        "        # Create main output directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Create subdirectories\n",
        "        model_registry_dir = os.path.join(output_dir, \"model_registry\")\n",
        "        plots_dir = os.path.join(output_dir, \"plots\")\n",
        "\n",
        "        os.makedirs(model_registry_dir, exist_ok=True)\n",
        "        os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"✅ Created directory structure:\")\n",
        "        print(f\"  - 📁 {output_dir} (main)\")\n",
        "        print(f\"  - 📁 {model_registry_dir} (models)\")\n",
        "        print(f\"  - 📁 {plots_dir} (visualizations)\")\n",
        "\n",
        "        return model_registry_dir, plots_dir\n"
      ],
      "metadata": {
        "id": "uCeTTdse8OGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "    \"\"\"Class for preprocessing wheat price data.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the preprocessor.\"\"\"\n",
        "        self.date_col = None\n",
        "\n",
        "    def preprocess_retail_prices(self, raw_data):\n",
        "        \"\"\"\n",
        "        Preprocess retail price data.\n",
        "\n",
        "        Args:\n",
        "            raw_data (pandas.DataFrame): Raw input data\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: Preprocessed retail data\n",
        "        \"\"\"\n",
        "        print(\"Starting data preprocessing...\")\n",
        "\n",
        "        # Convert MSP from quintal to KG\n",
        "        if 'MSP_Wheat' in raw_data.columns:\n",
        "            raw_data['MSP_Wheat_KG'] = raw_data['MSP_Wheat'] / 100\n",
        "            print(\"Converted MSP from quintal to KG\")\n",
        "        else:\n",
        "            raw_data['MSP_Wheat_KG'] = 0\n",
        "            print(\"MSP_Wheat column not found, using 0 as default\")\n",
        "\n",
        "        # Keep only retail prices if price type available\n",
        "        if 'pricetype' in raw_data.columns:\n",
        "            df_retail = raw_data[raw_data['pricetype'].str.lower() == 'retail'].copy()\n",
        "            print(f\"Filtered {len(df_retail):,} retail price records\")\n",
        "        else:\n",
        "            df_retail = raw_data.copy()\n",
        "            print(f\"No price type column found. Using all {len(df_retail):,} records\")\n",
        "\n",
        "        # Initialize price_per_KG column\n",
        "        if 'price' in df_retail.columns:\n",
        "            df_retail['price_per_KG'] = df_retail['price']\n",
        "            print(\"Using 'price' column as price_per_KG\")\n",
        "        else:\n",
        "            df_retail['price_per_KG'] = 0\n",
        "            print(\"No price column found, using 0 as default\")\n",
        "\n",
        "        # Drop rows with missing state values\n",
        "        if 'state' in df_retail.columns:\n",
        "            pre_count = len(df_retail)\n",
        "            df_retail = df_retail[df_retail['state'].notna() & (df_retail['state'].str.strip() != '')]\n",
        "            dropped = pre_count - len(df_retail)\n",
        "            print(f\"Dropped {dropped:,} rows with missing states ({dropped/pre_count:.2%})\")\n",
        "            print(f\"Remaining records: {len(df_retail):,}\")\n",
        "\n",
        "        # Convert date to datetime\n",
        "        self.date_col = self._find_date_column(df_retail)\n",
        "\n",
        "        if self.date_col:\n",
        "            print(f\"Converting '{self.date_col}' to datetime\")\n",
        "            df_retail['date'] = pd.to_datetime(df_retail[self.date_col])\n",
        "        else:\n",
        "            print(\"❌ No date column found. Cannot proceed with time-based modeling\")\n",
        "            return None\n",
        "\n",
        "        # Extract time features\n",
        "        print(\"Extracting time features...\")\n",
        "        df_retail = self._add_time_features(df_retail)\n",
        "\n",
        "        # Sort for logical imputation order\n",
        "        df_retail = df_retail.sort_values(['state', 'date'])\n",
        "        print(\"Sorted data by state and date\")\n",
        "\n",
        "        # Handle missing values\n",
        "        print(\"Handling missing values...\")\n",
        "        df_retail = self._handle_missing_values(df_retail)\n",
        "\n",
        "        # Filter for wheat only if commodity column exists\n",
        "        if 'commodity' in df_retail.columns:\n",
        "            pre_count = len(df_retail)\n",
        "            wheat_data = df_retail[df_retail['commodity'].str.lower() == 'wheat'].copy()\n",
        "            print(f\"Filtered for wheat commodity: {len(wheat_data):,} records from {pre_count:,}\")\n",
        "        else:\n",
        "            wheat_data = df_retail.copy()\n",
        "            print(f\"No commodity column found. Using all {len(wheat_data):,} records\")\n",
        "\n",
        "        print(\"✅ Preprocessing complete\")\n",
        "\n",
        "        # Display summary statistics\n",
        "        print(\"\\n📊 Summary Statistics for Preprocessed Data:\")\n",
        "        print(wheat_data.describe())\n",
        "\n",
        "        return wheat_data\n",
        "\n",
        "    def _find_date_column(self, df):\n",
        "        \"\"\"Find the date column in the dataframe.\"\"\"\n",
        "        date_candidates = ['date', 'date_x', 'Date']\n",
        "        for col in date_candidates:\n",
        "            if col in df.columns:\n",
        "                return col\n",
        "        return None\n",
        "\n",
        "    def _add_time_features(self, df):\n",
        "        \"\"\"Add time-based features to the dataframe.\"\"\"\n",
        "        # Basic time components\n",
        "        df['year'] = df['date'].dt.year\n",
        "        df['month_num'] = df['date'].dt.month\n",
        "        df['day'] = df['date'].dt.day\n",
        "        df['quarter'] = df['date'].dt.quarter\n",
        "\n",
        "        # Cyclical time features - these capture seasonality better\n",
        "        df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
        "        df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
        "        df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)\n",
        "        df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)\n",
        "\n",
        "        print(\"Added time features: year, month, day, quarter\")\n",
        "        print(\"Added cyclical features: month_sin, month_cos, quarter_sin, quarter_cos\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _handle_missing_values(self, df):\n",
        "        \"\"\"Handle missing values in the dataframe.\"\"\"\n",
        "        # Fill Rainfall using state and month group mean\n",
        "        if 'Rainfall' in df.columns:\n",
        "            missing_before = df['Rainfall'].isna().sum()\n",
        "            df['Rainfall'] = df.groupby(['state', 'month_num'])['Rainfall'].transform(\n",
        "                lambda x: x.fillna(x.mean())\n",
        "            )\n",
        "            missing_after = df['Rainfall'].isna().sum()\n",
        "            print(f\"Filled {missing_before - missing_after:,} missing Rainfall values\")\n",
        "\n",
        "        # Fill diesel price forward within each state\n",
        "        if 'Diesel Price' in df.columns:\n",
        "            missing_before = df['Diesel Price'].isna().sum()\n",
        "            df['diesel_price'] = df.groupby('state')['Diesel Price'].ffill()\n",
        "            missing_after = df['diesel_price'].isna().sum()\n",
        "            print(f\"Filled {missing_before - missing_after:,} missing Diesel Price values\")\n",
        "\n",
        "        # Convert ROC columns to numeric and handle missing values\n",
        "        if 'Diesel ROC' in df.columns:\n",
        "            df['Diesel ROC'] = pd.to_numeric(df['Diesel ROC'], errors='coerce')\n",
        "            missing_before = df['Diesel ROC'].isna().sum()\n",
        "            df['Diesel ROC'].fillna(method='ffill', inplace=True)\n",
        "            missing_after = df['Diesel ROC'].isna().sum()\n",
        "            print(f\"Filled {missing_before - missing_after:,} missing Diesel ROC values\")\n",
        "\n",
        "        if 'Wheat ROC' in df.columns:\n",
        "            df['Wheat ROC'] = pd.to_numeric(df['Wheat ROC'], errors='coerce')\n",
        "            missing_before = df['Wheat ROC'].isna().sum()\n",
        "            df['Wheat ROC'].fillna(method='ffill', inplace=True)\n",
        "            missing_after = df['Wheat ROC'].isna().sum()\n",
        "            print(f\"Filled {missing_before - missing_after:,} missing Wheat ROC values\")\n",
        "\n",
        "        # Calculate price ratios if not already present\n",
        "        if 'diesel_price' in df.columns and 'price_per_KG' in df.columns:\n",
        "            df['Diesel / Wheat Price Ratio'] = df['diesel_price'] / df['price_per_KG'].replace(0, np.nan)\n",
        "            print(\"Calculated 'Diesel / Wheat Price Ratio'\")\n",
        "\n",
        "        # Report remaining missing values\n",
        "        missing_counts = df.isnull().sum()\n",
        "        if missing_counts.sum() > 0:\n",
        "            print(\"\\nRemaining missing values:\")\n",
        "            for col in missing_counts[missing_counts > 0].index:\n",
        "                print(f\"- {col}: {missing_counts[col]:,} missing values\")\n",
        "        else:\n",
        "            print(\"No missing values remain in the dataset\")\n",
        "\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "0s5DuQV48Q0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer:\n",
        "    \"\"\"Class for feature engineering on time series data.\"\"\"\n",
        "\n",
        "    def engineer_features(self, df_state):\n",
        "        \"\"\"\n",
        "        Add time series features to the data.\n",
        "\n",
        "        Args:\n",
        "            df_state (pandas.DataFrame): State data with date index\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: Data with added features\n",
        "        \"\"\"\n",
        "        print(\"Adding time series features...\")\n",
        "\n",
        "        # Set date as index if not already\n",
        "        if not isinstance(df_state.index, pd.DatetimeIndex):\n",
        "            if 'date' in df_state.columns:\n",
        "                df_state = df_state.set_index('date', drop=False)\n",
        "                df_state = df_state.sort_index()\n",
        "                print(\"Set date as index and sorted data\")\n",
        "\n",
        "        # Add time lags for price\n",
        "        for lag in [1, 3, 6, 12]:  # 1, 3, 6, 12 month lags\n",
        "            lag_col = f'lag_{lag}m'\n",
        "            df_state[lag_col] = df_state['price_per_KG'].shift(lag)\n",
        "            print(f\"Added {lag_col} feature\")\n",
        "\n",
        "        # Add rolling statistics\n",
        "        for window in [3, 6]:\n",
        "            # Rolling mean\n",
        "            mean_col = f'rolling_mean_{window}m'\n",
        "            df_state[mean_col] = df_state['price_per_KG'].rolling(window=window).mean()\n",
        "            print(f\"Added {mean_col} feature\")\n",
        "\n",
        "            # Rolling std\n",
        "            std_col = f'rolling_std_{window}m'\n",
        "            df_state[std_col] = df_state['price_per_KG'].rolling(window=window).std()\n",
        "            print(f\"Added {std_col} feature\")\n",
        "\n",
        "        # Calculate rate of change\n",
        "        for period in [1, 3]:\n",
        "            roc_col = f'roc_{period}m'\n",
        "            df_state[roc_col] = df_state['price_per_KG'].pct_change(periods=period)\n",
        "            print(f\"Added {roc_col} feature\")\n",
        "\n",
        "        # Add MSP to retail price ratio\n",
        "        if 'MSP_Wheat_KG' in df_state.columns:\n",
        "            df_state['MSP_to_retail_ratio'] = df_state['MSP_Wheat_KG'] / df_state['price_per_KG']\n",
        "            print(\"Added MSP_to_retail_ratio feature\")\n",
        "\n",
        "        # Report on engineered features\n",
        "        feature_count = len(df_state.columns) - len(df_state.select_dtypes(include=['object']).columns)\n",
        "        print(f\"✅ Feature engineering complete. Dataset now has {feature_count} numeric features\")\n",
        "\n",
        "        # Display correlations with target\n",
        "        print(\"\\n📊 Correlation with price_per_KG:\")\n",
        "        # Select only numeric columns before calculating correlation\n",
        "        numeric_df_state = df_state.select_dtypes(include=['number'])\n",
        "        correlations = numeric_df_state.corr()['price_per_KG'].sort_values(ascending=False)\n",
        "        print(correlations.head(10))\n",
        "\n",
        "        return df_state\n"
      ],
      "metadata": {
        "id": "xSlCSASM8T-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    \"\"\"Class for training and evaluating forecasting models with MLflow tracking.\"\"\"\n",
        "\n",
        "    def __init__(self, s3_connector, s3_bucket, output_prefix, mlflow_tracking_uri=None):\n",
        "        \"\"\"\n",
        "        Initialize the model trainer with S3 storage and MLflow tracking.\n",
        "\n",
        "        Args:\n",
        "            s3_connector (S3Connector): S3 connector instance\n",
        "            s3_bucket (str): S3 bucket for saving models and plots\n",
        "            output_prefix (str): Prefix path in the S3 bucket\n",
        "            mlflow_tracking_uri (str, optional): MLflow tracking URI\n",
        "        \"\"\"\n",
        "        self.s3_connector = s3_connector\n",
        "        self.s3_bucket = s3_bucket\n",
        "        self.output_prefix = output_prefix\n",
        "        self.feature_cols = None\n",
        "\n",
        "        # Set up MLflow\n",
        "        self.mlflow_uri = mlflow_tracking_uri\n",
        "        if mlflow_tracking_uri:\n",
        "            mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
        "            self.client = MlflowClient(tracking_uri=mlflow_tracking_uri)\n",
        "            print(f\"✅ MLflow tracking configured: {mlflow_tracking_uri}\")\n",
        "        else:\n",
        "            self.client = None\n",
        "            print(\"ℹ️ MLflow tracking not configured\")\n",
        "\n",
        "        # Create S3 directory structure\n",
        "        self.model_registry_prefix = f\"{output_prefix}/model_registry\"\n",
        "        self.plots_prefix = f\"{output_prefix}/plots\"\n",
        "\n",
        "        # Ensure directories exist in S3\n",
        "        self.s3_connector.create_s3_directory(s3_bucket, self.model_registry_prefix)\n",
        "        self.s3_connector.create_s3_directory(s3_bucket, self.plots_prefix)\n",
        "\n",
        "        print(f\"✅ Set up S3 directory structure:\")\n",
        "        print(f\"  - 📁 s3://{s3_bucket}/{self.model_registry_prefix} (models)\")\n",
        "        print(f\"  - 📁 s3://{s3_bucket}/{self.plots_prefix} (visualizations)\")\n",
        "\n",
        "    def train_models_for_state(self, state, df_state, split_date):\n",
        "        \"\"\"\n",
        "        Train models for a specific state.\n",
        "\n",
        "        Args:\n",
        "            state (str): State name\n",
        "            df_state (pandas.DataFrame): Preprocessed data for the state\n",
        "            split_date (str): Date to split train/test data\n",
        "\n",
        "        Returns:\n",
        "            dict: State model results\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"📌 Processing state: {state.title()}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        try:\n",
        "            # Check if we have enough data\n",
        "            if len(df_state) < 24:  # Skip states with insufficient data\n",
        "                print(f\"⚠️ Skipping {state.title()} - insufficient data (only {len(df_state)} records)\")\n",
        "                return None\n",
        "\n",
        "            print(f\"Found {len(df_state):,} records for {state.title()}\")\n",
        "\n",
        "            # Define feature columns based on available columns\n",
        "            self.feature_cols = self._get_feature_columns(df_state)\n",
        "\n",
        "            # Prepare data for modeling\n",
        "            print(f\"Preparing train/test split using date {split_date}\")\n",
        "\n",
        "            # Split based on date\n",
        "            train_data = df_state[df_state.index < split_date].copy()\n",
        "            test_data = df_state[df_state.index >= split_date].copy()\n",
        "\n",
        "            print(f\"Train data: {len(train_data):,} records ({len(train_data)/len(df_state):.1%})\")\n",
        "            print(f\"Test data: {len(test_data):,} records ({len(test_data)/len(df_state):.1%})\")\n",
        "\n",
        "            # Drop rows with NaN values in key columns\n",
        "            train_data = train_data.dropna(subset=['price_per_KG'] +\n",
        "                                         [col for col in self.feature_cols if col in train_data.columns])\n",
        "            test_data = test_data.dropna(subset=['price_per_KG'] +\n",
        "                                        [col for col in self.feature_cols if col in test_data.columns])\n",
        "\n",
        "            print(f\"After dropping NaN values - Train: {len(train_data):,}, Test: {len(test_data):,}\")\n",
        "\n",
        "            if len(train_data) < 12 or len(test_data) < 4:\n",
        "                print(f\"⚠️ Skipping {state.title()} - insufficient data after cleaning\")\n",
        "                return None\n",
        "\n",
        "            # Feature scaling\n",
        "            scaler_features = StandardScaler()\n",
        "\n",
        "            # Extract features and target\n",
        "            X_train = pd.DataFrame(\n",
        "                scaler_features.fit_transform(train_data[self.feature_cols]),\n",
        "                columns=self.feature_cols,\n",
        "                index=train_data.index\n",
        "            )\n",
        "            y_train = train_data['price_per_KG'].values\n",
        "\n",
        "            X_test = pd.DataFrame(\n",
        "                scaler_features.transform(test_data[self.feature_cols]),\n",
        "                columns=self.feature_cols,\n",
        "                index=test_data.index\n",
        "            )\n",
        "            y_test = test_data['price_per_KG'].values\n",
        "\n",
        "            print(f\"Final feature matrix shapes - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "\n",
        "            # Train models\n",
        "            models = {}\n",
        "            model_metrics = {}\n",
        "\n",
        "            # Create MLflow experiment for the state if MLflow is configured\n",
        "            if self.mlflow_uri:\n",
        "                experiment_name = f\"wheat_price_forecast_{state}\"\n",
        "                try:\n",
        "                    experiment = self.client.get_experiment_by_name(experiment_name)\n",
        "                    if experiment:\n",
        "                        experiment_id = experiment.experiment_id\n",
        "                    else:\n",
        "                        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "                    print(f\"✅ MLflow experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ Error with MLflow experiment: {str(e)}\")\n",
        "                    experiment_id = None\n",
        "            else:\n",
        "                experiment_id = None\n",
        "\n",
        "            # 1. Random Forest\n",
        "            print(\"\\n🔹 Training Random Forest model...\")\n",
        "            rf_model, rf_metrics, rf_importance = self._train_random_forest(\n",
        "                X_train, y_train, X_test, y_test, state, experiment_id\n",
        "            )\n",
        "            models['random_forest'] = rf_model\n",
        "            model_metrics['random_forest'] = rf_metrics\n",
        "\n",
        "            # 2. XGBoost\n",
        "            print(\"\\n🔹 Training XGBoost model...\")\n",
        "            xgb_model, xgb_metrics, xgb_importance = self._train_xgboost(\n",
        "                X_train, y_train, X_test, y_test, state, experiment_id\n",
        "            )\n",
        "            models['xgboost'] = xgb_model\n",
        "            model_metrics['xgboost'] = xgb_metrics\n",
        "\n",
        "            # 3. Holt-Winters\n",
        "            print(\"\\n🔹 Training Holt-Winters model...\")\n",
        "            hw_fit, hw_metrics = self._train_holt_winters(\n",
        "                train_data, test_data, state, experiment_id\n",
        "            )\n",
        "\n",
        "            if hw_fit is not None:\n",
        "                models['holt_winters'] = hw_fit\n",
        "                model_metrics['holt_winters'] = hw_metrics\n",
        "\n",
        "            # Determine best model\n",
        "            print(\"\\n🔹 Determining best model...\")\n",
        "            best_model_name = min(model_metrics, key=lambda x: model_metrics[x]['test_rmse'])\n",
        "            best_model = models[best_model_name]\n",
        "            best_metrics = model_metrics[best_model_name]\n",
        "\n",
        "            print(f\"Best model for {state.title()}: {best_model_name}\")\n",
        "            print(f\"Best model metrics:\")\n",
        "            for metric, value in best_metrics.items():\n",
        "                print(f\"   - {metric}: {value:.4f}\")\n",
        "\n",
        "            # Log best model and comparison results to MLflow\n",
        "            if self.mlflow_uri:\n",
        "                with mlflow.start_run(experiment_id=experiment_id, run_name=f\"best_model_comparison_{state}\",nested=True):\n",
        "                    mlflow.log_param(\"best_model\", best_model_name)\n",
        "                    for name, metrics in model_metrics.items():\n",
        "                        for metric, value in metrics.items():\n",
        "                            mlflow.log_metric(f\"{name}_{metric}\", value)\n",
        "\n",
        "                    # Log a text summary\n",
        "                    summary = f\"Best model: {best_model_name}\\n\"\n",
        "                    summary += f\"Test RMSE: {best_metrics.get('test_rmse', 'N/A')}\\n\"\n",
        "                    summary += f\"Test R2: {best_metrics.get('test_r2', 'N/A')}\\n\"\n",
        "                    mlflow.log_text(summary, \"model_comparison_summary.txt\")\n",
        "\n",
        "            # Create visualizations and save directly to S3\n",
        "            self._create_forecast_visualization(\n",
        "                state,\n",
        "                train_data,\n",
        "                test_data,\n",
        "                models,\n",
        "                best_model_name,\n",
        "                split_date\n",
        "            )\n",
        "\n",
        "            # Save all models directly to S3\n",
        "            state_model_prefix = f\"{self.model_registry_prefix}/{state}\"\n",
        "            self.s3_connector.create_s3_directory(self.s3_bucket, state_model_prefix)\n",
        "\n",
        "            for model_name, model in models.items():\n",
        "                s3_model_key = f\"{state_model_prefix}/{model_name}.pkl\"\n",
        "                self.s3_connector.save_pickle_to_s3(model, self.s3_bucket, s3_model_key)\n",
        "                print(f\"Saved {model_name} model to s3://{self.s3_bucket}/{s3_model_key}\")\n",
        "\n",
        "            # Save best model separately\n",
        "            best_model_key = f\"{self.model_registry_prefix}/{state}_best_model.pkl\"\n",
        "            self.s3_connector.save_pickle_to_s3(best_model, self.s3_bucket, best_model_key)\n",
        "            print(f\"Saved best model ({best_model_name}) to s3://{self.s3_bucket}/{best_model_key}\")\n",
        "\n",
        "            # Store feature importance data\n",
        "            if best_model_name == 'random_forest':\n",
        "                importance_data = rf_importance\n",
        "            elif best_model_name == 'xgboost':\n",
        "                importance_data = xgb_importance\n",
        "            else:\n",
        "                importance_data = None\n",
        "\n",
        "            # Create result structure with S3 paths instead of local paths\n",
        "            result = {\n",
        "                'best_model': best_model_name,\n",
        "                'model': best_model,\n",
        "                'metrics': best_metrics,\n",
        "                'feature_importance': importance_data.to_dict() if importance_data is not None else None,\n",
        "                'model_s3_path': f\"s3://{self.s3_bucket}/{best_model_key}\"\n",
        "            }\n",
        "\n",
        "            print(f\"✅ Successfully processed {state.title()}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing state {state}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def _get_feature_columns(self, df):\n",
        "        \"\"\"Get feature columns that exist in the dataframe.\"\"\"\n",
        "        all_feature_cols = [\n",
        "            # Economic indicators\n",
        "            'MSP_Wheat_KG', 'CPI', 'diesel_price',\n",
        "            'Diesel ROC', 'Wheat ROC', 'Diesel / Wheat Price Ratio',\n",
        "\n",
        "            # External factors\n",
        "            'Rainfall',\n",
        "\n",
        "            # Time components\n",
        "            'year', 'month_num', 'quarter',\n",
        "            'month_sin', 'month_cos', 'quarter_sin', 'quarter_cos',\n",
        "\n",
        "            # Lagged features\n",
        "            'lag_1m', 'lag_3m', 'lag_6m', 'lag_12m',\n",
        "\n",
        "            # Rolling statistics\n",
        "            'rolling_mean_3m', 'rolling_mean_6m',\n",
        "            'rolling_std_3m', 'rolling_std_6m',\n",
        "\n",
        "            # Rate of change\n",
        "            'roc_1m', 'roc_3m',\n",
        "\n",
        "            # Price ratios\n",
        "            'MSP_to_retail_ratio'\n",
        "        ]\n",
        "\n",
        "        # Filter to columns that exist in the dataframe\n",
        "        feature_cols = [col for col in all_feature_cols if col in df.columns]\n",
        "        print(f\"Using {len(feature_cols)} features: {', '.join(feature_cols)}\")\n",
        "\n",
        "        return feature_cols\n",
        "\n",
        "    def _train_random_forest(self, X_train, y_train, X_test, y_test, state, experiment_id=None):\n",
        "        \"\"\"Train and evaluate Random Forest model with MLflow tracking.\"\"\"\n",
        "        rf_params = {\n",
        "            'n_estimators': 200,\n",
        "            'max_depth': 15,\n",
        "            'min_samples_split': 5,\n",
        "            'random_state': 42,\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "\n",
        "        print(f\"RF Parameters: {rf_params}\")\n",
        "\n",
        "        # Start MLflow run if tracking is enabled\n",
        "        if self.mlflow_uri and experiment_id:\n",
        "            mlflow_run = mlflow.start_run(experiment_id=experiment_id, run_name=f\"random_forest_{state}\",nested=True)\n",
        "            mlflow_run_id = mlflow_run.info.run_id\n",
        "            print(f\"Started MLflow run: {mlflow_run_id}\")\n",
        "        else:\n",
        "            mlflow_run = None\n",
        "\n",
        "        try:\n",
        "            # Train model\n",
        "            rf_model = RandomForestRegressor(**rf_params)\n",
        "            rf_model.fit(X_train, y_train)\n",
        "\n",
        "            # Evaluate\n",
        "            train_pred_rf = rf_model.predict(X_train)\n",
        "            test_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "            rf_metrics = self._calculate_metrics(y_train, train_pred_rf, y_test, test_pred_rf)\n",
        "\n",
        "            # Get feature importance\n",
        "            feature_importance_rf = pd.DataFrame({\n",
        "                'Feature': X_train.columns,\n",
        "                'Importance': rf_model.feature_importances_\n",
        "            }).sort_values('Importance', ascending=False)\n",
        "\n",
        "            print(f\"Random Forest metrics - Test RMSE: {rf_metrics['test_rmse']:.4f}, R²: {rf_metrics['test_r2']:.4f}\")\n",
        "            print(f\"Top 5 important features:\")\n",
        "            for i, row in feature_importance_rf.head(5).iterrows():\n",
        "                print(f\"   - {row['Feature']}: {row['Importance']:.4f}\")\n",
        "\n",
        "            # Log to MLflow if tracking is enabled\n",
        "            if mlflow_run:\n",
        "                # Log parameters\n",
        "                for param, value in rf_params.items():\n",
        "                    mlflow.log_param(param, value)\n",
        "\n",
        "                # Log metrics\n",
        "                for metric, value in rf_metrics.items():\n",
        "                    mlflow.log_metric(metric, value)\n",
        "\n",
        "                # Log feature importance\n",
        "                importance_table = feature_importance_rf.to_csv(index=False)\n",
        "                mlflow.log_text(importance_table, \"feature_importance.csv\")\n",
        "\n",
        "                # Create and log feature importance plot\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.bar(feature_importance_rf['Feature'].head(10), feature_importance_rf['Importance'].head(10))\n",
        "                plt.xlabel('Features')\n",
        "                plt.ylabel('Importance')\n",
        "                plt.title('Random Forest Feature Importance')\n",
        "                plt.xticks(rotation=45, ha='right')\n",
        "                plt.tight_layout()\n",
        "                mlflow.log_figure(plt.gcf(), \"feature_importance.png\")\n",
        "                plt.close()\n",
        "\n",
        "                # Log model\n",
        "                mlflow.sklearn.log_model(rf_model, \"random_forest_model\")\n",
        "\n",
        "                # Create and log residual plot\n",
        "                plt.figure(figsize=(8, 6))\n",
        "                plt.scatter(test_pred_rf, y_test - test_pred_rf, alpha=0.5)\n",
        "                plt.axhline(y=0, color='r', linestyle='-')\n",
        "                plt.xlabel('Predicted Values')\n",
        "                plt.ylabel('Residuals')\n",
        "                plt.title('Residual Plot')\n",
        "                plt.tight_layout()\n",
        "                mlflow.log_figure(plt.gcf(), \"residual_plot.png\")\n",
        "                plt.close()\n",
        "\n",
        "                # Register model\n",
        "                model_name = f\"random_forest_{state}\"\n",
        "                mlflow.register_model(f\"runs:/{mlflow_run_id}/random_forest_model\", model_name)\n",
        "\n",
        "                print(f\"✅ Logged Random Forest model to MLflow: {model_name}\")\n",
        "\n",
        "        finally:\n",
        "            # End the MLflow run\n",
        "            if mlflow_run:\n",
        "                mlflow.end_run()\n",
        "\n",
        "        return rf_model, rf_metrics, feature_importance_rf\n",
        "\n",
        "    def _train_xgboost(self, X_train, y_train, X_test, y_test, state, experiment_id=None):\n",
        "        \"\"\"Train and evaluate XGBoost model with MLflow tracking.\"\"\"\n",
        "        xgb_params = {\n",
        "            'n_estimators': 1000,\n",
        "            'learning_rate': 0.03,\n",
        "            'max_depth': 6,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'subsample': 0.9,\n",
        "            'gamma': 0.1,\n",
        "            'reg_alpha': 0.1,\n",
        "            'reg_lambda': 0.5,\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        print(f\"XGBoost Parameters: {xgb_params}\")\n",
        "\n",
        "        # Start MLflow run if tracking is enabled\n",
        "        if self.mlflow_uri and experiment_id:\n",
        "            mlflow_run = mlflow.start_run(experiment_id=experiment_id, run_name=f\"xgboost_{state}\",nested=True)\n",
        "            mlflow_run_id = mlflow_run.info.run_id\n",
        "            print(f\"Started MLflow run: {mlflow_run_id}\")\n",
        "        else:\n",
        "            mlflow_run = None\n",
        "\n",
        "        try:\n",
        "            # Train model\n",
        "            xgb_model = xgb.XGBRegressor(**xgb_params)\n",
        "            xgb_model.fit(X_train, y_train)\n",
        "\n",
        "            # Evaluate\n",
        "            train_pred_xgb = xgb_model.predict(X_train)\n",
        "            test_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "            xgb_metrics = self._calculate_metrics(y_train, train_pred_xgb, y_test, test_pred_xgb)\n",
        "\n",
        "            # Get feature importance\n",
        "            feature_importance_xgb = pd.DataFrame({\n",
        "                'Feature': X_train.columns,\n",
        "                'Importance': xgb_model.feature_importances_\n",
        "            }).sort_values('Importance', ascending=False)\n",
        "\n",
        "            print(f\"XGBoost metrics - Test RMSE: {xgb_metrics['test_rmse']:.4f}, R²: {xgb_metrics['test_r2']:.4f}\")\n",
        "            print(f\"Top 5 important features:\")\n",
        "            for i, row in feature_importance_xgb.head(5).iterrows():\n",
        "                print(f\"   - {row['Feature']}: {row['Importance']:.4f}\")\n",
        "\n",
        "            # Log to MLflow if tracking is enabled\n",
        "            if mlflow_run:\n",
        "                # Log parameters\n",
        "                for param, value in xgb_params.items():\n",
        "                    mlflow.log_param(param, value)\n",
        "\n",
        "                # Log metrics\n",
        "                for metric, value in xgb_metrics.items():\n",
        "                    mlflow.log_metric(metric, value)\n",
        "\n",
        "                # Log feature importance\n",
        "                importance_table = feature_importance_xgb.to_csv(index=False)\n",
        "                mlflow.log_text(importance_table, \"feature_importance.csv\")\n",
        "\n",
        "                # Create and log feature importance plot\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.bar(feature_importance_xgb['Feature'].head(10), feature_importance_xgb['Importance'].head(10))\n",
        "                plt.xlabel('Features')\n",
        "                plt.ylabel('Importance')\n",
        "                plt.title('XGBoost Feature Importance')\n",
        "                plt.xticks(rotation=45, ha='right')\n",
        "                plt.tight_layout()\n",
        "                mlflow.log_figure(plt.gcf(), \"feature_importance.png\")\n",
        "                plt.close()\n",
        "\n",
        "                # Log model\n",
        "                mlflow.xgboost.log_model(xgb_model, \"xgboost_model\")\n",
        "\n",
        "                # Create and log learning curves\n",
        "                plt.figure(figsize=(8, 6))\n",
        "                plt.scatter(test_pred_xgb, y_test - test_pred_xgb, alpha=0.5)\n",
        "                plt.axhline(y=0, color='r', linestyle='-')\n",
        "                plt.xlabel('Predicted Values')\n",
        "                plt.ylabel('Residuals')\n",
        "                plt.title('Residual Plot')\n",
        "                plt.tight_layout()\n",
        "                mlflow.log_figure(plt.gcf(), \"residual_plot.png\")\n",
        "                plt.close()\n",
        "\n",
        "                # Register model\n",
        "                model_name = f\"xgboost_{state}\"\n",
        "                mlflow.register_model(f\"runs:/{mlflow_run_id}/xgboost_model\", model_name)\n",
        "\n",
        "                print(f\"✅ Logged XGBoost model to MLflow: {model_name}\")\n",
        "\n",
        "        finally:\n",
        "            # End the MLflow run\n",
        "            if mlflow_run:\n",
        "                mlflow.end_run()\n",
        "\n",
        "        return xgb_model, xgb_metrics, feature_importance_xgb\n",
        "\n",
        "    def _train_holt_winters(self, train_data, test_data, state, experiment_id=None):\n",
        "        \"\"\"Train and evaluate Holt-Winters model with MLflow tracking.\"\"\"\n",
        "        # Convert to pandas Series with datetime index\n",
        "        train_series = pd.Series(train_data['price_per_KG'].values, index=train_data.index)\n",
        "        test_series = pd.Series(test_data['price_per_KG'].values, index=test_data.index)\n",
        "\n",
        "        hw_params = {\n",
        "            'trend': 'add',\n",
        "            'seasonal': 'mul',\n",
        "            'seasonal_periods': 12  # Monthly data with yearly seasonality\n",
        "        }\n",
        "\n",
        "        print(f\"Holt-Winters Parameters: {hw_params}\")\n",
        "\n",
        "        # Start MLflow run if tracking is enabled\n",
        "        if self.mlflow_uri and experiment_id:\n",
        "            mlflow_run = mlflow.start_run(experiment_id=experiment_id, run_name=f\"holt_winters_{state}\",nested=True)\n",
        "            mlflow_run_id = mlflow_run.info.run_id\n",
        "            print(f\"Started MLflow run: {mlflow_run_id}\")\n",
        "        else:\n",
        "            mlflow_run = None\n",
        "\n",
        "        try:\n",
        "            # Create and fit model\n",
        "            hw_model = ExponentialSmoothing(train_series, **hw_params)\n",
        "            hw_fit = hw_model.fit()\n",
        "\n",
        "            # Make predictions\n",
        "            hw_train_pred = hw_fit.fittedvalues\n",
        "            hw_test_pred = hw_fit.forecast(steps=len(test_series))\n",
        "\n",
        "            # Align indices\n",
        "            hw_test_pred.index = test_series.index\n",
        "\n",
        "            # Calculate metrics\n",
        "            hw_train_rmse = np.sqrt(mean_squared_error(train_series, hw_train_pred))\n",
        "            hw_test_rmse = np.sqrt(mean_squared_error(test_series, hw_test_pred))\n",
        "            hw_train_mae = mean_absolute_error(train_series, hw_train_pred)\n",
        "            hw_test_mae = mean_absolute_error(test_series, hw_test_pred)\n",
        "\n",
        "            # Avoid division by zero in MAPE\n",
        "            hw_train_mape = np.mean(np.abs((train_series - hw_train_pred) /\n",
        "                                          np.maximum(0.01, np.abs(train_series)))) * 100\n",
        "            hw_test_mape = np.mean(np.abs((test_series - hw_test_pred) /\n",
        "                                         np.maximum(0.01, np.abs(test_series)))) * 100\n",
        "\n",
        "            # Calculate R² if possible\n",
        "            try:\n",
        "                hw_train_r2 = r2_score(train_series, hw_train_pred)\n",
        "                hw_test_r2 = r2_score(test_series, hw_test_pred)\n",
        "            except:\n",
        "                hw_train_r2 = np.nan\n",
        "                hw_test_r2 = np.nan\n",
        "\n",
        "            hw_metrics = {\n",
        "                'train_rmse': hw_train_rmse,\n",
        "                'test_rmse': hw_test_rmse,\n",
        "                'train_mae': hw_train_mae,\n",
        "                'test_mae': hw_test_mae,\n",
        "                'train_mape': hw_train_mape,\n",
        "                'test_mape': hw_test_mape,\n",
        "                'train_r2': hw_train_r2,\n",
        "                'test_r2': hw_test_r2\n",
        "            }\n",
        "\n",
        "            print(f\"Holt-Winters metrics - Test RMSE: {hw_test_rmse:.4f}\")\n",
        "\n",
        "            # Log to MLflow if tracking is enabled\n",
        "            if mlflow_run:\n",
        "                # Log parameters\n",
        "                for param, value in hw_params.items():\n",
        "                    mlflow.log_param(param, value)\n",
        "\n",
        "                # Log model parameters from fitted model\n",
        "                model_params = hw_fit.params\n",
        "                for param, value in model_params.items():\n",
        "                    param_name = f\"fitted_{param}\"\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        mlflow.log_param(param_name, value)\n",
        "\n",
        "                # Log metrics\n",
        "                for metric, value in hw_metrics.items():\n",
        "                    if not np.isnan(value):  # Skip NaN values\n",
        "                        mlflow.log_metric(metric, value)\n",
        "\n",
        "                # Create and log forecast visualization\n",
        "                plt.figure(figsize=(12, 6))\n",
        "                plt.plot(train_series.index, train_series, 'b-', label='Train Actual')\n",
        "                plt.plot(hw_train_pred.index, hw_train_pred, 'g--', label='Train Fitted')\n",
        "                plt.plot(test_series.index, test_series, 'r-', label='Test Actual')\n",
        "                plt.plot(hw_test_pred.index, hw_test_pred, 'c--', label='Test Forecast')\n",
        "                plt.xlabel('Date')\n",
        "                plt.ylabel('Price per KG')\n",
        "                plt.title(f'Holt-Winters Forecast - {state.title()}')\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                plt.tight_layout()\n",
        "                mlflow.log_figure(plt.gcf(), \"forecast_plot.png\")\n",
        "                plt.close()\n",
        "\n",
        "                # Create and log residual plot\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.scatter(hw_test_pred, test_series - hw_test_pred, alpha=0.5)\n",
        "                plt.axhline(y=0, color='r', linestyle='-')\n",
        "                plt.xlabel('Predicted Values')\n",
        "                plt.ylabel('Residuals')\n",
        "                plt.title('Residual Plot - Holt-Winters')\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                plt.tight_layout()\n",
        "                mlflow.log_figure(plt.gcf(), \"residual_plot.png\")\n",
        "                plt.close()\n",
        "\n",
        "                # Save the model components\n",
        "                model_info = {\n",
        "                    'model_type': 'Holt-Winters',\n",
        "                    'params': hw_params,\n",
        "                    'fitted_params': {str(k): str(v) for k, v in model_params.items()},\n",
        "                    'metrics': hw_metrics\n",
        "                }\n",
        "                mlflow.log_dict(model_info, \"model_info.json\")\n",
        "\n",
        "                print(f\"✅ Logged Holt-Winters model to MLflow\")\n",
        "\n",
        "            return hw_fit, hw_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error training Holt-Winters model: {str(e)}\")\n",
        "            if mlflow_run:\n",
        "                # Log the error\n",
        "                mlflow.log_param(\"error\", str(e))\n",
        "            return None, None\n",
        "\n",
        "        finally:\n",
        "            # End the MLflow run\n",
        "            if mlflow_run:\n",
        "                mlflow.end_run()\n",
        "\n",
        "    def _calculate_metrics(self, y_train, train_pred, y_test, test_pred):\n",
        "        \"\"\"Calculate common evaluation metrics.\"\"\"\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "        train_mae = mean_absolute_error(y_train, train_pred)\n",
        "        test_mae = mean_absolute_error(y_test, test_pred)\n",
        "        train_r2 = r2_score(y_train, train_pred)\n",
        "        test_r2 = r2_score(y_test, test_pred)\n",
        "\n",
        "        # Avoid division by zero in MAPE\n",
        "        train_mape = np.mean(np.abs((y_train - train_pred) / np.maximum(0.01, np.abs(y_train)))) * 100\n",
        "        test_mape = np.mean(np.abs((y_test - test_pred) / np.maximum(0.01, np.abs(y_test)))) * 100\n",
        "\n",
        "        metrics = {\n",
        "            'train_rmse': train_rmse,\n",
        "            'test_rmse': test_rmse,\n",
        "            'train_mae': train_mae,\n",
        "            'test_mae': test_mae,\n",
        "            'train_mape': train_mape,\n",
        "            'test_mape': test_mape,\n",
        "            'train_r2': train_r2,\n",
        "            'test_r2': test_r2\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _create_forecast_visualization(self, state, train_data, test_data, models, best_model_name, split_date):\n",
        "        \"\"\"Create visualization of model forecasts and save directly to S3.\"\"\"\n",
        "        print(\"\\n🔹 Creating visualization...\")\n",
        "\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Plot actual prices\n",
        "        plt.plot(train_data.index, train_data['price_per_KG'], 'b-',\n",
        "                 label='Actual (Train)', alpha=0.7, linewidth=2)\n",
        "        plt.plot(test_data.index, test_data['price_per_KG'], 'k-',\n",
        "                 label='Actual (Test)', alpha=0.7, linewidth=2)\n",
        "\n",
        "        # Plot best model predictions\n",
        "        if best_model_name == 'holt_winters':\n",
        "            hw_fit = models['holt_winters']\n",
        "            hw_train_pred = hw_fit.fittedvalues\n",
        "            hw_test_pred = hw_fit.forecast(steps=len(test_data))\n",
        "            hw_test_pred.index = test_data.index\n",
        "\n",
        "            plt.plot(hw_train_pred.index, hw_train_pred, 'g--',\n",
        "                     label=f'Predicted (Train - {best_model_name})', alpha=0.7, linewidth=2)\n",
        "            plt.plot(hw_test_pred.index, hw_test_pred, 'r--',\n",
        "                     label=f'Predicted (Test - {best_model_name})', alpha=0.7, linewidth=2)\n",
        "        else:\n",
        "            # For RF and XGB, calculate predictions\n",
        "            X_train = train_data[self.feature_cols]\n",
        "            X_test = test_data[self.feature_cols]\n",
        "\n",
        "            best_model = models[best_model_name]\n",
        "            train_pred = best_model.predict(X_train)\n",
        "            test_pred = best_model.predict(X_test)\n",
        "\n",
        "            plt.plot(train_data.index, train_pred, 'g--',\n",
        "                     label=f'Predicted (Train - {best_model_name})', alpha=0.7, linewidth=2)\n",
        "            plt.plot(test_data.index, test_pred, 'r--',\n",
        "                     label=f'Predicted (Test - {best_model_name})', alpha=0.7, linewidth=2)\n",
        "\n",
        "        # Add chart elements\n",
        "        plt.title(f'Wheat Price Forecast for {state.title()} - {best_model_name.title()}', fontsize=16)\n",
        "        plt.xlabel('Date', fontsize=14)\n",
        "        plt.ylabel('Price per KG (₹)', fontsize=14)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend(loc='best', fontsize=12)\n",
        "\n",
        "        # Add vertical line for train/test split\n",
        "        plt.axvline(pd.to_datetime(split_date), color='gray', linestyle='--', alpha=0.7)\n",
        "        plt.text(pd.to_datetime(split_date), plt.ylim()[0], 'Train-Test Split',\n",
        "                 rotation=90, verticalalignment='bottom', fontsize=12)\n",
        "\n",
        "        # Format plot\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save the plot directly to S3\n",
        "        s3_plot_key = f\"{self.plots_prefix}/{state}_forecast.png\"\n",
        "        self.s3_connector.save_figure_to_s3(plt.gcf(), self.s3_bucket, s3_plot_key)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"✅ Saved visualization to s3://{self.s3_bucket}/{s3_plot_key}\")\n",
        "\n",
        "        # Create feature importance plot if applicable\n",
        "        if best_model_name in ['random_forest', 'xgboost']:\n",
        "            self._create_feature_importance_plot(state, best_model_name, models[best_model_name], self.feature_cols)\n",
        "\n",
        "\n",
        "    def _create_feature_importance_plot(self, state, model_name, model, feature_cols):\n",
        "        \"\"\"Create feature importance visualization and save directly to S3.\"\"\"\n",
        "        # Get feature importances\n",
        "        importances = model.feature_importances_\n",
        "\n",
        "        # Create DataFrame of feature importances\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'Feature': feature_cols,\n",
        "            'Importance': importances\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "\n",
        "        # Create plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Plot horizontal bar chart\n",
        "        sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15), palette='viridis')\n",
        "\n",
        "        # Add chart elements\n",
        "        plt.title(f'Top 15 Feature Importances for {state.title()} - {model_name.title()}', fontsize=16)\n",
        "        plt.xlabel('Importance', fontsize=14)\n",
        "        plt.ylabel('Feature', fontsize=14)\n",
        "        plt.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "        # Format plot\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save the plot directly to S3\n",
        "        s3_plot_key = f\"{self.plots_prefix}/{state}_{model_name}_importance.png\"\n",
        "        self.s3_connector.save_figure_to_s3(plt.gcf(), self.s3_bucket, s3_plot_key)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"✅ Saved feature importance plot to s3://{self.s3_bucket}/{s3_plot_key}\")\n",
        "\n",
        "        # Also save the feature importance data as JSON\n",
        "        importance_data = feature_importance.to_dict('records')\n",
        "        s3_importance_key = f\"{self.plots_prefix}/{state}_{model_name}_importance.json\"\n",
        "        self.s3_connector.save_data_to_s3(\n",
        "            importance_data,\n",
        "            self.s3_bucket,\n",
        "            s3_importance_key,\n",
        "            content_type='application/json'\n",
        "        )\n",
        "        print(f\"✅ Saved feature importance data to s3://{self.s3_bucket}/{s3_importance_key}\")"
      ],
      "metadata": {
        "id": "U3malv2C8WbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelAggregator:\n",
        "    \"\"\"Class for aggregating models across all states with MLflow tracking.\"\"\"\n",
        "\n",
        "    def __init__(self, s3_connector, s3_bucket, output_prefix, mlflow_tracking_uri=None):\n",
        "        \"\"\"\n",
        "        Initialize the model aggregator with S3 storage and MLflow tracking.\n",
        "\n",
        "        Args:\n",
        "            s3_connector (S3Connector): S3 connector instance\n",
        "            s3_bucket (str): S3 bucket for saving models\n",
        "            output_prefix (str): Prefix path in the S3 bucket\n",
        "            mlflow_tracking_uri (str, optional): MLflow tracking URI\n",
        "        \"\"\"\n",
        "        self.s3_connector = s3_connector\n",
        "        self.s3_bucket = s3_bucket\n",
        "        self.output_prefix = output_prefix\n",
        "\n",
        "        # Set up MLflow\n",
        "        self.mlflow_uri = mlflow_tracking_uri\n",
        "        if mlflow_tracking_uri:\n",
        "            mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
        "            self.client = MlflowClient(tracking_uri=mlflow_tracking_uri)\n",
        "            print(f\"✅ MLflow tracking configured for aggregator: {mlflow_tracking_uri}\")\n",
        "        else:\n",
        "            self.client = None\n",
        "            print(\"ℹ️ MLflow tracking not configured for aggregator\")\n",
        "\n",
        "    def aggregate_models(self, all_states_models, feature_cols):\n",
        "        \"\"\"\n",
        "        Combine all state models into a single file with metadata and save to S3.\n",
        "\n",
        "        Args:\n",
        "            all_states_models (dict): Dictionary of state-model mappings\n",
        "            feature_cols (list): Feature columns used in modeling\n",
        "\n",
        "        Returns:\n",
        "            str: S3 path to the combined model file\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"📦 Aggregating models across all states to S3\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Filter out None values\n",
        "        valid_models = {state: data for state, data in all_states_models.items() if data is not None}\n",
        "\n",
        "        print(f\"Aggregating models for {len(valid_models)}/{len(all_states_models)} states\")\n",
        "\n",
        "        # Create metadata\n",
        "        metadata = {\n",
        "            'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'states_included': list(valid_models.keys()),\n",
        "            'total_states': len(valid_models),\n",
        "            'model_details': {\n",
        "                state: {\n",
        "                    'best_model': data['best_model'],\n",
        "                    'metrics': data['metrics'],\n",
        "                    'feature_importance': data['feature_importance'],\n",
        "                    's3_model_path': data.get('model_s3_path', f\"s3://{self.s3_bucket}/{self.output_prefix}/model_registry/{state}_best_model.pkl\")\n",
        "                } for state, data in valid_models.items()\n",
        "            },\n",
        "            'feature_cols': feature_cols\n",
        "        }\n",
        "\n",
        "        # Create combined data structure\n",
        "        combined_data = {\n",
        "            'models': {state: data['model'] for state, data in valid_models.items()},\n",
        "            'metadata': metadata\n",
        "        }\n",
        "\n",
        "        # Generate S3 paths with timestamp\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "        # Save the combined model directly to S3\n",
        "        s3_combined_key = f\"{self.output_prefix}/models/all_states_best_model_{timestamp}.pkl\"\n",
        "        s3_latest_key = f\"{self.output_prefix}/models/all_states_best_model_latest.pkl\"\n",
        "        s3_metadata_key = f\"{self.output_prefix}/models/all_states_metadata_{timestamp}.json\"\n",
        "\n",
        "        # Start MLflow run if tracking is enabled\n",
        "        if self.mlflow_uri:\n",
        "            # Create a new experiment for aggregated models if it doesn't exist\n",
        "            experiment_name = \"wheat_price_forecast_aggregated\"\n",
        "            try:\n",
        "                experiment = self.client.get_experiment_by_name(experiment_name)\n",
        "                if experiment:\n",
        "                    experiment_id = experiment.experiment_id\n",
        "                else:\n",
        "                    experiment_id = mlflow.create_experiment(experiment_name)\n",
        "                print(f\"✅ MLflow experiment for aggregation: {experiment_name} (ID: {experiment_id})\")\n",
        "\n",
        "                # Start a new run\n",
        "                mlflow_run = mlflow.start_run(experiment_id=experiment_id, run_name=f\"aggregated_models_{timestamp}\",nested=True)\n",
        "                run_id = mlflow_run.info.run_id\n",
        "                print(f\"Started MLflow run: {run_id}\")\n",
        "\n",
        "                # Log metadata about the aggregation\n",
        "                mlflow.log_param(\"timestamp\", timestamp)\n",
        "                mlflow.log_param(\"total_states\", len(valid_models))\n",
        "                mlflow.log_param(\"states\", \",\".join(sorted(valid_models.keys())))\n",
        "\n",
        "                # Log performance metrics for each state\n",
        "                for state, data in valid_models.items():\n",
        "                    best_model = data['best_model']\n",
        "                    metrics = data['metrics']\n",
        "\n",
        "                    # Log the best model type for each state\n",
        "                    mlflow.log_param(f\"{state}_best_model\", best_model)\n",
        "\n",
        "                    # Log key metrics for each state\n",
        "                    for metric_name in ['test_rmse', 'test_r2', 'test_mape']:\n",
        "                        if metric_name in metrics:\n",
        "                            mlflow.log_metric(f\"{state}_{metric_name}\", metrics[metric_name])\n",
        "\n",
        "                # Create and log a summary table of results\n",
        "                results_table = self._create_results_table(valid_models)\n",
        "                mlflow.log_text(results_table, \"state_model_results.csv\")\n",
        "\n",
        "                # Log feature importance across all states\n",
        "                combined_importance = self._aggregate_feature_importance(valid_models, feature_cols)\n",
        "                if combined_importance is not None:\n",
        "                    mlflow.log_dict(combined_importance, \"combined_feature_importance.json\")\n",
        "\n",
        "                    # Create and log feature importance plot\n",
        "                    plt.figure(figsize=(10, 8))\n",
        "                    top_features = sorted(combined_importance.items(), key=lambda x: x[1], reverse=True)[:15]\n",
        "                    features, importances = zip(*top_features)\n",
        "                    plt.barh(features, importances)\n",
        "                    plt.xlabel('Aggregated Importance')\n",
        "                    plt.ylabel('Features')\n",
        "                    plt.title('Top 15 Features Across All States')\n",
        "                    plt.tight_layout()\n",
        "                    mlflow.log_figure(plt.gcf(), \"aggregated_feature_importance.png\")\n",
        "                    plt.close()\n",
        "\n",
        "                # Log the S3 paths\n",
        "                mlflow.log_param(\"s3_combined_model_path\", f\"s3://{self.s3_bucket}/{s3_combined_key}\")\n",
        "                mlflow.log_param(\"s3_latest_model_path\", f\"s3://{self.s3_bucket}/{s3_latest_key}\")\n",
        "                mlflow.log_param(\"s3_metadata_path\", f\"s3://{self.s3_bucket}/{s3_metadata_key}\")\n",
        "\n",
        "                # Register the aggregated model metadata\n",
        "                mlflow.log_dict(metadata, \"aggregated_model_metadata.json\")\n",
        "\n",
        "                print(f\"✅ Logged aggregated model metadata to MLflow\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error with MLflow experiment: {str(e)}\")\n",
        "\n",
        "        # Save combined model to S3\n",
        "        model_saved = self.s3_connector.save_pickle_to_s3(\n",
        "            combined_data,\n",
        "            self.s3_bucket,\n",
        "            s3_combined_key\n",
        "        )\n",
        "\n",
        "        if model_saved:\n",
        "            print(f\"✅ Saved combined model to S3: s3://{self.s3_bucket}/{s3_combined_key}\")\n",
        "\n",
        "            # Save a copy as \"latest\" version\n",
        "            self.s3_connector.save_pickle_to_s3(\n",
        "                combined_data,\n",
        "                self.s3_bucket,\n",
        "                s3_latest_key\n",
        "            )\n",
        "            print(f\"✅ Saved latest version to S3: s3://{self.s3_bucket}/{s3_latest_key}\")\n",
        "\n",
        "            # Save metadata as JSON\n",
        "            self.s3_connector.save_data_to_s3(\n",
        "                metadata,\n",
        "                self.s3_bucket,\n",
        "                s3_metadata_key,\n",
        "                content_type='application/json'\n",
        "            )\n",
        "            print(f\"✅ Saved metadata to S3: s3://{self.s3_bucket}/{s3_metadata_key}\")\n",
        "        else:\n",
        "            print(f\"❌ Failed to save combined model to S3\")\n",
        "\n",
        "        # End the MLflow run if it was started\n",
        "        if self.mlflow_uri:\n",
        "            try:\n",
        "                mlflow.end_run()\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error ending MLflow run: {str(e)}\")\n",
        "\n",
        "        # Return the S3 path\n",
        "        combined_s3_path = f\"s3://{self.s3_bucket}/{s3_combined_key}\"\n",
        "        return combined_s3_path\n",
        "\n",
        "    def _create_results_table(self, valid_models):\n",
        "        \"\"\"Create a CSV-formatted table of results for all states.\"\"\"\n",
        "        # Header row\n",
        "        table = \"State,Best Model,Test RMSE,Test MAPE,R²\\n\"\n",
        "\n",
        "        # Add a row for each state\n",
        "        for state, details in sorted(valid_models.items()):\n",
        "            rmse = details['metrics'].get('test_rmse', 'N/A')\n",
        "            mape = details['metrics'].get('test_mape', 'N/A')\n",
        "            r2 = details['metrics'].get('test_r2', 'N/A')\n",
        "\n",
        "            rmse_str = f\"{rmse:.4f}\" if isinstance(rmse, (int, float)) else rmse\n",
        "            mape_str = f\"{mape:.2f}\" if isinstance(mape, (int, float)) else mape\n",
        "            r2_str = f\"{r2:.4f}\" if isinstance(r2, (int, float)) else r2\n",
        "\n",
        "            table += f\"{state},{details['best_model']},{rmse_str},{mape_str},{r2_str}\\n\"\n",
        "\n",
        "        return table\n",
        "\n",
        "    def _aggregate_feature_importance(self, valid_models, feature_cols):\n",
        "        \"\"\"Aggregate feature importance across all models.\"\"\"\n",
        "        # Initialize dictionary to hold importance scores\n",
        "        combined_importance = {feature: 0.0 for feature in feature_cols}\n",
        "        models_with_importance = 0\n",
        "\n",
        "        # Sum importance scores across all states\n",
        "        for state, data in valid_models.items():\n",
        "            # Skip if no feature importance data\n",
        "            if data['feature_importance'] is None:\n",
        "                continue\n",
        "\n",
        "            models_with_importance += 1\n",
        "\n",
        "            # Extract feature importance dict from the data\n",
        "            importance_dict = data['feature_importance']\n",
        "\n",
        "            # If it's a DataFrame in dict form, extract the values\n",
        "            if isinstance(importance_dict, dict) and 'Feature' in importance_dict and 'Importance' in importance_dict:\n",
        "                features = importance_dict['Feature']\n",
        "                importances = importance_dict['Importance']\n",
        "\n",
        "                # Combine the feature and importance values\n",
        "                for i, feature in enumerate(features):\n",
        "                    if feature in combined_importance:\n",
        "                        combined_importance[feature] += importances[i]\n",
        "\n",
        "        # Average the importance scores\n",
        "        if models_with_importance > 0:\n",
        "            for feature in combined_importance:\n",
        "                combined_importance[feature] /= models_with_importance\n",
        "            return combined_importance\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def print_summary_table(self, all_states_models):\n",
        "        \"\"\"\n",
        "        Print a summary table of model results.\n",
        "\n",
        "        Args:\n",
        "            all_states_models (dict): Dictionary of state-model mappings\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"📊 Summary of Results\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Filter out None values\n",
        "        valid_models = {state: data for state, data in all_states_models.items() if data is not None}\n",
        "\n",
        "        # Print header\n",
        "        print(f\"{'State':<20} {'Best Model':<15} {'Test RMSE':<12} {'Test MAPE':<12} {'R²':<8}\")\n",
        "        print(f\"{'-'*80}\")\n",
        "\n",
        "        # Print each state's results\n",
        "        for state, details in sorted(valid_models.items()):\n",
        "            rmse = details['metrics'].get('test_rmse', 'N/A')\n",
        "            mape = details['metrics'].get('test_mape', 'N/A')\n",
        "            r2 = details['metrics'].get('test_r2', 'N/A')\n",
        "\n",
        "            rmse_str = f\"{rmse:.4f}\" if isinstance(rmse, (int, float)) else rmse\n",
        "            mape_str = f\"{mape:.2f}%\" if isinstance(mape, (int, float)) else mape\n",
        "            r2_str = f\"{r2:.4f}\" if isinstance(r2, (int, float)) else r2\n",
        "\n",
        "            print(f\"{state.title():<20} {details['best_model']:<15} {rmse_str:<12} {mape_str:<12} {r2_str:<8}\")\n",
        "\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"✅ Successfully processed {len(valid_models)}/{len(all_states_models)} states\")\n",
        "\n",
        "        # Log to MLflow if tracking is enabled\n",
        "        if self.mlflow_uri:\n",
        "            try:\n",
        "                # Create a separate experiment for the summary\n",
        "                experiment_name = \"wheat_price_forecast_summary\"\n",
        "                experiment = self.client.get_experiment_by_name(experiment_name)\n",
        "                if experiment:\n",
        "                    experiment_id = experiment.experiment_id\n",
        "                else:\n",
        "                    experiment_id = mlflow.create_experiment(experiment_name)\n",
        "\n",
        "                # Start a new run\n",
        "                with mlflow.start_run(experiment_id=experiment_id, run_name=f\"model_performance_summary\",nested=True):\n",
        "                    # Log summary metrics\n",
        "                    test_rmse_values = [data['metrics'].get('test_rmse') for data in valid_models.values()\n",
        "                                       if isinstance(data['metrics'].get('test_rmse'), (int, float))]\n",
        "\n",
        "                    if test_rmse_values:\n",
        "                        mlflow.log_metric(\"mean_test_rmse\", np.mean(test_rmse_values))\n",
        "                        mlflow.log_metric(\"median_test_rmse\", np.median(test_rmse_values))\n",
        "                        mlflow.log_metric(\"min_test_rmse\", np.min(test_rmse_values))\n",
        "                        mlflow.log_metric(\"max_test_rmse\", np.max(test_rmse_values))\n",
        "\n",
        "                    # Log model type distribution\n",
        "                    model_types = [data['best_model'] for data in valid_models.values()]\n",
        "                    model_counts = {}\n",
        "                    for model_type in set(model_types):\n",
        "                        count = model_types.count(model_type)\n",
        "                        model_counts[model_type] = count\n",
        "                        mlflow.log_metric(f\"{model_type}_count\", count)\n",
        "\n",
        "                    # Log total states processed\n",
        "                    mlflow.log_param(\"total_states_processed\", len(valid_models))\n",
        "                    mlflow.log_param(\"total_states_attempted\", len(all_states_models))\n",
        "\n",
        "                    # Create and log a summary visualization\n",
        "                    self._create_summary_visualizations(valid_models)\n",
        "\n",
        "                print(f\"✅ Logged summary statistics to MLflow\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error logging summary to MLflow: {str(e)}\")\n",
        "\n",
        "    def _create_summary_visualizations(self, valid_models):\n",
        "        \"\"\"Create and log summary visualizations to MLflow.\"\"\"\n",
        "        try:\n",
        "            # 1. Model distribution pie chart\n",
        "            model_types = [data['best_model'] for data in valid_models.values()]\n",
        "            model_counts = {}\n",
        "            for model_type in set(model_types):\n",
        "                model_counts[model_type] = model_types.count(model_type)\n",
        "\n",
        "            plt.figure(figsize=(8, 8))\n",
        "            plt.pie(model_counts.values(), labels=model_counts.keys(), autopct='%1.1f%%',\n",
        "                   shadow=True, startangle=90)\n",
        "            plt.title('Distribution of Best Model Types')\n",
        "            plt.axis('equal')\n",
        "            mlflow.log_figure(plt.gcf(), \"model_distribution_pie.png\")\n",
        "            plt.close()\n",
        "\n",
        "            # 2. RMSE distribution histogram\n",
        "            rmse_values = [data['metrics'].get('test_rmse') for data in valid_models.values()\n",
        "                          if isinstance(data['metrics'].get('test_rmse'), (int, float))]\n",
        "\n",
        "            if rmse_values:\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.hist(rmse_values, bins=10, alpha=0.7, color='skyblue')\n",
        "                plt.axvline(np.mean(rmse_values), color='red', linestyle='dashed', linewidth=1,\n",
        "                           label=f'Mean RMSE: {np.mean(rmse_values):.4f}')\n",
        "                plt.axvline(np.median(rmse_values), color='green', linestyle='dashed', linewidth=1,\n",
        "                           label=f'Median RMSE: {np.median(rmse_values):.4f}')\n",
        "                plt.xlabel('Test RMSE')\n",
        "                plt.ylabel('Number of States')\n",
        "                plt.title('Distribution of Test RMSE Across States')\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                plt.tight_layout()\n",
        "                mlflow.log_figure(plt.gcf(), \"rmse_distribution.png\")\n",
        "                plt.close()\n",
        "\n",
        "            # 3. Top performers bar chart\n",
        "            top_states = sorted([(state, data['metrics'].get('test_rmse', float('inf')))\n",
        "                                for state, data in valid_models.items()\n",
        "                                if isinstance(data['metrics'].get('test_rmse'), (int, float))],\n",
        "                               key=lambda x: x[1])[:5]\n",
        "\n",
        "            if top_states:\n",
        "                states, rmse_values = zip(*top_states)\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.bar(states, rmse_values, color='lightgreen')\n",
        "                plt.xlabel('State')\n",
        "                plt.ylabel('Test RMSE (lower is better)')\n",
        "                plt.title('Top 5 Performing States')\n",
        "                plt.xticks(rotation=45)\n",
        "                plt.grid(True, alpha=0.3, axis='y')\n",
        "                plt.tight_layout()\n",
        "                mlflow.log_figure(plt.gcf(), \"top_performers.png\")\n",
        "                plt.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error creating summary visualizations: {str(e)}\")"
      ],
      "metadata": {
        "id": "2iPpEQxW9GKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WheatPriceForecaster:\n",
        "    \"\"\"Main class for wheat price forecasting process with S3 storage and MLflow tracking.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 s3_bucket,\n",
        "                 s3_key,\n",
        "                 output_prefix=\"wheat_forecaster\",\n",
        "                 split_date=\"2020-01-01\",\n",
        "                 mlflow_uri=None,\n",
        "                 aws_access_key_id=None,\n",
        "                 aws_secret_access_key=None,\n",
        "                 aws_region='us-east-1'):\n",
        "        \"\"\"\n",
        "        Initialize the wheat price forecasting process with S3 data source and storage.\n",
        "\n",
        "        Args:\n",
        "            s3_bucket (str): S3 bucket containing the CSV data file and for storing outputs\n",
        "            s3_key (str): S3 key (path) to the CSV data file\n",
        "            output_prefix (str): Prefix path in the S3 bucket for all outputs\n",
        "            split_date (str): Date to split train/test data\n",
        "            mlflow_uri (str, optional): MLflow tracking URI\n",
        "            aws_access_key_id (str, optional): AWS access key ID\n",
        "            aws_secret_access_key (str, optional): AWS secret access key\n",
        "            aws_region (str, optional): AWS region name\n",
        "        \"\"\"\n",
        "        self.s3_bucket = s3_bucket\n",
        "        self.s3_key = s3_key\n",
        "        self.output_prefix = output_prefix\n",
        "        self.split_date = split_date\n",
        "        self.mlflow_uri = mlflow_uri\n",
        "\n",
        "        # Initialize S3 connector\n",
        "        self.s3_connector = S3Connector(\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key,\n",
        "            region_name=aws_region\n",
        "        )\n",
        "\n",
        "        # Initialize other attributes\n",
        "        self.raw_data = None\n",
        "        self.wheat_data = None\n",
        "        self.all_states = None\n",
        "        self.all_state_models = {}\n",
        "        self.feature_cols = None\n",
        "\n",
        "        # Print initialization information\n",
        "        print(f\"🚀 Initializing Wheat Price Forecaster with S3 storage\")\n",
        "        print(f\"📄 Input file: s3://{self.s3_bucket}/{self.s3_key}\")\n",
        "        print(f\"📁 Output location: s3://{self.s3_bucket}/{self.output_prefix}/\")\n",
        "        print(f\"📅 Train/Test split date: {self.split_date}\")\n",
        "\n",
        "        # Set up MLflow if provided\n",
        "        if self.mlflow_uri:\n",
        "            print(f\"📊 MLflow tracking URI: {self.mlflow_uri}\")\n",
        "            mlflow.set_tracking_uri(self.mlflow_uri)\n",
        "            self.client = MlflowClient(tracking_uri=self.mlflow_uri)\n",
        "\n",
        "            # Create the main experiment\n",
        "            try:\n",
        "                experiment_name = \"wheat_price_forecaster\"\n",
        "                experiment = self.client.get_experiment_by_name(experiment_name)\n",
        "                if experiment:\n",
        "                    self.main_experiment_id = experiment.experiment_id\n",
        "                    print(f\"Using existing MLflow experiment: {experiment_name} (ID: {self.main_experiment_id})\")\n",
        "                else:\n",
        "                    self.main_experiment_id = mlflow.create_experiment(experiment_name)\n",
        "                    print(f\"Created new MLflow experiment: {experiment_name} (ID: {self.main_experiment_id})\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error setting up MLflow experiment: {str(e)}\")\n",
        "                self.main_experiment_id = None\n",
        "        else:\n",
        "            self.client = None\n",
        "            self.main_experiment_id = None\n",
        "\n",
        "    def run_full_process(self):\n",
        "        \"\"\"Run the complete wheat price forecasting process with S3 storage and MLflow tracking.\"\"\"\n",
        "        # Start a main run in MLflow if configured\n",
        "        if self.mlflow_uri and self.main_experiment_id:\n",
        "            main_run = mlflow.start_run(experiment_id=self.main_experiment_id, run_name=\"full_forecasting_process\",nested=True)\n",
        "            main_run_id = main_run.info.run_id\n",
        "            print(f\"Started main MLflow run: {main_run_id}\")\n",
        "\n",
        "            # Log key parameters\n",
        "            mlflow.log_param(\"s3_bucket\", self.s3_bucket)\n",
        "            mlflow.log_param(\"s3_key\", self.s3_key)\n",
        "            mlflow.log_param(\"output_prefix\", self.output_prefix)\n",
        "            mlflow.log_param(\"split_date\", self.split_date)\n",
        "            mlflow.log_param(\"start_time\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "        else:\n",
        "            main_run = None\n",
        "\n",
        "        try:\n",
        "            # Step 1: Create S3 directory structure\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"Step 1: Setting up S3 directory structure\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            # Create S3 directory structure\n",
        "            self.s3_connector.create_s3_directory(self.s3_bucket, f\"{self.output_prefix}/\")\n",
        "            self.s3_connector.create_s3_directory(self.s3_bucket, f\"{self.output_prefix}/model_registry/\")\n",
        "            self.s3_connector.create_s3_directory(self.s3_bucket, f\"{self.output_prefix}/plots/\")\n",
        "            self.s3_connector.create_s3_directory(self.s3_bucket, f\"{self.output_prefix}/models/\")\n",
        "\n",
        "            print(f\"✅ Created S3 directory structure in s3://{self.s3_bucket}/{self.output_prefix}/\")\n",
        "\n",
        "            # Step 2: Load data from S3\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"Step 2: Loading data from S3\")\n",
        "            print(\"=\"*80)\n",
        "            self.raw_data = self.s3_connector.read_csv_from_s3(self.s3_bucket, self.s3_key)\n",
        "            if self.raw_data is None:\n",
        "                print(\"❌ Failed to load data from S3. Exiting process.\")\n",
        "                if main_run:\n",
        "                    mlflow.log_param(\"status\", \"FAILED\")\n",
        "                    mlflow.log_param(\"error\", \"Failed to load data from S3\")\n",
        "                    mlflow.end_run()\n",
        "                return None\n",
        "\n",
        "            # Log data statistics to MLflow\n",
        "            if main_run:\n",
        "                mlflow.log_param(\"data_rows\", len(self.raw_data))\n",
        "                mlflow.log_param(\"data_columns\", len(self.raw_data.columns))\n",
        "\n",
        "                # Log data schema\n",
        "                schema = self.raw_data.dtypes.astype(str).to_dict()\n",
        "                mlflow.log_dict(schema, \"data_schema.json\")\n",
        "\n",
        "            # Step 3: Preprocess data\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"Step 3: Preprocessing data\")\n",
        "            print(\"=\"*80)\n",
        "            preprocessor = DataPreprocessor()\n",
        "            self.wheat_data = preprocessor.preprocess_retail_prices(self.raw_data)\n",
        "            if self.wheat_data is None:\n",
        "                print(\"❌ Preprocessing failed. Exiting process.\")\n",
        "                if main_run:\n",
        "                    mlflow.log_param(\"status\", \"FAILED\")\n",
        "                    mlflow.log_param(\"error\", \"Preprocessing failed\")\n",
        "                    mlflow.end_run()\n",
        "                return None\n",
        "\n",
        "            # Log preprocessed data stats to MLflow\n",
        "            if main_run:\n",
        "                mlflow.log_param(\"preprocessed_rows\", len(self.wheat_data))\n",
        "\n",
        "                # Log summary statistics\n",
        "                summary_stats = self.wheat_data.describe().to_dict()\n",
        "                mlflow.log_dict(summary_stats, \"summary_statistics.json\")\n",
        "\n",
        "            # Get all states\n",
        "            self.all_states = self.wheat_data['state'].str.lower().unique().tolist()\n",
        "            print(f\"\\nFound {len(self.all_states)} states with wheat price data:\")\n",
        "            for i, state in enumerate(self.all_states):\n",
        "                print(f\"   {i+1}. {state.title()}\")\n",
        "\n",
        "            if main_run:\n",
        "                mlflow.log_param(\"total_states\", len(self.all_states))\n",
        "                mlflow.log_param(\"states\", \",\".join(sorted(self.all_states)))\n",
        "\n",
        "            # Step 4: Process each state\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"Step 4: Processing individual states\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            feature_engineer = FeatureEngineer()\n",
        "            model_trainer = ModelTrainer(\n",
        "                s3_connector=self.s3_connector,\n",
        "                s3_bucket=self.s3_bucket,\n",
        "                output_prefix=self.output_prefix,\n",
        "                mlflow_tracking_uri=self.mlflow_uri\n",
        "            )\n",
        "\n",
        "            for state_idx, state in enumerate(self.all_states):\n",
        "                print(f\"\\nProcessing state {state_idx+1}/{len(self.all_states)}: {state.title()}\")\n",
        "\n",
        "                # Filter data for this state\n",
        "                df_state = self.wheat_data[self.wheat_data['state'].str.lower() == state.lower()].copy()\n",
        "\n",
        "                # Engineer features\n",
        "                df_state = feature_engineer.engineer_features(df_state)\n",
        "\n",
        "                # Train models for this state\n",
        "                state_result = model_trainer.train_models_for_state(state, df_state, self.split_date)\n",
        "\n",
        "                if state_result is not None:\n",
        "                    # Store feature columns from first successful state if not already set\n",
        "                    if self.feature_cols is None:\n",
        "                        self.feature_cols = model_trainer.feature_cols\n",
        "\n",
        "                    # Store state result\n",
        "                    self.all_state_models[state] = state_result\n",
        "\n",
        "                    # Log information about this state to the main MLflow run\n",
        "                    if main_run:\n",
        "                        mlflow.log_metric(f\"{state}_test_rmse\", state_result['metrics']['test_rmse'])\n",
        "                        if 'test_r2' in state_result['metrics']:\n",
        "                            mlflow.log_metric(f\"{state}_test_r2\", state_result['metrics']['test_r2'])\n",
        "\n",
        "            # Step 5: Aggregate models to S3\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"Step 5: Aggregating models to S3\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            # Initialize aggregator with S3 capability and MLflow tracking\n",
        "            aggregator = ModelAggregator(\n",
        "                s3_connector=self.s3_connector,\n",
        "                s3_bucket=self.s3_bucket,\n",
        "                output_prefix=self.output_prefix,\n",
        "                mlflow_tracking_uri=self.mlflow_uri\n",
        "            )\n",
        "            combined_s3_path = aggregator.aggregate_models(self.all_state_models, self.feature_cols)\n",
        "\n",
        "            # Step 6: Print summary\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"Step 6: Results summary\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            aggregator.print_summary_table(self.all_state_models)\n",
        "\n",
        "            # Log successful states count to MLflow\n",
        "            if main_run:\n",
        "                valid_models_count = len([model for model in self.all_state_models.values() if model is not None])\n",
        "                mlflow.log_metric(\"successful_states\", valid_models_count)\n",
        "                mlflow.log_metric(\"success_rate\", valid_models_count / len(self.all_states))\n",
        "                mlflow.log_param(\"combined_model_path\", combined_s3_path)\n",
        "                mlflow.log_param(\"status\", \"SUCCESS\")\n",
        "                mlflow.log_param(\"end_time\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"✅ Wheat price forecasting process completed successfully\")\n",
        "            print(f\"✅ All outputs saved to S3: s3://{self.s3_bucket}/{self.output_prefix}/\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            return {\n",
        "                'combined_model_s3_path': combined_s3_path,\n",
        "                'all_state_models': self.all_state_models,\n",
        "                'feature_cols': self.feature_cols,\n",
        "                's3_location': f\"s3://{self.s3_bucket}/{self.output_prefix}/\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in forecasting process: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Log the error to MLflow\n",
        "            if main_run:\n",
        "                mlflow.log_param(\"status\", \"ERROR\")\n",
        "                mlflow.log_param(\"error_message\", str(e))\n",
        "                mlflow.log_text(traceback.format_exc(), \"error_traceback.txt\")\n",
        "\n",
        "            return None\n",
        "\n",
        "        finally:\n",
        "            # End the main MLflow run if it was started\n",
        "            if main_run:\n",
        "                mlflow.end_run()"
      ],
      "metadata": {
        "id": "0PWQa1sa9GPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(s3_bucket,\n",
        "         s3_key,\n",
        "         output_prefix=\"wheat_forecaster\",\n",
        "         split_date=\"2020-01-01\",\n",
        "         mlflow_uri=None,\n",
        "         aws_access_key_id=None,\n",
        "         aws_secret_access_key=None,\n",
        "         aws_region='us-east-1'):\n",
        "    \"\"\"\n",
        "    Run the wheat price forecasting pipeline using data from S3 and storing all outputs to S3.\n",
        "\n",
        "    Args:\n",
        "        s3_bucket (str): S3 bucket containing the CSV data file and for storing outputs\n",
        "        s3_key (str): S3 key (path) to the CSV data file\n",
        "        output_prefix (str): Prefix path in the S3 bucket for all outputs\n",
        "        split_date (str): Date to split train/test data\n",
        "        mlflow_uri (str, optional): MLflow tracking URI\n",
        "        aws_access_key_id (str, optional): AWS access key ID\n",
        "        aws_secret_access_key (str, optional): AWS secret access key\n",
        "        aws_region (str, optional): AWS region name\n",
        "\n",
        "    Returns:\n",
        "        dict: Results from the forecasting process with S3 paths\n",
        "    \"\"\"\n",
        "    # Configure MLflow if provided\n",
        "    if aws_access_key_id and aws_secret_access_key:\n",
        "        os.environ[\"AWS_ACCESS_KEY_ID\"] = aws_access_key_id\n",
        "        os.environ[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret_access_key\n",
        "        os.environ[\"AWS_DEFAULT_REGION\"] = aws_region\n",
        "    if mlflow_uri:\n",
        "        # Set tracking URI\n",
        "        mlflow.set_tracking_uri(mlflow_uri)\n",
        "        print(f\"MLflow tracking URI set to: {mlflow_uri}\")\n",
        "\n",
        "        # Create main experiment if it doesn't exist\n",
        "        experiment_name = \"wheat_price_forecaster_main\"\n",
        "        try:\n",
        "            experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "            if experiment:\n",
        "                experiment_id = experiment.experiment_id\n",
        "                print(f\"Using existing MLflow experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "            else:\n",
        "                experiment_id = mlflow.create_experiment(experiment_name)\n",
        "                print(f\"Created new MLflow experiment: {experiment_name} (ID: {experiment_id})\")\n",
        "\n",
        "            # Start the main run\n",
        "            with mlflow.start_run(experiment_id=experiment_id, run_name=\"pipeline_execution\",nested=True):\n",
        "                mlflow.log_param(\"execution_timestamp\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "                mlflow.log_param(\"s3_bucket\", s3_bucket)\n",
        "                mlflow.log_param(\"s3_key\", s3_key)\n",
        "                mlflow.log_param(\"output_prefix\", output_prefix)\n",
        "                mlflow.log_param(\"split_date\", split_date)\n",
        "                mlflow.log_param(\"aws_region\", aws_region)\n",
        "\n",
        "                # Initialize and run the forecaster\n",
        "                forecaster = WheatPriceForecaster(\n",
        "                    s3_bucket=s3_bucket,\n",
        "                    s3_key=s3_key,\n",
        "                    output_prefix=output_prefix,\n",
        "                    split_date=split_date,\n",
        "                    mlflow_uri=mlflow_uri,\n",
        "                    aws_access_key_id=aws_access_key_id,\n",
        "                    aws_secret_access_key=aws_secret_access_key,\n",
        "                    aws_region=aws_region\n",
        "                )\n",
        "                results = forecaster.run_full_process()\n",
        "                if results:\n",
        "                    # Add wheat_data to the results dictionary\n",
        "                    results['wheat_data'] = forecaster.wheat_data\n",
        "\n",
        "                    # # Now run the evaluation\n",
        "                    # evaluation_results = evaluate_wheat_price_models(results)\n",
        "                # Log final results\n",
        "                if results:\n",
        "                    mlflow.log_param(\"status\", \"SUCCESS\")\n",
        "                    mlflow.log_param(\"combined_model_path\", results.get('combined_model_s3_path', 'None'))\n",
        "                    mlflow.log_param(\"feature_count\", len(results.get('feature_cols', [])))\n",
        "                    mlflow.log_param(\"states_processed\", len(results.get('all_state_models', {})))\n",
        "                else:\n",
        "                    mlflow.log_param(\"status\", \"FAILED\")\n",
        "\n",
        "                return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with MLflow setup: {str(e)}\")\n",
        "            # Fall back to running without MLflow tracking for this specific run\n",
        "            forecaster = WheatPriceForecaster(\n",
        "                s3_bucket=s3_bucket,\n",
        "                s3_key=s3_key,\n",
        "                output_prefix=output_prefix,\n",
        "                split_date=split_date,\n",
        "                mlflow_uri=None,  # Don't try to use MLflow\n",
        "                aws_access_key_id=aws_access_key_id,\n",
        "                aws_secret_access_key=aws_secret_access_key,\n",
        "                aws_region=aws_region\n",
        "            )\n",
        "            results = forecaster.run_full_process()\n",
        "            return results\n",
        "    else:\n",
        "        # Run without MLflow\n",
        "        forecaster = WheatPriceForecaster(\n",
        "            s3_bucket=s3_bucket,\n",
        "            s3_key=s3_key,\n",
        "            output_prefix=output_prefix,\n",
        "            split_date=split_date,\n",
        "            mlflow_uri=None,\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key,\n",
        "            aws_region=aws_region\n",
        "        )\n",
        "        results = forecaster.run_full_process()\n",
        "        return results"
      ],
      "metadata": {
        "id": "MJI0bMFi9GSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# os.environ['AWS_ACCESS_KEY_ID'] = ''\n",
        "# os.environ['AWS_SECRET_ACCESS_KEY'] = ''\n",
        "# os.environ['AWS_DEFAULT_REGION'] = ''"
      ],
      "metadata": {
        "id": "-QQeugL2xkbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = main(\n",
        "    s3_bucket=\"foundation-project-data\",\n",
        "    s3_key=\"data/wheat_prices_merged.csv\",\n",
        "    output_prefix=\"wheat_forecaster\",\n",
        "    split_date=\"2020-01-01\",\n",
        "    mlflow_uri=\"http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/\",\n",
        "    #aws_access_key_id=\"\",\n",
        "    #aws_secret_access_key=\"\",\n",
        "    #aws_region=\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru3xWqI29fZ8",
        "outputId": "82b74b42-2939-40f9-f4f5-7da2cb02acf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow tracking URI set to: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/\n",
            "Using existing MLflow experiment: wheat_price_forecaster_main (ID: 655825255592778811)\n",
            "✅ S3 client initialized for region: eu-north-1\n",
            "🚀 Initializing Wheat Price Forecaster with S3 storage\n",
            "📄 Input file: s3://foundation-project-data/data/wheat_prices_merged.csv\n",
            "📁 Output location: s3://foundation-project-data/wheat_forecaster/\n",
            "📅 Train/Test split date: 2020-01-01\n",
            "📊 MLflow tracking URI: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/\n",
            "Using existing MLflow experiment: wheat_price_forecaster (ID: 957387433427483073)\n",
            "Started main MLflow run: 4f69b5e6c00d4f55807d8af16a33169e\n",
            "\n",
            "================================================================================\n",
            "Step 1: Setting up S3 directory structure\n",
            "================================================================================\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/plots/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/models/\n",
            "✅ Created S3 directory structure in s3://foundation-project-data/wheat_forecaster/\n",
            "\n",
            "================================================================================\n",
            "Step 2: Loading data from S3\n",
            "================================================================================\n",
            "Reading file from S3: s3://foundation-project-data/data/wheat_prices_merged.csv\n",
            "✅ Successfully read CSV from S3 with 5,658 rows\n",
            "\n",
            "================================================================================\n",
            "Step 3: Preprocessing data\n",
            "================================================================================\n",
            "Starting data preprocessing...\n",
            "Converted MSP from quintal to KG\n",
            "Filtered 4,867 retail price records\n",
            "Using 'price' column as price_per_KG\n",
            "Dropped 0 rows with missing states (0.00%)\n",
            "Remaining records: 4,867\n",
            "Converting 'date' to datetime\n",
            "Extracting time features...\n",
            "Added time features: year, month, day, quarter\n",
            "Added cyclical features: month_sin, month_cos, quarter_sin, quarter_cos\n",
            "Sorted data by state and date\n",
            "Handling missing values...\n",
            "Filled 1,026 missing Rainfall values\n",
            "Filled 0 missing Diesel Price values\n",
            "Filled 1,308 missing Diesel ROC values\n",
            "Filled 1,308 missing Wheat ROC values\n",
            "Calculated 'Diesel / Wheat Price Ratio'\n",
            "\n",
            "Remaining missing values:\n",
            "- Date: 1,298 missing values\n",
            "- Diesel Price: 1,298 missing values\n",
            "- Wheat Price (Indian Rupee per Metric Ton): 1,298 missing values\n",
            "- Diesel / Wheat Price Ratio: 1,298 missing values\n",
            "- Rainfall: 1,322 missing values\n",
            "- ANNUAL: 2,348 missing values\n",
            "- JF: 2,348 missing values\n",
            "- MAM: 2,348 missing values\n",
            "- JJAS: 2,348 missing values\n",
            "- OND: 2,348 missing values\n",
            "- index: 4,867 missing values\n",
            "- 0: 4,867 missing values\n",
            "- diesel_price: 1,298 missing values\n",
            "Filtered for wheat commodity: 4,867 records from 4,867\n",
            "✅ Preprocessing complete\n",
            "\n",
            "📊 Summary Statistics for Preprocessed Data:\n",
            "                             date         year        price          CPI  \\\n",
            "count                        4867  4867.000000  4867.000000  4867.000000   \n",
            "mean   2011-11-22 09:57:21.709472  2011.386686    19.207975     6.571177   \n",
            "min           1994-01-15 00:00:00  1994.000000     3.800000     3.330000   \n",
            "25%           2005-08-30 12:00:00  2005.000000    11.000000     4.300000   \n",
            "50%           2013-09-15 00:00:00  2013.000000    18.500000     6.370000   \n",
            "75%           2018-06-30 00:00:00  2018.000000    25.931591     8.910000   \n",
            "max           2022-12-15 00:00:00  2022.000000    60.000000    13.230000   \n",
            "std                           NaN     8.109863     9.331686     2.598563   \n",
            "\n",
            "          msp_year    MSP_Wheat  Diesel Price  \\\n",
            "count  4867.000000  4867.000000   3569.000000   \n",
            "mean   2011.227039  1324.245942    143.608571   \n",
            "min    1993.000000   350.000000     64.280000   \n",
            "25%    2005.000000   650.000000    100.130000   \n",
            "50%    2013.000000  1400.000000    134.890000   \n",
            "75%    2018.000000  1840.000000    167.670000   \n",
            "max    2022.000000  2125.000000    359.180000   \n",
            "std       8.115257   551.159864     60.091085   \n",
            "\n",
            "       Wheat Price (Indian Rupee per Metric Ton)   Diesel ROC    Wheat ROC  \\\n",
            "count                                3569.000000  4867.000000  4867.000000   \n",
            "mean                                16800.637691    -0.045546    -0.015570   \n",
            "min                                  7341.830000    -0.258800    -0.182900   \n",
            "25%                                 12370.720000    -0.227800    -0.080000   \n",
            "50%                                 14844.200000    -0.015900    -0.024400   \n",
            "75%                                 19282.070000     0.050800     0.034200   \n",
            "max                                 40377.800000     0.337400     0.265400   \n",
            "std                                  6815.883204     0.131715     0.071884   \n",
            "\n",
            "       ...  MSP_Wheat_KG  price_per_KG    month_num     day      quarter  \\\n",
            "count  ...   4867.000000   4867.000000  4867.000000  4867.0  4867.000000   \n",
            "mean   ...     13.242459     19.207975     6.609616    15.0     2.534415   \n",
            "min    ...      3.500000      3.800000     1.000000    15.0     1.000000   \n",
            "25%    ...      6.500000     11.000000     4.000000    15.0     2.000000   \n",
            "50%    ...     14.000000     18.500000     7.000000    15.0     3.000000   \n",
            "75%    ...     18.400000     25.931591    10.000000    15.0     4.000000   \n",
            "max    ...     21.250000     60.000000    12.000000    15.0     4.000000   \n",
            "std    ...      5.511599      9.331686     3.443880     0.0     1.116239   \n",
            "\n",
            "          month_sin     month_cos   quarter_sin   quarter_cos  diesel_price  \n",
            "count  4.867000e+03  4.867000e+03  4.867000e+03  4.867000e+03   3569.000000  \n",
            "mean  -2.196411e-02  1.911619e-03 -1.787549e-02  1.479351e-02    143.608571  \n",
            "min   -1.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00     64.280000  \n",
            "25%   -8.660254e-01 -8.660254e-01 -1.000000e+00 -1.836970e-16    100.130000  \n",
            "50%   -2.449294e-16 -1.836970e-16 -2.449294e-16 -1.836970e-16    134.890000  \n",
            "75%    5.000000e-01  8.660254e-01  1.224647e-16  1.000000e+00    167.670000  \n",
            "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00    359.180000  \n",
            "std    7.048365e-01  7.091719e-01  7.057169e-01  7.082589e-01     60.091085  \n",
            "\n",
            "[8 rows x 29 columns]\n",
            "\n",
            "Found 31 states with wheat price data:\n",
            "   1. Andaman And Nicobar\n",
            "   2. Andhra Pradesh\n",
            "   3. Assam\n",
            "   4. Bihar\n",
            "   5. Chandigarh\n",
            "   6. Chhattisgarh\n",
            "   7. Delhi\n",
            "   8. Goa\n",
            "   9. Gujarat\n",
            "   10. Haryana\n",
            "   11. Himachal Pradesh\n",
            "   12. Jharkhand\n",
            "   13. Karnataka\n",
            "   14. Kerala\n",
            "   15. Madhya Pradesh\n",
            "   16. Maharashtra\n",
            "   17. Manipur\n",
            "   18. Meghalaya\n",
            "   19. Mizoram\n",
            "   20. Nagaland\n",
            "   21. Orissa\n",
            "   22. Puducherry\n",
            "   23. Punjab\n",
            "   24. Rajasthan\n",
            "   25. Sikkim\n",
            "   26. Tamil Nadu\n",
            "   27. Telangana\n",
            "   28. Tripura\n",
            "   29. Uttar Pradesh\n",
            "   30. Uttarakhand\n",
            "   31. West Bengal\n",
            "\n",
            "================================================================================\n",
            "Step 4: Processing individual states\n",
            "================================================================================\n",
            "✅ MLflow tracking configured: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/plots/\n",
            "✅ Set up S3 directory structure:\n",
            "  - 📁 s3://foundation-project-data/wheat_forecaster/model_registry (models)\n",
            "  - 📁 s3://foundation-project-data/wheat_forecaster/plots (visualizations)\n",
            "\n",
            "Processing state 1/31: Andaman And Nicobar\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.993208\n",
            "lag_1m             0.988189\n",
            "rolling_mean_6m    0.983719\n",
            "lag_3m             0.968071\n",
            "MSP_Wheat_KG       0.957335\n",
            "MSP_Wheat          0.957335\n",
            "year               0.949912\n",
            "msp_year           0.947900\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Andaman And Nicobar\n",
            "================================================================================\n",
            "Found 97 records for Andaman And Nicobar\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 66 records (68.0%)\n",
            "Test data: 31 records (32.0%)\n",
            "After dropping NaN values - Train: 54, Test: 31\n",
            "Final feature matrix shapes - X_train: (54, 25), X_test: (31, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_andaman and nicobar (ID: 970560080101903254)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 9ead936e10f346bda3194b4b7ebbe9bf\n",
            "Random Forest metrics - Test RMSE: 2.4941, R²: -2.4182\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3669\n",
            "   - rolling_mean_6m: 0.2897\n",
            "   - lag_1m: 0.1009\n",
            "   - MSP_Wheat_KG: 0.0836\n",
            "   - year: 0.0717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:04:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_andaman and nicobar' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:04:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_andaman and nicobar, version 4\n",
            "Created version '4' of model 'random_forest_andaman and nicobar'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_andaman and nicobar\n",
            "🏃 View run random_forest_andaman and nicobar at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/970560080101903254/runs/9ead936e10f346bda3194b4b7ebbe9bf\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/970560080101903254\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: c2597dbf0fbf4981978e5f2c8fb43b3f\n",
            "XGBoost metrics - Test RMSE: 3.3279, R²: -5.0854\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.4372\n",
            "   - rolling_mean_3m: 0.1423\n",
            "   - MSP_Wheat_KG: 0.1131\n",
            "   - year: 0.1039\n",
            "   - diesel_price: 0.0922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:04:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_andaman and nicobar' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:04:36 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_andaman and nicobar, version 3\n",
            "Created version '3' of model 'xgboost_andaman and nicobar'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_andaman and nicobar\n",
            "🏃 View run xgboost_andaman and nicobar at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/970560080101903254/runs/c2597dbf0fbf4981978e5f2c8fb43b3f\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/970560080101903254\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: cc59117c0e08459ba1c1b328eb09081c\n",
            "Holt-Winters metrics - Test RMSE: 3.7136\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_andaman and nicobar at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/970560080101903254/runs/cc59117c0e08459ba1c1b328eb09081c\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/970560080101903254\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Andaman And Nicobar: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.2836\n",
            "   - test_rmse: 2.4941\n",
            "   - train_mae: 0.1476\n",
            "   - test_mae: 2.0949\n",
            "   - train_mape: 0.4328\n",
            "   - test_mape: 4.9890\n",
            "   - train_r2: 0.9956\n",
            "   - test_r2: -2.4182\n",
            "🏃 View run best_model_comparison_andaman and nicobar at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/970560080101903254/runs/991df51ccf8a4580b3cfba46c52e51f5\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/970560080101903254\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/andaman and nicobar_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/andaman and nicobar_best_model.pkl\n",
            "✅ Successfully processed Andaman And Nicobar\n",
            "\n",
            "Processing state 2/31: Andhra Pradesh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.980992\n",
            "rolling_mean_6m    0.965950\n",
            "lag_1m             0.953954\n",
            "lag_3m             0.929783\n",
            "year               0.917954\n",
            "MSP_Wheat_KG       0.917729\n",
            "MSP_Wheat          0.917729\n",
            "msp_year           0.914837\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Andhra Pradesh\n",
            "================================================================================\n",
            "Found 99 records for Andhra Pradesh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 66 records (66.7%)\n",
            "Test data: 33 records (33.3%)\n",
            "After dropping NaN values - Train: 54, Test: 33\n",
            "Final feature matrix shapes - X_train: (54, 25), X_test: (33, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_andhra pradesh (ID: 483282642091161192)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 9f614cfcbf474baca81ce387b4bb8534\n",
            "Random Forest metrics - Test RMSE: 4.2536, R²: -1.6305\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3039\n",
            "   - rolling_mean_6m: 0.2994\n",
            "   - roc_1m: 0.0837\n",
            "   - rolling_std_3m: 0.0634\n",
            "   - lag_1m: 0.0455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:05:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_andhra pradesh' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:05:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_andhra pradesh, version 2\n",
            "Created version '2' of model 'random_forest_andhra pradesh'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_andhra pradesh\n",
            "🏃 View run random_forest_andhra pradesh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/483282642091161192/runs/9f614cfcbf474baca81ce387b4bb8534\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/483282642091161192\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 0b62949a936748d593c4baba6d47a2aa\n",
            "XGBoost metrics - Test RMSE: 3.3055, R²: -0.5885\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.1549\n",
            "   - rolling_std_6m: 0.1523\n",
            "   - CPI: 0.1019\n",
            "   - rolling_mean_3m: 0.1008\n",
            "   - MSP_Wheat_KG: 0.0755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:05:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_andhra pradesh' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:06:02 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_andhra pradesh, version 2\n",
            "Created version '2' of model 'xgboost_andhra pradesh'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_andhra pradesh\n",
            "🏃 View run xgboost_andhra pradesh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/483282642091161192/runs/0b62949a936748d593c4baba6d47a2aa\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/483282642091161192\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: dfb6467819e64defb238334b1af91034\n",
            "Holt-Winters metrics - Test RMSE: 9.7640\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_andhra pradesh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/483282642091161192/runs/dfb6467819e64defb238334b1af91034\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/483282642091161192\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Andhra Pradesh: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.1068\n",
            "   - test_rmse: 3.3055\n",
            "   - train_mae: 0.0645\n",
            "   - test_mae: 2.5981\n",
            "   - train_mape: 0.2313\n",
            "   - test_mape: 6.9778\n",
            "   - train_r2: 0.9982\n",
            "   - test_r2: -0.5885\n",
            "🏃 View run best_model_comparison_andhra pradesh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/483282642091161192/runs/ca316d5eee984370be91eae470cbc036\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/483282642091161192\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/andhra pradesh_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/andhra pradesh_best_model.pkl\n",
            "✅ Successfully processed Andhra Pradesh\n",
            "\n",
            "Processing state 3/31: Assam\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.993224\n",
            "lag_1m             0.985648\n",
            "rolling_mean_6m    0.982591\n",
            "lag_3m             0.963256\n",
            "lag_6m             0.940372\n",
            "year               0.929634\n",
            "msp_year           0.929441\n",
            "MSP_Wheat          0.922022\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Assam\n",
            "================================================================================\n",
            "Found 159 records for Assam\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 125 records (78.6%)\n",
            "Test data: 34 records (21.4%)\n",
            "After dropping NaN values - Train: 113, Test: 34\n",
            "Final feature matrix shapes - X_train: (113, 25), X_test: (34, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_assam (ID: 825516195861702545)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 96b5594e062841abb36a24e5566c1f38\n",
            "Random Forest metrics - Test RMSE: 1.1689, R²: 0.6758\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3257\n",
            "   - rolling_mean_6m: 0.2369\n",
            "   - lag_1m: 0.2029\n",
            "   - lag_3m: 0.1358\n",
            "   - year: 0.0386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:06:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_assam' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:07:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_assam, version 2\n",
            "Created version '2' of model 'random_forest_assam'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_assam\n",
            "🏃 View run random_forest_assam at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/825516195861702545/runs/96b5594e062841abb36a24e5566c1f38\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/825516195861702545\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 24d1efb13ed4471aa1d07f7c017bd619\n",
            "XGBoost metrics - Test RMSE: 1.3997, R²: 0.5351\n",
            "Top 5 important features:\n",
            "   - lag_3m: 0.5243\n",
            "   - lag_1m: 0.1862\n",
            "   - year: 0.1359\n",
            "   - rolling_mean_6m: 0.0599\n",
            "   - rolling_mean_3m: 0.0544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:07:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_assam' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:07:27 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_assam, version 2\n",
            "Created version '2' of model 'xgboost_assam'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_assam\n",
            "🏃 View run xgboost_assam at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/825516195861702545/runs/24d1efb13ed4471aa1d07f7c017bd619\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/825516195861702545\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 29ae589cc0e74bdb8b05bd0834f21ad7\n",
            "Holt-Winters metrics - Test RMSE: 3.0048\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_assam at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/825516195861702545/runs/29ae589cc0e74bdb8b05bd0834f21ad7\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/825516195861702545\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Assam: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.2224\n",
            "   - test_rmse: 1.1689\n",
            "   - train_mae: 0.1340\n",
            "   - test_mae: 0.8873\n",
            "   - train_mape: 0.7181\n",
            "   - test_mape: 3.2550\n",
            "   - train_r2: 0.9979\n",
            "   - test_r2: 0.6758\n",
            "🏃 View run best_model_comparison_assam at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/825516195861702545/runs/68fdd6823b4944f28ca5585509360c88\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/825516195861702545\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/assam_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/assam_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/assam_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/assam_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/assam_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/assam_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/assam/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/assam/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/assam/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/assam/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/assam/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/assam/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/assam/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/assam_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/assam_best_model.pkl\n",
            "✅ Successfully processed Assam\n",
            "\n",
            "Processing state 4/31: Bihar\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.991982\n",
            "lag_1m             0.983748\n",
            "rolling_mean_6m    0.981128\n",
            "lag_3m             0.961915\n",
            "MSP_Wheat          0.954708\n",
            "MSP_Wheat_KG       0.954708\n",
            "msp_year           0.937907\n",
            "year               0.937503\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Bihar\n",
            "================================================================================\n",
            "Found 259 records for Bihar\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 223 records (86.1%)\n",
            "Test data: 36 records (13.9%)\n",
            "After dropping NaN values - Train: 146, Test: 36\n",
            "Final feature matrix shapes - X_train: (146, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_bihar (ID: 475930764270883970)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: ed4c37dd740c4dc292254cedb139ce95\n",
            "Random Forest metrics - Test RMSE: 1.4489, R²: 0.6543\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.8469\n",
            "   - rolling_mean_6m: 0.0464\n",
            "   - lag_1m: 0.0437\n",
            "   - MSP_to_retail_ratio: 0.0160\n",
            "   - roc_1m: 0.0102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:08:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_bihar' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:08:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_bihar, version 2\n",
            "Created version '2' of model 'random_forest_bihar'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_bihar\n",
            "🏃 View run random_forest_bihar at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/475930764270883970/runs/ed4c37dd740c4dc292254cedb139ce95\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/475930764270883970\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 561699d946a04004a96ba46557feb421\n",
            "XGBoost metrics - Test RMSE: 1.4960, R²: 0.6315\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.2850\n",
            "   - rolling_mean_3m: 0.2362\n",
            "   - lag_1m: 0.2182\n",
            "   - MSP_Wheat_KG: 0.0868\n",
            "   - rolling_std_6m: 0.0407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:08:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_bihar' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:08:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_bihar, version 2\n",
            "Created version '2' of model 'xgboost_bihar'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_bihar\n",
            "🏃 View run xgboost_bihar at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/475930764270883970/runs/561699d946a04004a96ba46557feb421\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/475930764270883970\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 6724992df4864760b9593f7317840045\n",
            "Holt-Winters metrics - Test RMSE: 4.1494\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_bihar at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/475930764270883970/runs/6724992df4864760b9593f7317840045\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/475930764270883970\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Bihar: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.3460\n",
            "   - test_rmse: 1.4489\n",
            "   - train_mae: 0.2223\n",
            "   - test_mae: 0.9745\n",
            "   - train_mape: 1.3140\n",
            "   - test_mape: 4.1453\n",
            "   - train_r2: 0.9921\n",
            "   - test_r2: 0.6543\n",
            "🏃 View run best_model_comparison_bihar at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/475930764270883970/runs/a08ae31e52c2490590d148b2017fdee7\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/475930764270883970\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/bihar_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/bihar_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/bihar_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/bihar_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/bihar_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/bihar_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/bihar/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/bihar/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/bihar/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/bihar/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/bihar/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/bihar/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/bihar/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/bihar_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/bihar_best_model.pkl\n",
            "✅ Successfully processed Bihar\n",
            "\n",
            "Processing state 5/31: Chandigarh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.962519\n",
            "rolling_mean_6m    0.896990\n",
            "lag_1m             0.896789\n",
            "lag_3m             0.766036\n",
            "MSP_Wheat_KG       0.751957\n",
            "MSP_Wheat          0.751957\n",
            "msp_year           0.735284\n",
            "year               0.721384\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Chandigarh\n",
            "================================================================================\n",
            "Found 87 records for Chandigarh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 64 records (73.6%)\n",
            "Test data: 23 records (26.4%)\n",
            "After dropping NaN values - Train: 52, Test: 23\n",
            "Final feature matrix shapes - X_train: (52, 25), X_test: (23, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_chandigarh (ID: 391420983674295879)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: dc27e99a80e14c70b2da6a7fbcfe1ee7\n",
            "Random Forest metrics - Test RMSE: 1.5562, R²: 0.5651\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.5622\n",
            "   - lag_1m: 0.3384\n",
            "   - rolling_mean_6m: 0.0219\n",
            "   - roc_1m: 0.0160\n",
            "   - MSP_to_retail_ratio: 0.0117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:09:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_chandigarh' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:09:55 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_chandigarh, version 2\n",
            "Created version '2' of model 'random_forest_chandigarh'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_chandigarh\n",
            "🏃 View run random_forest_chandigarh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/391420983674295879/runs/dc27e99a80e14c70b2da6a7fbcfe1ee7\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/391420983674295879\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 2bafdf49fcfb4802bfebc2cdd43f0fd3\n",
            "XGBoost metrics - Test RMSE: 1.9523, R²: 0.3154\n",
            "Top 5 important features:\n",
            "   - CPI: 0.5967\n",
            "   - lag_1m: 0.1553\n",
            "   - rolling_mean_3m: 0.1012\n",
            "   - roc_3m: 0.0211\n",
            "   - lag_6m: 0.0172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:10:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_chandigarh' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:10:20 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_chandigarh, version 2\n",
            "Created version '2' of model 'xgboost_chandigarh'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_chandigarh\n",
            "🏃 View run xgboost_chandigarh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/391420983674295879/runs/2bafdf49fcfb4802bfebc2cdd43f0fd3\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/391420983674295879\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 0d33f636ecb34928a65c6b0829da74d7\n",
            "Holt-Winters metrics - Test RMSE: 5.2383\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_chandigarh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/391420983674295879/runs/0d33f636ecb34928a65c6b0829da74d7\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/391420983674295879\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Chandigarh: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.2893\n",
            "   - test_rmse: 1.5562\n",
            "   - train_mae: 0.1610\n",
            "   - test_mae: 1.1810\n",
            "   - train_mape: 0.8006\n",
            "   - test_mape: 5.1207\n",
            "   - train_r2: 0.9851\n",
            "   - test_r2: 0.5651\n",
            "🏃 View run best_model_comparison_chandigarh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/391420983674295879/runs/dd27f301300d4f91bd762bf65391bf56\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/391420983674295879\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/chandigarh_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/chandigarh_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/chandigarh_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/chandigarh_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/chandigarh_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/chandigarh_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/chandigarh_best_model.pkl\n",
            "✅ Successfully processed Chandigarh\n",
            "\n",
            "Processing state 6/31: Chhattisgarh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price                                        1.000000\n",
            "price_per_KG                                 1.000000\n",
            "rolling_mean_3m                              0.650236\n",
            "roc_1m                                       0.638076\n",
            "roc_3m                                       0.614765\n",
            "rolling_mean_6m                              0.608490\n",
            "Wheat Price (Indian Rupee per Metric Ton)    0.554384\n",
            "Diesel Price                                 0.536052\n",
            "diesel_price                                 0.536052\n",
            "MSP_Wheat                                    0.534047\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Chhattisgarh\n",
            "================================================================================\n",
            "Found 27 records for Chhattisgarh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 0 records (0.0%)\n",
            "Test data: 27 records (100.0%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Chhattisgarh - insufficient data after cleaning\n",
            "\n",
            "Processing state 7/31: Delhi\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.994947\n",
            "rolling_mean_6m    0.988619\n",
            "lag_1m             0.988350\n",
            "MSP_Wheat_KG       0.978569\n",
            "MSP_Wheat          0.978569\n",
            "lag_3m             0.976122\n",
            "year               0.965751\n",
            "msp_year           0.964683\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Delhi\n",
            "================================================================================\n",
            "Found 310 records for Delhi\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 283 records (91.3%)\n",
            "Test data: 27 records (8.7%)\n",
            "After dropping NaN values - Train: 156, Test: 27\n",
            "Final feature matrix shapes - X_train: (156, 25), X_test: (27, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_delhi (ID: 805557253290265605)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: b5174cf736e94f4cbd3430a6cf741be2\n",
            "Random Forest metrics - Test RMSE: 1.0122, R²: 0.8041\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.7129\n",
            "   - rolling_mean_6m: 0.1156\n",
            "   - lag_1m: 0.0668\n",
            "   - MSP_Wheat_KG: 0.0327\n",
            "   - year: 0.0150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:11:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_delhi' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:11:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_delhi, version 2\n",
            "Created version '2' of model 'random_forest_delhi'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_delhi\n",
            "🏃 View run random_forest_delhi at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/805557253290265605/runs/b5174cf736e94f4cbd3430a6cf741be2\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/805557253290265605\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: e4c04eff46e6467eab9879936ff90aeb\n",
            "XGBoost metrics - Test RMSE: 1.1473, R²: 0.7482\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.4590\n",
            "   - rolling_mean_3m: 0.2160\n",
            "   - MSP_Wheat_KG: 0.0648\n",
            "   - lag_1m: 0.0512\n",
            "   - lag_12m: 0.0401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:11:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_delhi' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:11:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_delhi, version 2\n",
            "Created version '2' of model 'xgboost_delhi'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_delhi\n",
            "🏃 View run xgboost_delhi at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/805557253290265605/runs/e4c04eff46e6467eab9879936ff90aeb\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/805557253290265605\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: f1bda552179f466d9cfdb0349cc918f8\n",
            "Holt-Winters metrics - Test RMSE: 4.0344\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_delhi at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/805557253290265605/runs/f1bda552179f466d9cfdb0349cc918f8\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/805557253290265605\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Delhi: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.3551\n",
            "   - test_rmse: 1.0122\n",
            "   - train_mae: 0.1713\n",
            "   - test_mae: 0.7603\n",
            "   - train_mape: 1.0038\n",
            "   - test_mape: 3.1877\n",
            "   - train_r2: 0.9916\n",
            "   - test_r2: 0.8041\n",
            "🏃 View run best_model_comparison_delhi at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/805557253290265605/runs/87b072f445c842269c35e2b729d94a76\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/805557253290265605\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/delhi_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/delhi_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/delhi_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/delhi_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/delhi_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/delhi_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/delhi/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/delhi/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/delhi/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/delhi/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/delhi/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/delhi/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/delhi/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/delhi_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/delhi_best_model.pkl\n",
            "✅ Successfully processed Delhi\n",
            "\n",
            "Processing state 8/31: Goa\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.988238\n",
            "lag_1m             0.979324\n",
            "rolling_mean_6m    0.973388\n",
            "lag_3m             0.934758\n",
            "lag_6m             0.911878\n",
            "year               0.897717\n",
            "msp_year           0.892188\n",
            "lag_12m            0.865166\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Goa\n",
            "================================================================================\n",
            "Found 80 records for Goa\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 56 records (70.0%)\n",
            "Test data: 24 records (30.0%)\n",
            "After dropping NaN values - Train: 43, Test: 22\n",
            "Final feature matrix shapes - X_train: (43, 25), X_test: (22, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_goa (ID: 636709703506848025)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 24b1742bd09d4e999ebaad4e08a54240\n",
            "Random Forest metrics - Test RMSE: 4.1054, R²: -2.2594\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.4283\n",
            "   - roc_3m: 0.2931\n",
            "   - lag_1m: 0.1222\n",
            "   - rolling_mean_6m: 0.0485\n",
            "   - year: 0.0328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:12:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_goa' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:12:47 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_goa, version 2\n",
            "Created version '2' of model 'random_forest_goa'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_goa\n",
            "🏃 View run random_forest_goa at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/636709703506848025/runs/24b1742bd09d4e999ebaad4e08a54240\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/636709703506848025\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 5501f62859054e0099e2dfb174ffbb79\n",
            "XGBoost metrics - Test RMSE: 4.0217, R²: -2.1278\n",
            "Top 5 important features:\n",
            "   - MSP_Wheat_KG: 0.2311\n",
            "   - rolling_mean_3m: 0.1959\n",
            "   - year: 0.1120\n",
            "   - roc_3m: 0.1108\n",
            "   - lag_6m: 0.0866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:13:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_goa' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:13:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_goa, version 2\n",
            "Created version '2' of model 'xgboost_goa'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_goa\n",
            "🏃 View run xgboost_goa at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/636709703506848025/runs/5501f62859054e0099e2dfb174ffbb79\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/636709703506848025\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 4aae3e0dc5e14ac198af44e4d239f5cd\n",
            "Holt-Winters metrics - Test RMSE: 2.1603\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_goa at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/636709703506848025/runs/4aae3e0dc5e14ac198af44e4d239f5cd\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/636709703506848025\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Goa: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.4663\n",
            "   - test_rmse: 2.1603\n",
            "   - train_mae: 0.3414\n",
            "   - test_mae: 1.8619\n",
            "   - train_mape: 1.1056\n",
            "   - test_mape: 5.0445\n",
            "   - train_r2: 0.8337\n",
            "   - test_r2: 0.0975\n",
            "🏃 View run best_model_comparison_goa at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/636709703506848025/runs/5aee02176e1148b992b10057e47ee0ea\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/636709703506848025\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/goa_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/goa_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/goa/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/goa/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/goa/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/goa/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/goa/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/goa/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/goa/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/goa_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/goa_best_model.pkl\n",
            "✅ Successfully processed Goa\n",
            "\n",
            "Processing state 9/31: Gujarat\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.996899\n",
            "rolling_mean_6m    0.993703\n",
            "lag_1m             0.993117\n",
            "lag_3m             0.986002\n",
            "lag_6m             0.980850\n",
            "MSP_Wheat_KG       0.969012\n",
            "MSP_Wheat          0.969012\n",
            "lag_12m            0.967627\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Gujarat\n",
            "================================================================================\n",
            "Found 258 records for Gujarat\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 222 records (86.0%)\n",
            "Test data: 36 records (14.0%)\n",
            "After dropping NaN values - Train: 134, Test: 36\n",
            "Final feature matrix shapes - X_train: (134, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_gujarat (ID: 980562315729280568)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: ed43c9d101104bad8e4da173af217e94\n",
            "Random Forest metrics - Test RMSE: 4.9122, R²: -1.7847\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.6912\n",
            "   - rolling_mean_6m: 0.1492\n",
            "   - lag_1m: 0.0940\n",
            "   - year: 0.0137\n",
            "   - MSP_Wheat_KG: 0.0130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:14:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_gujarat' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:14:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_gujarat, version 2\n",
            "Created version '2' of model 'random_forest_gujarat'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_gujarat\n",
            "🏃 View run random_forest_gujarat at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/980562315729280568/runs/ed43c9d101104bad8e4da173af217e94\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/980562315729280568\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: af9ef34dae27409b8dbfcc26982657b1\n",
            "XGBoost metrics - Test RMSE: 5.2374, R²: -2.1656\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.4055\n",
            "   - rolling_mean_3m: 0.2278\n",
            "   - MSP_Wheat_KG: 0.1679\n",
            "   - lag_1m: 0.0550\n",
            "   - year: 0.0541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:14:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_gujarat' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:14:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_gujarat, version 2\n",
            "Created version '2' of model 'xgboost_gujarat'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_gujarat\n",
            "🏃 View run xgboost_gujarat at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/980562315729280568/runs/af9ef34dae27409b8dbfcc26982657b1\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/980562315729280568\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 547185a7aded4c439ccad3a23c3889cd\n",
            "Holt-Winters metrics - Test RMSE: 3.9267\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_gujarat at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/980562315729280568/runs/547185a7aded4c439ccad3a23c3889cd\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/980562315729280568\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Gujarat: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.9089\n",
            "   - test_rmse: 3.9267\n",
            "   - train_mae: 0.6170\n",
            "   - test_mae: 3.2930\n",
            "   - train_mape: 3.8642\n",
            "   - test_mape: 11.6397\n",
            "   - train_r2: 0.9421\n",
            "   - test_r2: -0.7795\n",
            "🏃 View run best_model_comparison_gujarat at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/980562315729280568/runs/c4799d4ffa2c4b869b0a2217f694b9fd\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/980562315729280568\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/gujarat_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/gujarat_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/gujarat/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/gujarat_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/gujarat_best_model.pkl\n",
            "✅ Successfully processed Gujarat\n",
            "\n",
            "Processing state 10/31: Haryana\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.980551\n",
            "rolling_mean_6m    0.971206\n",
            "lag_1m             0.957536\n",
            "lag_3m             0.930766\n",
            "year               0.920828\n",
            "msp_year           0.918282\n",
            "MSP_Wheat_KG       0.904261\n",
            "MSP_Wheat          0.904261\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Haryana\n",
            "================================================================================\n",
            "Found 136 records for Haryana\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 100 records (73.5%)\n",
            "Test data: 36 records (26.5%)\n",
            "After dropping NaN values - Train: 88, Test: 36\n",
            "Final feature matrix shapes - X_train: (88, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_haryana (ID: 847499864479308147)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: e1977955676f4ea1b38b75799317dc91\n",
            "Random Forest metrics - Test RMSE: 2.5765, R²: -3.4008\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.5195\n",
            "   - rolling_mean_6m: 0.1507\n",
            "   - lag_1m: 0.1257\n",
            "   - MSP_to_retail_ratio: 0.0701\n",
            "   - Diesel / Wheat Price Ratio: 0.0344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:15:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_haryana' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:15:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_haryana, version 2\n",
            "Created version '2' of model 'random_forest_haryana'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_haryana\n",
            "🏃 View run random_forest_haryana at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/847499864479308147/runs/e1977955676f4ea1b38b75799317dc91\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/847499864479308147\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 7241594e18934b5da43b9249009096e2\n",
            "XGBoost metrics - Test RMSE: 2.6412, R²: -3.6246\n",
            "Top 5 important features:\n",
            "   - lag_1m: 0.1905\n",
            "   - rolling_mean_3m: 0.1881\n",
            "   - year: 0.1660\n",
            "   - rolling_mean_6m: 0.1587\n",
            "   - lag_3m: 0.1155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:15:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_haryana' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:15:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_haryana, version 2\n",
            "Created version '2' of model 'xgboost_haryana'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_haryana\n",
            "🏃 View run xgboost_haryana at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/847499864479308147/runs/7241594e18934b5da43b9249009096e2\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/847499864479308147\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 5bf77feef66e422884bbf2814519c508\n",
            "Holt-Winters metrics - Test RMSE: 0.9177\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_haryana at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/847499864479308147/runs/5bf77feef66e422884bbf2814519c508\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/847499864479308147\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Haryana: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.6442\n",
            "   - test_rmse: 0.9177\n",
            "   - train_mae: 0.4595\n",
            "   - test_mae: 0.7647\n",
            "   - train_mape: 2.5957\n",
            "   - test_mape: 3.3519\n",
            "   - train_r2: 0.9276\n",
            "   - test_r2: 0.4417\n",
            "🏃 View run best_model_comparison_haryana at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/847499864479308147/runs/c78be5af4402414b99e292e56e0a8baf\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/847499864479308147\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/haryana_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/haryana_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/haryana/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/haryana/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/haryana/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/haryana/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/haryana/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/haryana/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/haryana/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/haryana_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/haryana_best_model.pkl\n",
            "✅ Successfully processed Haryana\n",
            "\n",
            "Processing state 11/31: Himachal Pradesh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "MAM                0.959778\n",
            "rolling_mean_3m    0.917462\n",
            "JF                 0.868506\n",
            "lag_1m             0.853700\n",
            "msp_year           0.837622\n",
            "year               0.835793\n",
            "MSP_Wheat_KG       0.811949\n",
            "MSP_Wheat          0.811949\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Himachal Pradesh\n",
            "================================================================================\n",
            "Found 37 records for Himachal Pradesh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 25 records (67.6%)\n",
            "Test data: 12 records (32.4%)\n",
            "After dropping NaN values - Train: 13, Test: 12\n",
            "Final feature matrix shapes - X_train: (13, 25), X_test: (12, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_himachal pradesh (ID: 120846478319441965)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: dcb5878c3da34a40a2cb431d7b5fc150\n",
            "Random Forest metrics - Test RMSE: 5.9799, R²: -4.1441\n",
            "Top 5 important features:\n",
            "   - year: 0.1514\n",
            "   - rolling_mean_3m: 0.1348\n",
            "   - rolling_std_6m: 0.1093\n",
            "   - rolling_mean_6m: 0.0948\n",
            "   - MSP_Wheat_KG: 0.0893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:16:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_himachal pradesh' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:16:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_himachal pradesh, version 2\n",
            "Created version '2' of model 'random_forest_himachal pradesh'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_himachal pradesh\n",
            "🏃 View run random_forest_himachal pradesh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/120846478319441965/runs/dcb5878c3da34a40a2cb431d7b5fc150\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/120846478319441965\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: a19d547bd45f42cd9e6fc98e5b71a643\n",
            "XGBoost metrics - Test RMSE: 4.7876, R²: -2.2973\n",
            "Top 5 important features:\n",
            "   - CPI: 0.5031\n",
            "   - MSP_Wheat_KG: 0.4560\n",
            "   - Diesel / Wheat Price Ratio: 0.0230\n",
            "   - year: 0.0113\n",
            "   - diesel_price: 0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:17:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_himachal pradesh' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:17:23 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_himachal pradesh, version 2\n",
            "Created version '2' of model 'xgboost_himachal pradesh'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_himachal pradesh\n",
            "🏃 View run xgboost_himachal pradesh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/120846478319441965/runs/a19d547bd45f42cd9e6fc98e5b71a643\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/120846478319441965\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: d14a4154ca6f4109a40ba1b21fcb8260\n",
            "❌ Error training Holt-Winters model: Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.\n",
            "🏃 View run holt_winters_himachal pradesh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/120846478319441965/runs/d14a4154ca6f4109a40ba1b21fcb8260\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/120846478319441965\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Himachal Pradesh: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.1544\n",
            "   - test_rmse: 4.7876\n",
            "   - train_mae: 0.0953\n",
            "   - test_mae: 4.4757\n",
            "   - train_mape: 0.5663\n",
            "   - test_mape: 17.4322\n",
            "   - train_r2: 0.9991\n",
            "   - test_r2: -2.2973\n",
            "🏃 View run best_model_comparison_himachal pradesh at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/120846478319441965/runs/cd3bfc2c12e646a5a818f7841b636aa1\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/120846478319441965\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/himachal pradesh_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/himachal pradesh_best_model.pkl\n",
            "✅ Successfully processed Himachal Pradesh\n",
            "\n",
            "Processing state 12/31: Jharkhand\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.976709\n",
            "lag_1m             0.960154\n",
            "rolling_mean_6m    0.952307\n",
            "lag_3m             0.902141\n",
            "MSP_Wheat          0.864170\n",
            "MSP_Wheat_KG       0.864170\n",
            "year               0.855873\n",
            "msp_year           0.853486\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Jharkhand\n",
            "================================================================================\n",
            "Found 128 records for Jharkhand\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 92 records (71.9%)\n",
            "Test data: 36 records (28.1%)\n",
            "After dropping NaN values - Train: 80, Test: 36\n",
            "Final feature matrix shapes - X_train: (80, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_jharkhand (ID: 293452666711369971)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 3db22aaeeb904a9d87cbc2dfd66dd8e6\n",
            "Random Forest metrics - Test RMSE: 1.2729, R²: 0.7251\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3945\n",
            "   - rolling_mean_6m: 0.3006\n",
            "   - lag_1m: 0.1376\n",
            "   - MSP_to_retail_ratio: 0.0585\n",
            "   - Diesel / Wheat Price Ratio: 0.0413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:18:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_jharkhand' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:18:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_jharkhand, version 2\n",
            "Created version '2' of model 'random_forest_jharkhand'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_jharkhand\n",
            "🏃 View run random_forest_jharkhand at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/293452666711369971/runs/3db22aaeeb904a9d87cbc2dfd66dd8e6\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/293452666711369971\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: fe0fe9607a094810bd991b2c7c1cd961\n",
            "XGBoost metrics - Test RMSE: 1.2306, R²: 0.7431\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.2609\n",
            "   - rolling_mean_3m: 0.2101\n",
            "   - lag_3m: 0.2089\n",
            "   - lag_1m: 0.0935\n",
            "   - rolling_std_6m: 0.0469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:18:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_jharkhand' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:18:30 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_jharkhand, version 2\n",
            "Created version '2' of model 'xgboost_jharkhand'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_jharkhand\n",
            "🏃 View run xgboost_jharkhand at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/293452666711369971/runs/fe0fe9607a094810bd991b2c7c1cd961\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/293452666711369971\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 46d6e481b7bb4a3bae9f9dbd65eafc7d\n",
            "Holt-Winters metrics - Test RMSE: 6.3747\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_jharkhand at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/293452666711369971/runs/46d6e481b7bb4a3bae9f9dbd65eafc7d\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/293452666711369971\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Jharkhand: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.0894\n",
            "   - test_rmse: 1.2306\n",
            "   - train_mae: 0.0522\n",
            "   - test_mae: 0.9504\n",
            "   - train_mape: 0.2375\n",
            "   - test_mape: 3.5593\n",
            "   - train_r2: 0.9991\n",
            "   - test_r2: 0.7431\n",
            "🏃 View run best_model_comparison_jharkhand at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/293452666711369971/runs/9d14d0f43f044268b9ea5009fa955dc9\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/293452666711369971\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/jharkhand_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/jharkhand_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/jharkhand_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/jharkhand_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/jharkhand_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/jharkhand_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/jharkhand_best_model.pkl\n",
            "✅ Successfully processed Jharkhand\n",
            "\n",
            "Processing state 13/31: Karnataka\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.995779\n",
            "rolling_mean_6m    0.993618\n",
            "lag_1m             0.988378\n",
            "lag_3m             0.986917\n",
            "lag_6m             0.979794\n",
            "MSP_Wheat          0.979409\n",
            "MSP_Wheat_KG       0.979409\n",
            "lag_12m            0.971125\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Karnataka\n",
            "================================================================================\n",
            "Found 301 records for Karnataka\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 266 records (88.4%)\n",
            "Test data: 35 records (11.6%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Karnataka - insufficient data after cleaning\n",
            "\n",
            "Processing state 14/31: Kerala\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.989927\n",
            "rolling_mean_6m    0.982877\n",
            "lag_1m             0.979262\n",
            "MSP_Wheat          0.968962\n",
            "MSP_Wheat_KG       0.968962\n",
            "lag_3m             0.957190\n",
            "lag_6m             0.954730\n",
            "year               0.951830\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Kerala\n",
            "================================================================================\n",
            "Found 224 records for Kerala\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 188 records (83.9%)\n",
            "Test data: 36 records (16.1%)\n",
            "After dropping NaN values - Train: 135, Test: 36\n",
            "Final feature matrix shapes - X_train: (135, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_kerala (ID: 894517152820527327)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 3fbef26b830040699f59e591c0d8fc74\n",
            "Random Forest metrics - Test RMSE: 3.2028, R²: -0.4771\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.8392\n",
            "   - rolling_mean_6m: 0.0589\n",
            "   - lag_1m: 0.0340\n",
            "   - MSP_to_retail_ratio: 0.0251\n",
            "   - Diesel / Wheat Price Ratio: 0.0070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:19:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_kerala' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:19:32 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_kerala, version 2\n",
            "Created version '2' of model 'random_forest_kerala'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_kerala\n",
            "🏃 View run random_forest_kerala at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/894517152820527327/runs/3fbef26b830040699f59e591c0d8fc74\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/894517152820527327\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: ddcc7f65c6144c6fb00627c29c09d235\n",
            "XGBoost metrics - Test RMSE: 3.8821, R²: -1.1701\n",
            "Top 5 important features:\n",
            "   - year: 0.4481\n",
            "   - rolling_mean_3m: 0.2148\n",
            "   - rolling_mean_6m: 0.1761\n",
            "   - lag_1m: 0.0638\n",
            "   - MSP_to_retail_ratio: 0.0159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:19:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_kerala' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:19:57 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_kerala, version 2\n",
            "Created version '2' of model 'xgboost_kerala'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_kerala\n",
            "🏃 View run xgboost_kerala at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/894517152820527327/runs/ddcc7f65c6144c6fb00627c29c09d235\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/894517152820527327\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 8032b3d50ba448a5bc0f928da5cf0b90\n",
            "Holt-Winters metrics - Test RMSE: 2.6003\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_kerala at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/894517152820527327/runs/8032b3d50ba448a5bc0f928da5cf0b90\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/894517152820527327\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Kerala: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 2.0331\n",
            "   - test_rmse: 2.6003\n",
            "   - train_mae: 1.2874\n",
            "   - test_mae: 2.2261\n",
            "   - train_mape: 4.8367\n",
            "   - test_mape: 6.1703\n",
            "   - train_r2: 0.8793\n",
            "   - test_r2: 0.0264\n",
            "🏃 View run best_model_comparison_kerala at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/894517152820527327/runs/6aeba1c2492f45d981182b3be4bfa76c\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/894517152820527327\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/kerala_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/kerala_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/kerala/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/kerala/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/kerala/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/kerala/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/kerala/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/kerala/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/kerala/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/kerala_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/kerala_best_model.pkl\n",
            "✅ Successfully processed Kerala\n",
            "\n",
            "Processing state 15/31: Madhya Pradesh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.996886\n",
            "rolling_mean_6m    0.993000\n",
            "lag_1m             0.992638\n",
            "MSP_Wheat          0.985689\n",
            "MSP_Wheat_KG       0.985689\n",
            "lag_3m             0.985005\n",
            "lag_6m             0.977425\n",
            "lag_12m            0.967828\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Madhya Pradesh\n",
            "================================================================================\n",
            "Found 283 records for Madhya Pradesh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 247 records (87.3%)\n",
            "Test data: 36 records (12.7%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Madhya Pradesh - insufficient data after cleaning\n",
            "\n",
            "Processing state 16/31: Maharashtra\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.993091\n",
            "rolling_mean_6m    0.987926\n",
            "lag_1m             0.983160\n",
            "MSP_Wheat          0.978237\n",
            "MSP_Wheat_KG       0.978237\n",
            "lag_3m             0.972835\n",
            "lag_6m             0.966410\n",
            "lag_12m            0.963693\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Maharashtra\n",
            "================================================================================\n",
            "Found 288 records for Maharashtra\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 252 records (87.5%)\n",
            "Test data: 36 records (12.5%)\n",
            "After dropping NaN values - Train: 141, Test: 36\n",
            "Final feature matrix shapes - X_train: (141, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_maharashtra (ID: 796230522728744342)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 0dfff88b91804024be82ef66c118022e\n",
            "Random Forest metrics - Test RMSE: 3.6550, R²: -1.6399\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.5738\n",
            "   - rolling_mean_6m: 0.2148\n",
            "   - year: 0.0826\n",
            "   - lag_3m: 0.0278\n",
            "   - lag_1m: 0.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:20:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_maharashtra' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:20:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_maharashtra, version 2\n",
            "Created version '2' of model 'random_forest_maharashtra'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_maharashtra\n",
            "🏃 View run random_forest_maharashtra at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/796230522728744342/runs/0dfff88b91804024be82ef66c118022e\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/796230522728744342\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 828404b4cc764864b83f7789904711b2\n",
            "XGBoost metrics - Test RMSE: 3.7066, R²: -1.7151\n",
            "Top 5 important features:\n",
            "   - year: 0.4472\n",
            "   - rolling_mean_6m: 0.2261\n",
            "   - rolling_mean_3m: 0.1909\n",
            "   - lag_3m: 0.0600\n",
            "   - roc_3m: 0.0130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:21:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_maharashtra' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:21:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_maharashtra, version 2\n",
            "Created version '2' of model 'xgboost_maharashtra'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_maharashtra\n",
            "🏃 View run xgboost_maharashtra at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/796230522728744342/runs/828404b4cc764864b83f7789904711b2\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/796230522728744342\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 720de2835a1949bda9d8e242293999f2\n",
            "Holt-Winters metrics - Test RMSE: 2.2955\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_maharashtra at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/796230522728744342/runs/720de2835a1949bda9d8e242293999f2\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/796230522728744342\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Maharashtra: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 1.6292\n",
            "   - test_rmse: 2.2955\n",
            "   - train_mae: 1.1973\n",
            "   - test_mae: 1.7778\n",
            "   - train_mape: 5.2881\n",
            "   - test_mape: 5.1949\n",
            "   - train_r2: 0.8940\n",
            "   - test_r2: -0.0413\n",
            "🏃 View run best_model_comparison_maharashtra at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/796230522728744342/runs/341c41284578406f8d96008f6d56a4b6\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/796230522728744342\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/maharashtra_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/maharashtra_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/maharashtra_best_model.pkl\n",
            "✅ Successfully processed Maharashtra\n",
            "\n",
            "Processing state 17/31: Manipur\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "roc_3m             1.000000\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.918559\n",
            "lag_1m             0.632456\n",
            "roc_1m             0.632456\n",
            "Diesel ROC         0.473540\n",
            "Wheat ROC          0.223475\n",
            "diesel_price       0.211446\n",
            "Diesel Price       0.211446\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Manipur\n",
            "================================================================================\n",
            "⚠️ Skipping Manipur - insufficient data (only 7 records)\n",
            "\n",
            "Processing state 18/31: Meghalaya\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.994184\n",
            "lag_1m             0.989276\n",
            "MSP_Wheat_KG       0.988283\n",
            "MSP_Wheat          0.988283\n",
            "rolling_mean_6m    0.985185\n",
            "lag_3m             0.969710\n",
            "year               0.968191\n",
            "msp_year           0.967927\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Meghalaya\n",
            "================================================================================\n",
            "Found 179 records for Meghalaya\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 146 records (81.6%)\n",
            "Test data: 33 records (18.4%)\n",
            "After dropping NaN values - Train: 60, Test: 33\n",
            "Final feature matrix shapes - X_train: (60, 25), X_test: (33, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_meghalaya (ID: 260402784426429180)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 9106371b8e3f4ae2ad26fd51a0c90688\n",
            "Random Forest metrics - Test RMSE: 2.3687, R²: 0.2994\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.5929\n",
            "   - lag_1m: 0.1485\n",
            "   - rolling_mean_6m: 0.1078\n",
            "   - year: 0.0219\n",
            "   - lag_3m: 0.0162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:22:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_meghalaya' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:22:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_meghalaya, version 2\n",
            "Created version '2' of model 'random_forest_meghalaya'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_meghalaya\n",
            "🏃 View run random_forest_meghalaya at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/260402784426429180/runs/9106371b8e3f4ae2ad26fd51a0c90688\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/260402784426429180\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: d8563248b80a482185de9de22f73ea67\n",
            "XGBoost metrics - Test RMSE: 2.5694, R²: 0.1757\n",
            "Top 5 important features:\n",
            "   - lag_3m: 0.3311\n",
            "   - rolling_mean_6m: 0.1909\n",
            "   - rolling_mean_3m: 0.1518\n",
            "   - lag_1m: 0.1012\n",
            "   - rolling_std_6m: 0.0849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:22:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_meghalaya' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:22:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_meghalaya, version 2\n",
            "Created version '2' of model 'xgboost_meghalaya'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_meghalaya\n",
            "🏃 View run xgboost_meghalaya at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/260402784426429180/runs/d8563248b80a482185de9de22f73ea67\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/260402784426429180\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 038ec348afe74fd8b2099b4fbab94329\n",
            "Holt-Winters metrics - Test RMSE: 3.0715\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_meghalaya at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/260402784426429180/runs/038ec348afe74fd8b2099b4fbab94329\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/260402784426429180\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Meghalaya: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.3659\n",
            "   - test_rmse: 2.3687\n",
            "   - train_mae: 0.2157\n",
            "   - test_mae: 1.7304\n",
            "   - train_mape: 0.7181\n",
            "   - test_mape: 4.9913\n",
            "   - train_r2: 0.9817\n",
            "   - test_r2: 0.2994\n",
            "🏃 View run best_model_comparison_meghalaya at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/260402784426429180/runs/8902cc7496604fbbbdc9844586705654\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/260402784426429180\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/meghalaya_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/meghalaya_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/meghalaya_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/meghalaya_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/meghalaya_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/meghalaya_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/meghalaya_best_model.pkl\n",
            "✅ Successfully processed Meghalaya\n",
            "\n",
            "Processing state 19/31: Mizoram\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.987783\n",
            "year               0.981586\n",
            "msp_year           0.981100\n",
            "MSP_Wheat_KG       0.980937\n",
            "MSP_Wheat          0.980937\n",
            "lag_1m             0.979405\n",
            "rolling_mean_6m    0.948631\n",
            "lag_3m             0.914167\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Mizoram\n",
            "================================================================================\n",
            "Found 41 records for Mizoram\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 21 records (51.2%)\n",
            "Test data: 20 records (48.8%)\n",
            "After dropping NaN values - Train: 1, Test: 20\n",
            "⚠️ Skipping Mizoram - insufficient data after cleaning\n",
            "\n",
            "Processing state 20/31: Nagaland\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.970164\n",
            "lag_1m             0.955073\n",
            "rolling_mean_6m    0.901761\n",
            "ANNUAL             0.833618\n",
            "OND                0.831077\n",
            "lag_3m             0.825295\n",
            "MSP_Wheat          0.764570\n",
            "MSP_Wheat_KG       0.764570\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Nagaland\n",
            "================================================================================\n",
            "Found 123 records for Nagaland\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 88 records (71.5%)\n",
            "Test data: 35 records (28.5%)\n",
            "After dropping NaN values - Train: 76, Test: 35\n",
            "Final feature matrix shapes - X_train: (76, 25), X_test: (35, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_nagaland (ID: 614505012785867318)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 824d4741755042c4bf789b3f840d9671\n",
            "Random Forest metrics - Test RMSE: 5.4358, R²: 0.6488\n",
            "Top 5 important features:\n",
            "   - MSP_to_retail_ratio: 0.6514\n",
            "   - rolling_mean_3m: 0.1415\n",
            "   - lag_1m: 0.0788\n",
            "   - rolling_std_6m: 0.0359\n",
            "   - rolling_mean_6m: 0.0342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:23:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_nagaland' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:23:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_nagaland, version 2\n",
            "Created version '2' of model 'random_forest_nagaland'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_nagaland\n",
            "🏃 View run random_forest_nagaland at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/614505012785867318/runs/824d4741755042c4bf789b3f840d9671\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/614505012785867318\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 0e0a3dec9ad64b7fa1719745c3064ac3\n",
            "XGBoost metrics - Test RMSE: 4.9772, R²: 0.7055\n",
            "Top 5 important features:\n",
            "   - lag_3m: 0.3488\n",
            "   - MSP_to_retail_ratio: 0.2516\n",
            "   - rolling_mean_6m: 0.0882\n",
            "   - rolling_mean_3m: 0.0805\n",
            "   - year: 0.0679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:24:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_nagaland' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:24:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_nagaland, version 2\n",
            "Created version '2' of model 'xgboost_nagaland'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_nagaland\n",
            "🏃 View run xgboost_nagaland at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/614505012785867318/runs/0e0a3dec9ad64b7fa1719745c3064ac3\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/614505012785867318\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 4f546d378fbe4798a3d5541624a8e0a2\n",
            "Holt-Winters metrics - Test RMSE: 24.4913\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_nagaland at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/614505012785867318/runs/4f546d378fbe4798a3d5541624a8e0a2\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/614505012785867318\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Nagaland: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.0673\n",
            "   - test_rmse: 4.9772\n",
            "   - train_mae: 0.0506\n",
            "   - test_mae: 3.6232\n",
            "   - train_mape: 0.2093\n",
            "   - test_mape: 9.7128\n",
            "   - train_r2: 1.0000\n",
            "   - test_r2: 0.7055\n",
            "🏃 View run best_model_comparison_nagaland at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/614505012785867318/runs/6beded292cc542b19e881d1f24cc51eb\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/614505012785867318\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/nagaland_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/nagaland_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/nagaland_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/nagaland_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/nagaland_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/nagaland_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/nagaland/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/nagaland_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/nagaland_best_model.pkl\n",
            "✅ Successfully processed Nagaland\n",
            "\n",
            "Processing state 21/31: Orissa\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.997116\n",
            "lag_1m             0.995029\n",
            "rolling_mean_6m    0.992670\n",
            "lag_3m             0.984767\n",
            "lag_6m             0.974535\n",
            "MSP_Wheat_KG       0.969719\n",
            "MSP_Wheat          0.969719\n",
            "lag_12m            0.950152\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Orissa\n",
            "================================================================================\n",
            "Found 174 records for Orissa\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 138 records (79.3%)\n",
            "Test data: 36 records (20.7%)\n",
            "After dropping NaN values - Train: 87, Test: 36\n",
            "Final feature matrix shapes - X_train: (87, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_orissa (ID: 385283577071730117)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 16349a7b162e4859b189f3eed6cee082\n",
            "Random Forest metrics - Test RMSE: 4.9234, R²: -67.5213\n",
            "Top 5 important features:\n",
            "   - CPI: 0.2112\n",
            "   - rolling_mean_3m: 0.1612\n",
            "   - year: 0.1516\n",
            "   - rolling_mean_6m: 0.1335\n",
            "   - MSP_Wheat_KG: 0.1081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:25:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_orissa' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:25:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_orissa, version 2\n",
            "Created version '2' of model 'random_forest_orissa'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_orissa\n",
            "🏃 View run random_forest_orissa at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/385283577071730117/runs/16349a7b162e4859b189f3eed6cee082\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/385283577071730117\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 32d5621f62fa4087a8c961b627c6bc42\n",
            "XGBoost metrics - Test RMSE: 3.5199, R²: -34.0241\n",
            "Top 5 important features:\n",
            "   - MSP_Wheat_KG: 0.4644\n",
            "   - CPI: 0.4622\n",
            "   - year: 0.0171\n",
            "   - lag_1m: 0.0127\n",
            "   - rolling_mean_3m: 0.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:25:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_orissa' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:25:41 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_orissa, version 2\n",
            "Created version '2' of model 'xgboost_orissa'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_orissa\n",
            "🏃 View run xgboost_orissa at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/385283577071730117/runs/32d5621f62fa4087a8c961b627c6bc42\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/385283577071730117\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: c07d6b5140114f14a2a423fa3d7f59e6\n",
            "Holt-Winters metrics - Test RMSE: 3.9760\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_orissa at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/385283577071730117/runs/c07d6b5140114f14a2a423fa3d7f59e6\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/385283577071730117\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Orissa: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.1001\n",
            "   - test_rmse: 3.5199\n",
            "   - train_mae: 0.0663\n",
            "   - test_mae: 3.3982\n",
            "   - train_mape: 0.3959\n",
            "   - test_mape: 10.1048\n",
            "   - train_r2: 0.9997\n",
            "   - test_r2: -34.0241\n",
            "🏃 View run best_model_comparison_orissa at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/385283577071730117/runs/d33c069070f944dcb9eb3b33cb0e49f3\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/385283577071730117\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/orissa_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/orissa_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/orissa_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/orissa_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/orissa_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/orissa_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/orissa/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/orissa/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/orissa/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/orissa/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/orissa/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/orissa/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/orissa/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/orissa_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/orissa_best_model.pkl\n",
            "✅ Successfully processed Orissa\n",
            "\n",
            "Processing state 22/31: Puducherry\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.947999\n",
            "lag_1m             0.919493\n",
            "MSP_Wheat_KG       0.843505\n",
            "MSP_Wheat          0.843505\n",
            "msp_year           0.842547\n",
            "year               0.836874\n",
            "rolling_mean_6m    0.828812\n",
            "lag_3m             0.707011\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Puducherry\n",
            "================================================================================\n",
            "Found 78 records for Puducherry\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 52 records (66.7%)\n",
            "Test data: 26 records (33.3%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Puducherry - insufficient data after cleaning\n",
            "\n",
            "Processing state 23/31: Punjab\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.990961\n",
            "rolling_mean_6m    0.981796\n",
            "lag_1m             0.964806\n",
            "lag_3m             0.952290\n",
            "year               0.940151\n",
            "msp_year           0.935377\n",
            "MSP_Wheat          0.926581\n",
            "MSP_Wheat_KG       0.926581\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Punjab\n",
            "================================================================================\n",
            "Found 134 records for Punjab\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 98 records (73.1%)\n",
            "Test data: 36 records (26.9%)\n",
            "After dropping NaN values - Train: 86, Test: 36\n",
            "Final feature matrix shapes - X_train: (86, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_punjab (ID: 810701662396791980)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 381a69bf59a446e88b0ec167f7ba12d7\n",
            "Random Forest metrics - Test RMSE: 0.9112, R²: -0.2891\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3151\n",
            "   - lag_1m: 0.1821\n",
            "   - rolling_mean_6m: 0.1762\n",
            "   - MSP_Wheat_KG: 0.1203\n",
            "   - MSP_to_retail_ratio: 0.0556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:26:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_punjab' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:26:43 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_punjab, version 2\n",
            "Created version '2' of model 'random_forest_punjab'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_punjab\n",
            "🏃 View run random_forest_punjab at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/810701662396791980/runs/381a69bf59a446e88b0ec167f7ba12d7\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/810701662396791980\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 627f0a2977194cdfac001358b897e79b\n",
            "XGBoost metrics - Test RMSE: 0.8455, R²: -0.1099\n",
            "Top 5 important features:\n",
            "   - MSP_Wheat_KG: 0.5766\n",
            "   - CPI: 0.1318\n",
            "   - year: 0.0666\n",
            "   - rolling_mean_3m: 0.0437\n",
            "   - rolling_mean_6m: 0.0413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:27:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_punjab' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:27:06 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_punjab, version 2\n",
            "Created version '2' of model 'xgboost_punjab'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_punjab\n",
            "🏃 View run xgboost_punjab at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/810701662396791980/runs/627f0a2977194cdfac001358b897e79b\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/810701662396791980\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: db45c789f8244a44986ca3d0317cfe8a\n",
            "Holt-Winters metrics - Test RMSE: 2.3688\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_punjab at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/810701662396791980/runs/db45c789f8244a44986ca3d0317cfe8a\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/810701662396791980\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Punjab: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.0841\n",
            "   - test_rmse: 0.8455\n",
            "   - train_mae: 0.0543\n",
            "   - test_mae: 0.7041\n",
            "   - train_mape: 0.3056\n",
            "   - test_mape: 3.1548\n",
            "   - train_r2: 0.9978\n",
            "   - test_r2: -0.1099\n",
            "🏃 View run best_model_comparison_punjab at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/810701662396791980/runs/9efa321689c94f7ab47fc232a148aef8\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/810701662396791980\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/punjab_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/punjab_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/punjab_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/punjab_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/punjab_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/punjab_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/punjab/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/punjab/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/punjab/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/punjab/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/punjab/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/punjab/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/punjab/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/punjab_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/punjab_best_model.pkl\n",
            "✅ Successfully processed Punjab\n",
            "\n",
            "Processing state 24/31: Rajasthan\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.996646\n",
            "rolling_mean_6m    0.993361\n",
            "lag_1m             0.992727\n",
            "lag_3m             0.984086\n",
            "lag_6m             0.979230\n",
            "MSP_Wheat_KG       0.977201\n",
            "MSP_Wheat          0.977201\n",
            "lag_12m            0.967716\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Rajasthan\n",
            "================================================================================\n",
            "Found 292 records for Rajasthan\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 256 records (87.7%)\n",
            "Test data: 36 records (12.3%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Rajasthan - insufficient data after cleaning\n",
            "\n",
            "Processing state 25/31: Sikkim\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.968801\n",
            "lag_1m             0.948113\n",
            "rolling_mean_6m    0.934039\n",
            "rolling_std_6m     0.918382\n",
            "roc_3m             0.817870\n",
            "lag_3m             0.783756\n",
            "rolling_std_3m     0.614148\n",
            "MSP_Wheat_KG       0.603755\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Sikkim\n",
            "================================================================================\n",
            "Found 25 records for Sikkim\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 0 records (0.0%)\n",
            "Test data: 25 records (100.0%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Sikkim - insufficient data after cleaning\n",
            "\n",
            "Processing state 26/31: Tamil Nadu\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.998875\n",
            "lag_1m             0.997563\n",
            "rolling_mean_6m    0.997434\n",
            "lag_3m             0.994488\n",
            "lag_6m             0.990685\n",
            "MSP_Wheat          0.984919\n",
            "MSP_Wheat_KG       0.984919\n",
            "lag_12m            0.983355\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Tamil Nadu\n",
            "================================================================================\n",
            "Found 314 records for Tamil Nadu\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 278 records (88.5%)\n",
            "Test data: 36 records (11.5%)\n",
            "After dropping NaN values - Train: 153, Test: 36\n",
            "Final feature matrix shapes - X_train: (153, 25), X_test: (36, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_tamil nadu (ID: 292722273853716452)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 7824737856194d9aaa802a9bd41e5c99\n",
            "Random Forest metrics - Test RMSE: 2.4542, R²: -2.0429\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.4116\n",
            "   - rolling_mean_6m: 0.3580\n",
            "   - lag_1m: 0.1351\n",
            "   - lag_3m: 0.0574\n",
            "   - year: 0.0101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:28:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_tamil nadu' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:28:08 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_tamil nadu, version 2\n",
            "Created version '2' of model 'random_forest_tamil nadu'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_tamil nadu\n",
            "🏃 View run random_forest_tamil nadu at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/292722273853716452/runs/7824737856194d9aaa802a9bd41e5c99\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/292722273853716452\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 46b8e900877344bfb0c8cce02ca8b735\n",
            "XGBoost metrics - Test RMSE: 2.6648, R²: -2.5875\n",
            "Top 5 important features:\n",
            "   - year: 0.5378\n",
            "   - rolling_mean_6m: 0.2130\n",
            "   - rolling_mean_3m: 0.1002\n",
            "   - lag_1m: 0.0667\n",
            "   - lag_6m: 0.0269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:28:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_tamil nadu' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:28:32 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_tamil nadu, version 2\n",
            "Created version '2' of model 'xgboost_tamil nadu'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_tamil nadu\n",
            "🏃 View run xgboost_tamil nadu at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/292722273853716452/runs/46b8e900877344bfb0c8cce02ca8b735\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/292722273853716452\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: 951b6c9b71be449a98f8e7cbe44d9eb0\n",
            "Holt-Winters metrics - Test RMSE: 1.1682\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_tamil nadu at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/292722273853716452/runs/951b6c9b71be449a98f8e7cbe44d9eb0\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/292722273853716452\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Tamil Nadu: holt_winters\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.7900\n",
            "   - test_rmse: 1.1682\n",
            "   - train_mae: 0.5157\n",
            "   - test_mae: 0.9688\n",
            "   - train_mape: 2.1239\n",
            "   - test_mape: 2.6433\n",
            "   - train_r2: 0.9845\n",
            "   - test_r2: 0.3106\n",
            "🏃 View run best_model_comparison_tamil nadu at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/292722273853716452/runs/dc77a329152b4ef09b94c25e936e62b0\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/292722273853716452\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/tamil nadu_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/tamil nadu_forecast.png\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (holt_winters) to s3://foundation-project-data/wheat_forecaster/model_registry/tamil nadu_best_model.pkl\n",
            "✅ Successfully processed Tamil Nadu\n",
            "\n",
            "Processing state 27/31: Telangana\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.995722\n",
            "rolling_mean_6m    0.991543\n",
            "lag_1m             0.991303\n",
            "lag_3m             0.982249\n",
            "lag_6m             0.973351\n",
            "MSP_Wheat_KG       0.968573\n",
            "MSP_Wheat          0.968573\n",
            "msp_year           0.957326\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Telangana\n",
            "================================================================================\n",
            "Found 153 records for Telangana\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 125 records (81.7%)\n",
            "Test data: 28 records (18.3%)\n",
            "After dropping NaN values - Train: 63, Test: 28\n",
            "Final feature matrix shapes - X_train: (63, 25), X_test: (28, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_telangana (ID: 330442492123962138)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: 5045b215f5d347e69f849538025eb1a6\n",
            "Random Forest metrics - Test RMSE: 3.1366, R²: -1.7398\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.4570\n",
            "   - rolling_mean_3m: 0.2019\n",
            "   - year: 0.1254\n",
            "   - MSP_Wheat_KG: 0.0635\n",
            "   - lag_1m: 0.0433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:29:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_telangana' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:29:31 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_telangana, version 2\n",
            "Created version '2' of model 'random_forest_telangana'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_telangana\n",
            "🏃 View run random_forest_telangana at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/330442492123962138/runs/5045b215f5d347e69f849538025eb1a6\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/330442492123962138\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: 66a30630cc684e1183e8b80619eb7208\n",
            "XGBoost metrics - Test RMSE: 2.5392, R²: -0.7955\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.6853\n",
            "   - MSP_Wheat_KG: 0.0857\n",
            "   - rolling_mean_3m: 0.0609\n",
            "   - MSP_to_retail_ratio: 0.0336\n",
            "   - lag_12m: 0.0314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:29:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_telangana' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:29:55 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_telangana, version 2\n",
            "Created version '2' of model 'xgboost_telangana'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_telangana\n",
            "🏃 View run xgboost_telangana at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/330442492123962138/runs/66a30630cc684e1183e8b80619eb7208\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/330442492123962138\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: f6dbb9a4ee684d7cb0974d7e42d700f3\n",
            "Holt-Winters metrics - Test RMSE: 3.0535\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_telangana at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/330442492123962138/runs/f6dbb9a4ee684d7cb0974d7e42d700f3\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/330442492123962138\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Telangana: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.1071\n",
            "   - test_rmse: 2.5392\n",
            "   - train_mae: 0.0642\n",
            "   - test_mae: 2.0579\n",
            "   - train_mape: 0.3247\n",
            "   - test_mape: 6.1197\n",
            "   - train_r2: 0.9997\n",
            "   - test_r2: -0.7955\n",
            "🏃 View run best_model_comparison_telangana at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/330442492123962138/runs/b8c1c2585063463da406da7febcc676c\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/330442492123962138\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/telangana_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/telangana_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/telangana_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/telangana_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/telangana_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/telangana_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/telangana/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/telangana/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/telangana/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/telangana/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/telangana/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/telangana/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/telangana/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/telangana_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/telangana_best_model.pkl\n",
            "✅ Successfully processed Telangana\n",
            "\n",
            "Processing state 28/31: Tripura\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "year                                        NaN\n",
            "price                                       NaN\n",
            "CPI                                         NaN\n",
            "msp_year                                    NaN\n",
            "MSP_Wheat                                   NaN\n",
            "Diesel Price                                NaN\n",
            "Wheat Price (Indian Rupee per Metric Ton)   NaN\n",
            "Diesel ROC                                  NaN\n",
            "Wheat ROC                                   NaN\n",
            "Diesel / Wheat Price Ratio                  NaN\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Tripura\n",
            "================================================================================\n",
            "⚠️ Skipping Tripura - insufficient data (only 1 records)\n",
            "\n",
            "Processing state 29/31: Uttar Pradesh\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.996179\n",
            "lag_1m             0.992883\n",
            "rolling_mean_6m    0.990952\n",
            "lag_3m             0.979976\n",
            "MSP_Wheat          0.979790\n",
            "MSP_Wheat_KG       0.979790\n",
            "lag_6m             0.970929\n",
            "year               0.968669\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Uttar Pradesh\n",
            "================================================================================\n",
            "Found 306 records for Uttar Pradesh\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 270 records (88.2%)\n",
            "Test data: 36 records (11.8%)\n",
            "After dropping NaN values - Train: 0, Test: 0\n",
            "⚠️ Skipping Uttar Pradesh - insufficient data after cleaning\n",
            "\n",
            "Processing state 30/31: Uttarakhand\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.982989\n",
            "lag_1m             0.969170\n",
            "rolling_mean_6m    0.951346\n",
            "lag_3m             0.907491\n",
            "MSP_Wheat_KG       0.881051\n",
            "MSP_Wheat          0.881051\n",
            "year               0.869378\n",
            "msp_year           0.867749\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: Uttarakhand\n",
            "================================================================================\n",
            "Found 102 records for Uttarakhand\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 71 records (69.6%)\n",
            "Test data: 31 records (30.4%)\n",
            "After dropping NaN values - Train: 59, Test: 31\n",
            "Final feature matrix shapes - X_train: (59, 25), X_test: (31, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_uttarakhand (ID: 401887017500909504)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: d5edc329fb654182b33c06db1c668b09\n",
            "Random Forest metrics - Test RMSE: 2.2336, R²: 0.1460\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.3392\n",
            "   - rolling_mean_6m: 0.2596\n",
            "   - lag_1m: 0.1132\n",
            "   - MSP_Wheat_KG: 0.1056\n",
            "   - year: 0.0539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:30:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_uttarakhand' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:30:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_uttarakhand, version 2\n",
            "Created version '2' of model 'random_forest_uttarakhand'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_uttarakhand\n",
            "🏃 View run random_forest_uttarakhand at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/401887017500909504/runs/d5edc329fb654182b33c06db1c668b09\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/401887017500909504\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: d887f534d8be4b3381e7f21a5d616ec7\n",
            "XGBoost metrics - Test RMSE: 1.6941, R²: 0.5088\n",
            "Top 5 important features:\n",
            "   - rolling_mean_6m: 0.3066\n",
            "   - MSP_Wheat_KG: 0.1675\n",
            "   - year: 0.1238\n",
            "   - rolling_mean_3m: 0.1234\n",
            "   - lag_6m: 0.1014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:31:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_uttarakhand' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:31:23 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_uttarakhand, version 2\n",
            "Created version '2' of model 'xgboost_uttarakhand'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_uttarakhand\n",
            "🏃 View run xgboost_uttarakhand at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/401887017500909504/runs/d887f534d8be4b3381e7f21a5d616ec7\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/401887017500909504\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: b018a0591da7485f9ca4e112cca4e8ec\n",
            "Holt-Winters metrics - Test RMSE: 6.7719\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_uttarakhand at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/401887017500909504/runs/b018a0591da7485f9ca4e112cca4e8ec\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/401887017500909504\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for Uttarakhand: xgboost\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.0997\n",
            "   - test_rmse: 1.6941\n",
            "   - train_mae: 0.0588\n",
            "   - test_mae: 1.4444\n",
            "   - train_mape: 0.3085\n",
            "   - test_mape: 6.3961\n",
            "   - train_r2: 0.9989\n",
            "   - test_r2: 0.5088\n",
            "🏃 View run best_model_comparison_uttarakhand at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/401887017500909504/runs/a881ca5eee5a4bcfada9c3235fd90d8a\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/401887017500909504\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_xgboost_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_xgboost_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_xgboost_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/uttarakhand_xgboost_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (xgboost) to s3://foundation-project-data/wheat_forecaster/model_registry/uttarakhand_best_model.pkl\n",
            "✅ Successfully processed Uttarakhand\n",
            "\n",
            "Processing state 31/31: West Bengal\n",
            "Adding time series features...\n",
            "Set date as index and sorted data\n",
            "Added lag_1m feature\n",
            "Added lag_3m feature\n",
            "Added lag_6m feature\n",
            "Added lag_12m feature\n",
            "Added rolling_mean_3m feature\n",
            "Added rolling_std_3m feature\n",
            "Added rolling_mean_6m feature\n",
            "Added rolling_std_6m feature\n",
            "Added roc_1m feature\n",
            "Added roc_3m feature\n",
            "Added MSP_to_retail_ratio feature\n",
            "✅ Feature engineering complete. Dataset now has 40 numeric features\n",
            "\n",
            "📊 Correlation with price_per_KG:\n",
            "price              1.000000\n",
            "price_per_KG       1.000000\n",
            "rolling_mean_3m    0.991265\n",
            "lag_1m             0.983536\n",
            "rolling_mean_6m    0.980504\n",
            "MSP_Wheat_KG       0.977476\n",
            "MSP_Wheat          0.977476\n",
            "year               0.971739\n",
            "msp_year           0.970974\n",
            "lag_3m             0.955344\n",
            "Name: price_per_KG, dtype: float64\n",
            "\n",
            "================================================================================\n",
            "📌 Processing state: West Bengal\n",
            "================================================================================\n",
            "Found 165 records for West Bengal\n",
            "Using 25 features: MSP_Wheat_KG, CPI, diesel_price, Diesel ROC, Wheat ROC, Diesel / Wheat Price Ratio, Rainfall, year, month_num, quarter, month_sin, month_cos, quarter_sin, quarter_cos, lag_1m, lag_3m, lag_6m, lag_12m, rolling_mean_3m, rolling_mean_6m, rolling_std_3m, rolling_std_6m, roc_1m, roc_3m, MSP_to_retail_ratio\n",
            "Preparing train/test split using date 2020-01-01\n",
            "Train data: 130 records (78.8%)\n",
            "Test data: 35 records (21.2%)\n",
            "After dropping NaN values - Train: 82, Test: 35\n",
            "Final feature matrix shapes - X_train: (82, 25), X_test: (35, 25)\n",
            "✅ MLflow experiment: wheat_price_forecast_west bengal (ID: 708359278913264189)\n",
            "\n",
            "🔹 Training Random Forest model...\n",
            "RF Parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'random_state': 42, 'n_jobs': -1}\n",
            "Started MLflow run: e1d87e5d11d24690bd899aa92bc2126d\n",
            "Random Forest metrics - Test RMSE: 1.7884, R²: 0.3017\n",
            "Top 5 important features:\n",
            "   - rolling_mean_3m: 0.7072\n",
            "   - lag_1m: 0.1187\n",
            "   - rolling_mean_6m: 0.0743\n",
            "   - MSP_to_retail_ratio: 0.0167\n",
            "   - diesel_price: 0.0140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:32:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'random_forest_west bengal' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:32:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_west bengal, version 2\n",
            "Created version '2' of model 'random_forest_west bengal'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged Random Forest model to MLflow: random_forest_west bengal\n",
            "🏃 View run random_forest_west bengal at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/708359278913264189/runs/e1d87e5d11d24690bd899aa92bc2126d\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/708359278913264189\n",
            "\n",
            "🔹 Training XGBoost model...\n",
            "XGBoost Parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42}\n",
            "Started MLflow run: a8d7b5cf4af74ddf9381485866d8beb1\n",
            "XGBoost metrics - Test RMSE: 1.9416, R²: 0.1770\n",
            "Top 5 important features:\n",
            "   - year: 0.3140\n",
            "   - rolling_mean_3m: 0.2239\n",
            "   - lag_1m: 0.1496\n",
            "   - CPI: 0.1188\n",
            "   - rolling_mean_6m: 0.1044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/20 07:32:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Registered model 'xgboost_west bengal' already exists. Creating a new version of this model...\n",
            "2025/04/20 07:32:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_west bengal, version 2\n",
            "Created version '2' of model 'xgboost_west bengal'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logged XGBoost model to MLflow: xgboost_west bengal\n",
            "🏃 View run xgboost_west bengal at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/708359278913264189/runs/a8d7b5cf4af74ddf9381485866d8beb1\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/708359278913264189\n",
            "\n",
            "🔹 Training Holt-Winters model...\n",
            "Holt-Winters Parameters: {'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12}\n",
            "Started MLflow run: af29c7ea7a5741028a3494330cf27c5c\n",
            "Holt-Winters metrics - Test RMSE: 3.9181\n",
            "✅ Logged Holt-Winters model to MLflow\n",
            "🏃 View run holt_winters_west bengal at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/708359278913264189/runs/af29c7ea7a5741028a3494330cf27c5c\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/708359278913264189\n",
            "\n",
            "🔹 Determining best model...\n",
            "Best model for West Bengal: random_forest\n",
            "Best model metrics:\n",
            "   - train_rmse: 0.3606\n",
            "   - test_rmse: 1.7884\n",
            "   - train_mae: 0.2440\n",
            "   - test_mae: 1.4809\n",
            "   - train_mape: 1.3313\n",
            "   - test_mape: 5.9852\n",
            "   - train_r2: 0.9887\n",
            "   - test_r2: 0.3017\n",
            "🏃 View run best_model_comparison_west bengal at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/708359278913264189/runs/17639f26e66844639305f9b7e71e2ea8\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/708359278913264189\n",
            "\n",
            "🔹 Creating visualization...\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/west bengal_forecast.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved visualization to s3://foundation-project-data/wheat_forecaster/plots/west bengal_forecast.png\n",
            "Saving figure to S3: s3://foundation-project-data/wheat_forecaster/plots/west bengal_random_forest_importance.png\n",
            "✅ Successfully saved figure to S3\n",
            "✅ Saved feature importance plot to s3://foundation-project-data/wheat_forecaster/plots/west bengal_random_forest_importance.png\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/plots/west bengal_random_forest_importance.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved feature importance data to s3://foundation-project-data/wheat_forecaster/plots/west bengal_random_forest_importance.json\n",
            "✅ Created S3 directory: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/random_forest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved random_forest model to s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/random_forest.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/xgboost.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved xgboost model to s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/xgboost.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/holt_winters.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved holt_winters model to s3://foundation-project-data/wheat_forecaster/model_registry/west bengal/holt_winters.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/model_registry/west bengal_best_model.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "Saved best model (random_forest) to s3://foundation-project-data/wheat_forecaster/model_registry/west bengal_best_model.pkl\n",
            "✅ Successfully processed West Bengal\n",
            "\n",
            "================================================================================\n",
            "Step 5: Aggregating models to S3\n",
            "================================================================================\n",
            "✅ MLflow tracking configured for aggregator: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/\n",
            "\n",
            "================================================================================\n",
            "📦 Aggregating models across all states to S3\n",
            "================================================================================\n",
            "Aggregating models for 21/21 states\n",
            "✅ MLflow experiment for aggregation: wheat_price_forecast_aggregated (ID: 592832557275875003)\n",
            "Started MLflow run: a1aa077f11a1434fab0e685f7662b378\n",
            "✅ Logged aggregated model metadata to MLflow\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_best_model_20250420_073330.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "✅ Saved combined model to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_best_model_20250420_073330.pkl\n",
            "Saving pickled object to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_best_model_latest.pkl\n",
            "✅ Successfully saved pickled object to S3\n",
            "✅ Saved latest version to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_best_model_latest.pkl\n",
            "Saving data to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_metadata_20250420_073330.json\n",
            "❌ Error: Data type not supported for direct S3 upload\n",
            "✅ Saved metadata to S3: s3://foundation-project-data/wheat_forecaster/models/all_states_metadata_20250420_073330.json\n",
            "🏃 View run aggregated_models_20250420_073330 at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/592832557275875003/runs/a1aa077f11a1434fab0e685f7662b378\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/592832557275875003\n",
            "\n",
            "================================================================================\n",
            "Step 6: Results summary\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "📊 Summary of Results\n",
            "================================================================================\n",
            "State                Best Model      Test RMSE    Test MAPE    R²      \n",
            "--------------------------------------------------------------------------------\n",
            "Andaman And Nicobar  random_forest   2.4941       4.99%        -2.4182 \n",
            "Andhra Pradesh       xgboost         3.3055       6.98%        -0.5885 \n",
            "Assam                random_forest   1.1689       3.26%        0.6758  \n",
            "Bihar                random_forest   1.4489       4.15%        0.6543  \n",
            "Chandigarh           random_forest   1.5562       5.12%        0.5651  \n",
            "Delhi                random_forest   1.0122       3.19%        0.8041  \n",
            "Goa                  holt_winters    2.1603       5.04%        0.0975  \n",
            "Gujarat              holt_winters    3.9267       11.64%       -0.7795 \n",
            "Haryana              holt_winters    0.9177       3.35%        0.4417  \n",
            "Himachal Pradesh     xgboost         4.7876       17.43%       -2.2973 \n",
            "Jharkhand            xgboost         1.2306       3.56%        0.7431  \n",
            "Kerala               holt_winters    2.6003       6.17%        0.0264  \n",
            "Maharashtra          holt_winters    2.2955       5.19%        -0.0413 \n",
            "Meghalaya            random_forest   2.3687       4.99%        0.2994  \n",
            "Nagaland             xgboost         4.9772       9.71%        0.7055  \n",
            "Orissa               xgboost         3.5199       10.10%       -34.0241\n",
            "Punjab               xgboost         0.8455       3.15%        -0.1099 \n",
            "Tamil Nadu           holt_winters    1.1682       2.64%        0.3106  \n",
            "Telangana            xgboost         2.5392       6.12%        -0.7955 \n",
            "Uttarakhand          xgboost         1.6941       6.40%        0.5088  \n",
            "West Bengal          random_forest   1.7884       5.99%        0.3017  \n",
            "================================================================================\n",
            "✅ Successfully processed 21/21 states\n",
            "🏃 View run model_performance_summary at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/866422211067638996/runs/4e01d62424d94cf5b2b8a7b6f3c8571f\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/866422211067638996\n",
            "✅ Logged summary statistics to MLflow\n",
            "\n",
            "================================================================================\n",
            "✅ Wheat price forecasting process completed successfully\n",
            "✅ All outputs saved to S3: s3://foundation-project-data/wheat_forecaster/\n",
            "================================================================================\n",
            "🏃 View run full_forecasting_process at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/957387433427483073/runs/4f69b5e6c00d4f55807d8af16a33169e\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/957387433427483073\n",
            "🏃 View run pipeline_execution at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/655825255592778811/runs/ba61a0e88ca94fbda4d5d8c1f403e7cc\n",
            "🧪 View experiment at: http://ec2-51-20-136-254.eu-north-1.compute.amazonaws.com:5000/#/experiments/655825255592778811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_wheat_price_models_minimal(forecaster_results, target_mape=20.0):\n",
        "    \"\"\"\n",
        "    Minimal evaluation of wheat price forecasting models using only the metrics\n",
        "    already calculated in the results dictionary.\n",
        "\n",
        "    Args:\n",
        "        forecaster_results: Results dictionary from WheatPriceForecaster.run_full_process()\n",
        "        target_mape: Target MAPE value to achieve (default: 20.0%)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing basic evaluation results\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"📊 Minimal Model Evaluation\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Extract results\n",
        "    all_state_models = forecaster_results['all_state_models']\n",
        "    valid_models = {state: data for state, data in all_state_models.items() if data is not None}\n",
        "\n",
        "    # Initialize results dictionary\n",
        "    eval_results = {\n",
        "        'mape_evaluation': {},\n",
        "        'summary': {}\n",
        "    }\n",
        "\n",
        "    # 1. MAPE Target Evaluation\n",
        "    print(f\"\\n🔹 Evaluating MAPE Target (<{target_mape}%)...\")\n",
        "    meet_target = []\n",
        "    miss_target = []\n",
        "\n",
        "    for state, model_info in valid_models.items():\n",
        "        mape = model_info['metrics'].get('test_mape', float('inf'))\n",
        "        if mape < target_mape:\n",
        "            meet_target.append((state, mape))\n",
        "        else:\n",
        "            miss_target.append((state, mape))\n",
        "\n",
        "    # Sort by MAPE (ascending)\n",
        "    meet_target.sort(key=lambda x: x[1])\n",
        "    miss_target.sort(key=lambda x: x[1])\n",
        "\n",
        "    eval_results['mape_evaluation'] = {\n",
        "        'target': target_mape,\n",
        "        'meet_target': meet_target,\n",
        "        'miss_target': miss_target,\n",
        "        'meet_target_count': len(meet_target),\n",
        "        'miss_target_count': len(miss_target),\n",
        "        'success_rate': len(meet_target) / (len(meet_target) + len(miss_target)) * 100 if (len(meet_target) + len(miss_target)) > 0 else 0\n",
        "    }\n",
        "\n",
        "    print(f\"States meeting MAPE target: {len(meet_target)}/{len(valid_models)} ({eval_results['mape_evaluation']['success_rate']:.1f}%)\")\n",
        "    if meet_target:\n",
        "        print(\"Top 5 performing states:\")\n",
        "        for i, (state, mape) in enumerate(meet_target[:5]):\n",
        "            print(f\"  {i+1}. {state.title()}: MAPE = {mape:.2f}%\")\n",
        "\n",
        "    # 2. Generate summary\n",
        "    print(\"\\n🔹 Generating summary statistics...\")\n",
        "\n",
        "    # Calculate overall stats\n",
        "    mape_values = [data['metrics'].get('test_mape') for data in valid_models.values()\n",
        "                  if 'test_mape' in data['metrics']]\n",
        "    rmse_values = [data['metrics'].get('test_rmse') for data in valid_models.values()\n",
        "                  if 'test_rmse' in data['metrics']]\n",
        "    r2_values = [data['metrics'].get('test_r2') for data in valid_models.values()\n",
        "                if 'test_r2' in data['metrics'] and not np.isnan(data['metrics'].get('test_r2', float('nan')))]\n",
        "\n",
        "    model_counts = {}\n",
        "    for data in valid_models.values():\n",
        "        model_type = data['best_model']\n",
        "        model_counts[model_type] = model_counts.get(model_type, 0) + 1\n",
        "\n",
        "    eval_results['summary'] = {\n",
        "        'total_states': len(valid_models),\n",
        "        'mean_mape': np.mean(mape_values) if mape_values else None,\n",
        "        'median_mape': np.median(mape_values) if mape_values else None,\n",
        "        'min_mape': np.min(mape_values) if mape_values else None,\n",
        "        'max_mape': np.max(mape_values) if mape_values else None,\n",
        "        'mean_rmse': np.mean(rmse_values) if rmse_values else None,\n",
        "        'median_rmse': np.median(rmse_values) if rmse_values else None,\n",
        "        'mean_r2': np.mean(r2_values) if r2_values else None,\n",
        "        'model_distribution': model_counts\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nOverall Performance Summary:\")\n",
        "    print(f\"  Total states analyzed: {len(valid_models)}\")\n",
        "    if eval_results['summary']['mean_mape'] is not None:\n",
        "        print(f\"  Mean MAPE: {eval_results['summary']['mean_mape']:.2f}%\")\n",
        "        print(f\"  Median MAPE: {eval_results['summary']['median_mape']:.2f}%\")\n",
        "        print(f\"  MAPE range: {eval_results['summary']['min_mape']:.2f}% - {eval_results['summary']['max_mape']:.2f}%\")\n",
        "    if eval_results['summary']['mean_rmse'] is not None:\n",
        "        print(f\"  Mean RMSE: {eval_results['summary']['mean_rmse']:.4f}\")\n",
        "    if eval_results['summary']['mean_r2'] is not None:\n",
        "        print(f\"  Mean R²: {eval_results['summary']['mean_r2']:.4f}\")\n",
        "\n",
        "    print(\"\\nModel Distribution:\")\n",
        "    for model_type, count in model_counts.items():\n",
        "        print(f\"  {model_type}: {count} states ({count/len(valid_models)*100:.1f}%)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"✅ Model evaluation completed\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return eval_results"
      ],
      "metadata": {
        "id": "uDj5MwCGJWs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = evaluate_wheat_price_models_minimal(results)\n",
        "\n",
        "# You can now use evaluation_results for further analysis, reporting, or visualization\n",
        "print(f\"Number of states meeting MAPE target: {evaluation_results['mape_evaluation']['meet_target_count']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guHRm0JZ8xX5",
        "outputId": "cbac7b6e-a9b2-4562-d39b-2b019b7f6ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📊 Minimal Model Evaluation\n",
            "================================================================================\n",
            "\n",
            "🔹 Evaluating MAPE Target (<20.0%)...\n",
            "States meeting MAPE target: 21/21 (100.0%)\n",
            "Top 5 performing states:\n",
            "  1. Tamil Nadu: MAPE = 2.64%\n",
            "  2. Punjab: MAPE = 3.15%\n",
            "  3. Delhi: MAPE = 3.19%\n",
            "  4. Assam: MAPE = 3.26%\n",
            "  5. Haryana: MAPE = 3.35%\n",
            "\n",
            "🔹 Generating summary statistics...\n",
            "\n",
            "Overall Performance Summary:\n",
            "  Total states analyzed: 21\n",
            "  Mean MAPE: 6.15%\n",
            "  Median MAPE: 5.12%\n",
            "  MAPE range: 2.64% - 17.43%\n",
            "  Mean RMSE: 2.2765\n",
            "  Mean R²: -1.6629\n",
            "\n",
            "Model Distribution:\n",
            "  random_forest: 7 states (33.3%)\n",
            "  xgboost: 8 states (38.1%)\n",
            "  holt_winters: 6 states (28.6%)\n",
            "\n",
            "================================================================================\n",
            "✅ Model evaluation completed\n",
            "================================================================================\n",
            "Number of states meeting MAPE target: 21\n"
          ]
        }
      ]
    }
  ]
}